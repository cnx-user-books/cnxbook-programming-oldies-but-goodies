<!DOCTYPE doctype PUBLIC "-//w3c//dtd html 4.0 transitional//en">
<html>
<head>
                
  <meta http-equiv="Content-Type"
 content="text/html; charset=iso-8859-1">
                
  <meta name="GENERATOR" content="Microsoft FrontPage 6.0">
  <title>... JAVA and DSP by Richard G Baldwin</title>
</head>
<body link="#0000ff" vlink="#666666" alink="#ff0000" lang="EN-US">
 
<h2>Processing Image Pixels, Applying Image Convolution in Java</h2>
    <i>Learn how to design copying filters, smoothing filters, sharpening 
filters, 3D embossing filters, and edge detection filters, and how to apply 
those filters to images.</i><p><b>Published:</b>&nbsp; March 7, 2006<br>
   <b>By <a href="#About_the_author">Richard G. Baldwin</a></b> </p>
     
<p>Java Programming, Notes # 412</p>
     
<ul>
  <li><a href="#Preface">Preface</a></li>
  <li><a href="#Background_Information">Background Information</a></li>
  <li><a href="#Preview">Preview</a></li>
  <li><a href="#Experimental_Results">Experimental Results</a></li>
<ul>
	<li><a href="#A_simple_copy_filter">A simple copy filter</a></li>
	<li><a href="#A_smoothing_or_softening_filter">A smoothing or softening filter</a></li>
	<li><a href="#Bipolar_filters">Bipolar filters</a></li>
<ul>
      <li><a href="#Embossing_Filters_that_produce_a_3D-like_effect">Embossing filters that produce a 3D-like effect</a></li>
	  <li><a href="#Edge_detection_filters">Edge detection filters</a></li>
	  <li><a href="#Sharpening_filters">Sharpening filters</a></li>
</ul>
    <li><a href="#An_alternative_normalization_scheme">An alternative normalization 
	scheme </a>
<ul>
      <li><a href="#Back_to_the_sharpening_filter">Back to the sharpening filter</a></li>
		<li><a href="#Smoothing_or_softening_filters">Smoothing or softening 
		filters</a></li>
		<li><a href="#3D_embossing_filters">3D embossing filters</a></li>
		<li><a href="#Edge_detection_filter">Edge detection filter</a></li>    
</ul>
</ul>
  <li><a href="#Program_Code">Program Code</a><li><a href="#Summary">Summary</a></li>
	<li><a href="#Whats Next">What's Next</a></li>
	<li><a href="#References">References</a></li>
  <li><a href="#Complete_Program_Listings">Complete Program Listings</a> </li>

</ul>
        
<hr size="3" width="100%" align="center">    
<center>    
<h2> <a name="Preface">Preface</a></h2>
   </center>
<p><font color="#FF0000"><b>Part of a series</b></font></p>
<p>This lesson is one in a series designed to teach you how to use Java to 
create special effects with images by directly manipulating the pixels in the 
images.&nbsp; This is also the first part of a two-part lesson.&nbsp; The primary objective of this lesson is to teach you how to integrate 
much of what you have already learned about Digital Signal Processing <i>(DSP)</i> and Image 
Convolution into several Java programs that can be used to experiment with, and 
to understand the effects of a wide variety of image-convolution operations.</p>
<p>The first lesson in the series was entitled 
<a href="http://www.developer.com/java/other/article.php/3403921">Processing 
Image Pixels using Java, Getting Started</a>.&nbsp; The previous lesson 
was entitled <a href="http://www.developer.com/java/other/article.php/3579206">Processing Image Pixels, Understanding Image Convolution in 
Java</a>.&nbsp; This lesson builds upon those earlier lessons.</p>
<p><font color="#FF0000"><b>Not a lesson on JAI</b></font></p>
<p>The lessons in this series do not provide instructions on how to use 
the Java Advanced Imaging <i>(JAI)</i> API.&nbsp; 
<i>(That will be the primary topic for a future series of lessons.)</i>&nbsp; The purpose of 
this series is to teach you how to implement common 
<i>(and some not so common)</i> image-processing algorithms by 
working directly with the pixels.</p>
<p><font color="#FF0000"><b>You will need a driver program</b></font></p>
<p>The lesson entitled 
<a href="http://www.developer.com/java/other/article.php/3441391">Processing 
Image Pixels Using Java: Controlling Contrast and Brightness</a> provided and explained a program named <b>
ImgMod02a</b> that makes it easy to:</p>
<ul>
	<li>Manipulate and modify the pixels that belong to an image.</li>
	<li>Display the processed image along with the original image.</li>
</ul>
<p><b>ImgMod02a</b> serves as a driver that controls 
the execution of a second program that actually processes the pixels.&nbsp; <i>
<b>(ImgMod02a</b> displays the original and processed images in the standard 
format shown in <a href="#Figure_57">Figure 57</a>.)</i></p>The 
image-processing programs that I will explain in this lesson run under the control of <b>
ImgMod02a</b>.&nbsp; 
	In order to 
compile and run the programs that I will provide in this lesson, you will need to go to the lessons entitled 
<a href="http://www.developer.com/java/other/article.php/3441391">Processing 
Image Pixels Using Java: Controlling Contrast and Brightness</a> and  
<a href="http://www.developer.com/java/other/article.php/3403921">Processing 
Image Pixels using Java, Getting Started</a> to get copies of the class 
named <b>ImgMod02a</b> and the interface named <b>ImgIntfc02</b>.<p><font color="#FF0000"><b>C</b></font><font color="#ff0000"><b>lass 
files 
required</b></font></p>
<p>I will be discussing several different Java programs in this lesson.&nbsp; One of 
those programs is based on a class named <b>ImgMod33</b>.&nbsp; To compile and 
execute that program, you will need access to the following class files:</p>
<ul>
	<li>ImgIntfc02.class</li>
	<li>ImgMod02a.class</li>
	<li>ImgMod29.class</li>
	<li>ImgMod30.class</li>
	<li>ImgMod32.class</li>
	<li>ImgMod33.class</li>
</ul>
<p>A second Java program that I will discuss in this lesson is based on the class named <b>
ImgMod033a</b>.&nbsp; To compile and execute that program you will need access 
to the following class files:</p>
<ul>
	<li>ImgIntfc02.class</li>
	<li>ImgMod02a.class</li>
	<li>ImgMod29.class</li>
	<li>ImgMod30.class</li>
	<li>ImgMod32a.class</li>
	<li>ImgMod33a.class</li>
</li>
</ul>
<p>A third Java program that I will be discussing is based on a class named <b>Dsp041</b>.&nbsp; To 
compile and execute 
that program, you will need access to the following class files:</p>
<ul>
	<li>Dsp041.class</li>
	<li>Graph03.class</li>
	<li>GraphIntfc01.class</li>
	<li>GUI.class</li>
</ul>
<p>The source code for all of the above classes is provided either in this lesson or 
in lessons referred to in the <a href="#References">References</a> section of this 
lesson.</p>
<p><b><font color="#ff0000">Viewing tip</font></b> </p>
<p>You may find it useful to open another copy of this lesson in a separate
 browser window.&nbsp; That will make it easier for you to scroll back and
 forth among the different figures while you are reading about
 them.</p>
<p><font color="#FF0000"><b>Design rationale</b></font></p>
<p>In this lesson, I will walk you through the design rationale for several 
different types of convolution filters and show you the output produced by 
applying the filters to images.&nbsp; </p>
<p>Because of the limited dynamic range of the standard format for image color 
values, data normalization following convolution is an extremely important but 
seldom discussed issue.&nbsp; In this lesson, I will explain the design 
rationale for and provide examples of two different data normalization schemes.</p>
<h2 align="center"><a name="Background_Information">Background Information</a></h2>
<p>The earlier lesson entitled 
<a href="http://www.developer.com/java/other/article.php/3403921">Processing 
Image Pixels using Java, Getting Started</a> provided a great deal of background 
information as to how images are constructed, stored, transported, and rendered.&nbsp; 
I won't repeat that material here, but will simply refer you to the earlier 
lesson.</p>
<p>The earlier lesson introduced and explained the concept of a pixel.&nbsp; In 
addition, the lesson provided a brief discussion of image files, and indicated 
that the program named <b>ImgMod02a</b> is compatible with <i><b>gif</b></i> files,
<i><b>jpg</b></i> 
files, and possibly some other file formats as well.</p>
<p>The lessons in this series are not 
particularly concerned with file formats.&nbsp; Rather, the lessons are concerned with what 
to do with the pixels after they have been extracted from an image file.&nbsp; 
Therefore, there is very little discussion about file formats.</p>
<p><font color="#FF0000"><b>A three-dimensional array of pixel data as type int</b></font></p>
<p>The driver program named <b>ImgMod02a</b>:</p>
<ul>
	<li>Extracts the pixels from an image file.</li>
	<li>Converts the pixel data to type <b>int.</b></li>
	<li>Stores the pixel data in a three-dimensional array of type <b>int</b> that is 
	well suited for processing.</li>
	<li>Passes the three-dimensional array object's reference to a method in an 
	object instantiated from an 
	image-processing class.</li>
	<li>Receives a reference to a three-dimensional array object containing 
	processed pixel data from the image-processing method.</li>
	<li>Displays the original image and the processed image in a stacked display 
	as shown in <a href="#Figure_57">Figure 57</a>.</li>
	<li>Makes it possible for the user to provide new input data to the 
	image-processing method, invoking the image-processing method repeatedly 
	in order to create new displays showing the newly-processed image along with the 
	original image.</li>
</ul>
<p>The manner in which that is accomplished was explained in the earlier lesson 
entitled <a href="http://www.developer.com/java/other/article.php/3403921">Processing Image Pixels using Java, Getting Started</a>.</p>
<p><font color="#FF0000"><b>Concentrate on the three-dimensional array of 
type int</b></font></p>
<p>This lesson concentrates on showing you how to write 
image-processing programs that implement general purpose 2D image convolution.&nbsp; 
The convolution filter is read into the program from a text file, making it very 
easy to experimentally apply a variety of different convolution filters to the 
same image.&nbsp; The convolution programs receive raw pixel data in the form of a three-dimensional array 
of type <b>int</b>, 
and return processed pixel data in the form of a three-dimensional array of 
type <b>int</b>.</p>
<p><font color="#FF0000"><b>A grid of colored pixels</b></font></p>
<p>Each three-dimensional array object represents one image consisting of a 
grid of colored pixels.&nbsp; The pixels in the grid are arranged in rows 
and columns when they are rendered.&nbsp; One of the dimensions of the array represents rows.&nbsp; 
A second dimension represents columns.&nbsp; The third dimension represents the color 
<i>(and transparency)</i> of 
the pixels.</p>
<p><font color="#FF0000"><b>Fundamentals</b></font></p>
<p>Once again, I will refer you to the earlier lesson entitled 
<a href="http://www.developer.com/java/other/article.php/3403921">Processing 
Image Pixels using Java, Getting Started</a> to learn:</p>
<ul>
	<li>How the primary colors of red, green, and blue and the transparency of a 
	pixel are represented by four <b><i>unsigned</i></b> 8-bit bytes of data.</li>
	<li>How specific colors are created by mixing different amounts of red, 
	green, and blue.</li>
	<li>How the range of each primary color and the range of transparency 
	extends from 0 to 255.</li>
	<li>How black, white, and the colors in between are created.</li>
	<li>How the overall color of each individual pixel is 
determined by the values stored in the three color bytes for that pixel, as 
	modified by the transparency byte.</li>
</ul>
<p><font color="#FF0000"><b>Convolution in one dimension</b></font></p>
<p>The earlier lesson entitled 
<a href="http://www.developer.com/java/other/article.php/3484591">Convolution 
and Frequency Filtering in Java</a> taught you about performing convolution in 
one dimension.&nbsp; In that lesson, I showed you how to apply a convolution 
filter to a 
sampled time series in one dimension.&nbsp; As you may recall, the mathematical 
process in one dimension involves the following steps:</p>
<ul>
	<li>Register the n-point convolution filter with the first <b>n</b> samples in 
	the time series.</li>
	<li>Compute an output value, which is the sum of the products of the 
	convolution filter coefficient values and the corresponding time series values.</li>
	<li>Move the convolution filter one step forward, registering it with the 
	next <b>n</b> samples in the time series and compute the next output value as a sum 
	of products.</li>
	<li>Repeat this process until all samples in the time series have been 
	processed.</li>
</ul>
<p><font color="#FF0000"><b>Convolution in two dimensions</b></font></p>
<p>Convolution in two dimensions involves essentially the same steps except that 
in this case we are dealing with three different 3D sampled surfaces and a 3D convolution 
filter instead of a simple sampled time series.</p>
<blockquote>
	<p><i>(There is a red surface, a green surface, and a blue surface, each of 
	which must be processed.&nbsp; Each surface has width and height 
	corresponding to the first two dimensions of the 3D surface.&nbsp; In 
	addition, each sampled value that represents the surface can be different.&nbsp; 
	This constitutes the third dimension of the surface.&nbsp; There is also an 
	alpha or transparency surface that could be processed, but the programs in 
	this lesson don't process the alpha surface.&nbsp; Similarly, the 
	convolution filter has three dimensions corresponding to width, height, 
	and the values of the coefficients in the operator.&nbsp; Don't be confused 
	by the dimensions of the array object containing the surface or the 
	convolution filter and the dimensions of surface or the convolution filter.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Steps in the processing</b></font></p>
<p>Basically, the steps involved in processing one of the three surfaces to 
produce one output surface consist of:</p>
<ul>
	<li>Register the 2D aspect <i>(width and height)</i> of the convolution 
	filter with the first 2D area centered on the first row of samples on the 
	input surface.</li>
	<li>Compute a point for the output surface, by computing the sum of the 
	products of the convolution filter values and the corresponding input 
	surface values.</li>
	<li>Move the convolution filter one step forward along the row, 
	registering it with the next 2D area on the surface and compute the next point 
	on the output surface as a sum of products.&nbsp; When that row has been 
	completely processed, move the convolution filter to the beginning of the 
	next row, registering with the corresponding 2D area on the input surface 
	and compute the next point for the output surface.</li>
	<li>Repeat this process until all samples in the surface have been 
	processed.</li>
</ul>
<p><font color="#FF0000"><b>Repeat once for each color surface</b></font></p>
<p>Repeat the above set of steps three times, once for each of the three color 
surfaces.</p>
<p><font color="#FF0000"><b>Watch out for the edges</b></font></p>
<p>Special care must be taken to avoid 
having the edges of the convolution filter extend outside the boundaries of 
the input surface.</p>
<p><b><font color="#ff0000">Supplementary material</font></b> </p>
<p>I recommend that you also study the other lessons in my extensive collection
 of online Java tutorials.&nbsp; You will find those lessons published at
<a href="http://softwaredev.earthweb.com/java">Gamelan.com</a>.&nbsp; However, 
as of the date of this writing, Gamelan doesn't maintain a consolidated index 
of my Java tutorial lessons, and sometimes they are difficult to locate there.&nbsp; 
You will find a consolidated index at <a
 href="http://www.dickbaldwin.com">www.DickBaldwin.com</a><font
 color="#000000">.</font></p>
<p>I particularly recommend that you study the lessons referred to in the
<a href="#References">References</a> section of this lesson.</p>
<h2 align="center"><a name="Preview">Preview</a></h2>
<p>In this lesson, I will present, explain, and provide experimental results 
obtained from several major Digital Signal /Image Processing classes:</p>
<ul>
	<li>Dsp041/Graph08</li>
	<li>ImgMod33/ImgMod32</li>
	<li>ImgMod33a/ImgMod32a</li>
</ul>
<p><b>Dsp041</b> is a new Java class.&nbsp; <b>ImgMod33</b> is also a new Java 
class, which uses the earlier class named <b>ImgMod32</b> to perform the convolution 
operation and the normalization of the convolution output.&nbsp; <b>ImgMod32</b> 
was explained in the earlier lesson entitled 
<a href="http://www.developer.com/java/other/article.php/3579206">Processing Image Pixels, 
Understanding Image Convolution in Java</a>.</p>
<p><b>Graph08</b> is a major update to an existing program that is used for plotting.</p>
<p><b>ImgMod32a</b> is a newly modified version of the class named <b>ImgMod32</b>, 
which provides an alternative approach to normalization.&nbsp; <b>ImgMod33a</b> 
is a copy of <b>ImgMod33</b> except that it uses <b>ImgMod32a</b> instead of <b>ImgMod32</b> to perform the convolution and the normalization of the convolution 
output.</p>
<p><font color="#FF0000"><b>Normalization</b></font></p>
<p>If color values in images were represented by values of type <b>double</b>, 
normalization would not be required, and therefore would not be an issue.&nbsp; 
However, color values in images are represented by eight-bit unsigned integers.&nbsp; 
As a result, normalization is required, and normalization is a very important 
issue.&nbsp; I will illustrate the importance of proper normalization in this 
lesson.</p>
<p><font color="#FF0000"><b>Convolution output values go out of their allowed 
range</b></font></p>
<p>When you convolve a 
2D convolution filter with the color values on a color plane, there is a high 
probability that the results will include both negative values and values 
greater than 255, which is the maximum allowable value in an eight-bit unsigned 
integer.&nbsp; The big issue is deciding how to convert the convolution results 
back into values ranging from 0 to 255 inclusive <i>(normalization)</i>.</p>
<p>There is no one right 
solution to the problem.&nbsp; Some normalization schemes work best in some 
applications and other normalization schemes work best in other applications.</p>
<p><font color="#FF0000"><b>Two different normalization schemes</b></font></p>
<p>In this lesson, I will demonstrate the use of two different normalization 
schemes.&nbsp; The program combination <b>ImgMod33/ImgMod32</b> uses one scheme.&nbsp; 
The program combination <b>ImgMod33a/ImgMod32a</b> uses a different scheme.&nbsp; 
I will explain the two normalization schemes in detail in 
conjunction with demonstrations that illustrate their use.</p>
<p><font color="#FF0000"><b><a name="The_class_named_Dsp041">The class named Dsp041</a></b></font></p>
<p>The purpose of 
the class named <b>Dsp041</b> is to make it easy to experiment with different time series and 
different convolution filters in order to understand the concepts involved in 
convolution filtering.&nbsp; In this lesson, I will use this class to explain 
complex image processing concepts in one dimension before proceeding to the more 
difficult case of two dimensions.</p>
<p>The class named <b>Dsp041</b> must be run under control of the class 
named <b>Graph08</b>.&nbsp; Thus, the class named <b>Dsp041</b> requires access to the class named 
<b>Graph08</b> and an 
interface named <b>GraphIntfc08</b>.&nbsp; <b>Graph08</b> and <b>GraphIntfc08</b> are updates to 
an earlier class named <b>Graph03</b> and an interface named <b>GraphIntfc01</b>.&nbsp; The updates allow the user to plot a maximum of eight 
graphs in a single display instead of a maximum of five graphs as is the case with 
<b>Graph03</b>.</p>
<blockquote>
	<p><i>(Graph03 
and GraphIntfc01 were explained in an earlier lesson entitled 
	<a href="http://www.developer.com/java/other/article.php/3487996">Convolution and Matched 
Filtering in Java</a>.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Executing Dsp041 as a program</b></font></p>
<p>To execute the class named <b>Dsp041</b> as a program, enter the following command at the 
command line:</p>
<p></p>
<pre><b><font size="3">java Graph08 Dsp041</font></b></pre>
<p></p>
<p>Access to the following classes is required to compile and run this class under 
control of the class named 
<b>Graph08</b>:</p>
<ul>
	<li>Dsp041.class</li>
	<li>Graph08.class</li>
	<li>GUI.class</li>
	<li>GraphIntfc08.class</li>
</ul>
<p>The source code these classes and interfaces is provided in the section entitled <a href="#Complete_Program_Listings">Complete Program 
Listings</a>.</p>
<p><font color="#FF0000"><b>Filtering a known waveform</b></font></p>
<p>The class named <b>Dsp041</b> illustrates the application of a convolution filter to signals having a 
known waveform.&nbsp; In its current state, five different convolution filters are 
coded into the class.</p>
<blockquote>
	<p><i>(Since the class can only apply one convolution filter at a 
time, it is necessary to enable and disable the individual filters using comments and then 
	to recompile the class in order to switch from one convolution filter to the other.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Five different convolution filters</b></font></p>
<p>The 
five convolution filters that are built into the class named <b>Dsp041</b> are:</p>
<ol>
	<li>A single impulse filter that simply copies the 
input to the output.</li>
	<li>A high-pass filter with an output that is proportional to 
the slope of the signal.&nbsp; The output approximates the first derivative 
of the signal.</li>
	<li>A high-pass filter with an output that is proportional to the 
rate of change of the slope of the signal.&nbsp; This output approximates the second 
derivative of the signal.</li>
	<li>A relatively soft high-pass filter, which produces a 
little blip in its output each time the slope of the signal changes.&nbsp; The size of 
the blip is roughly proportional to the rate of change of the slope of the 
signal.</li>
	<li>A low-pass smoothing filter.&nbsp; The output approximates a four-point 
running average or integration of the signal.</li>
</ol>
<p><font color="#FF0000"><b>Behavior of the program</b></font></p>
<p>These convolution filters are 
applied to signal waveforms having varying shapes, and in particular varying slopes.&nbsp; Several interesting 
graphic results 
are displayed.</p>
<blockquote>
	<p><i>(The filters and the signal waveforms can be easily modified by 
modifying that part of the program and recompiling the program.)</i></p>
</blockquote>
<p>The display 
contains six graphs and shows the following:</p>
<ol>
	<li>The signal waveform as a time 
series.</li>
	<li>The convolution filter waveform as a time series.</li>
	<li>The result of 
applying the convolution filter to the signal, including the impulse response of 
the filter.</li>
	<li>The amplitude spectrum of the signal expressed in decibels <i>(db)</i>.</li>
	<li>The 
amplitude frequency response of the convolution filter expressed in db.</li>
	<li>The 
amplitude spectrum of the output produced by applying the convolution filter to 
the signal.</li>
</ol>
<blockquote>
	<p><i>(See <a href="#Figure_1">Figure 1</a> for an example of the graphic output produced by the 
	class named <b>Dsp041</b>.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Normalization</b></font></p>
<p>The convolution algorithm used in this class emulates a one-dimensional version of the 2D 
image convolution algorithm used in the class named <b>ImgMod032</b>.</p>
<blockquote>
	<p><i>(<b>ImgMod032</b> provides the convolution capability for the class named 
	<b>ImgMod033</b>, which will be discussed later in this lesson.)</i></p>
</blockquote>
<p>There are two major differences between this algorithm and the 2D algorithm 
provided by the class named <b>ImgMod32</b>:</p>
<p>First, this algorithm flips the convolution filter end-for-end whereas the 
2D algorithm does not flip the convolution filter.&nbsp; Thus, the 2D 
algorithm requires that the convolution filter be flipped before it is passed 
to the method.</p>
<p>Second, whereas the 2D convolution algorithm normalizes the output data so as 
to guarantee that the output values range from 0 to 255 inclusive, this 
algorithm normalizes the output data so as to guarantee that the output values 
range from 0 to 100 inclusive.&nbsp; This difference is of no practical 
significance other than to cause the output values to be plotted on a scale that 
is somewhat easier to interpret.</p>
<p>Both convolution algorithms assume that the incoming data consists of all positive values
<i>(as is the case for image color values)</i> with regard to the normalization 
rationale.&nbsp; However, this is not a technical requirement.</p>
<p><font color="#FF0000"><b>The normalization scheme</b></font></p>
<p>The algorithm begins by computing and saving the mean value of the incoming 
data.&nbsp; Then it makes a copy of the incoming data, removing the mean in the 
process. <i>(The copy is made simply to avoid modifying the original data.)</i></p>
<p>Then the method applies the convolution filter to the copy of the incoming 
data producing an output time series with a mean value of zero.&nbsp; Then the 
method adds the original mean value to the output values causing the mean value 
of the output to be the same as the mean value of the input.</p>
<p>Following this, the algorithm computes the minimum value of the output and 
checks to see if it is negative.&nbsp; If it is negative, the minimum value is 
subtracted from all output values, causing the minimum value of the output to be 
zero.&nbsp; Otherwise, no adjustment is made on the basis of the minimum value.</p>
<p>Then the algorithm computes the maximum value and checks to see if the 
maximum value is greater than 100.&nbsp; If so, all output values are scaled so 
as to cause the maximum output value to be 100.&nbsp; Otherwise, no adjustment 
is made on the basis of the maximum value.</p>
<p><font color="#FF0000"><b>Spectral graphs</b></font></p>
<p>In addition to computing 
and plotting the output from the convolution process, the class named <b>Dsp041</b> computes and 
displays the following spectral graphs in the frequency domain:</p>
<ul>
	<li>The amplitude spectrum of the signal expressed in decibels <i>(db)</i>.</li>
	<li>The 
amplitude frequency response of the convolution filter expressed in db.</li>
	<li>The 
amplitude spectrum of the output produced by applying the convolution filter to 
the signal, also expressed in db.</li>
</ul>
<p>This makes it possible for the user to relate the convolution results in 
the time domain with the spectral results in the frequency domain.</p>
<p><font color="#FF0000"><b>The class named Graph08</b></font></p>
<p>This is an updated version 
of the earlier class named <b>Graph03.&nbsp; </b>The update makes it possible 
for the user to plot up to eight functions in a single display instead of only 
5 as is the case with <b>Graph03</b>.</p>
<p><b>GraphIntfc08</b> is a corresponding update to the earlier interface named 
<b>GraphIntfc01</b>.&nbsp; </p>
<p>This is a plotting program.&nbsp; It is designed to access an object 
instantiated from a class file that implements <b>GraphIntfc08</b>, and to plot the output from up to eight functions defined in that 
class file.</p>
<p><font color="#FF0000"><b>Required methods</b></font></p>
<p>The plotting surface is divided into the required number of 
equal sized plotting areas, and one function is plotted in Cartesian 
coordinates in each plotting area.&nbsp; The methods corresponding to the functions are named 
<b>f1</b>, <b>f2</b>, <b>f3</b>, <b>f4</b>, <b>f5</b>, <b>f6</b>, <b>f7</b>, and 
<b>f8</b>.</p>
<p>The class that defines the functions listed above must also 
define a method named <b>getNmbr</b>, which takes no parameters and returns the 
number of functions to be plotted.&nbsp; If this method returns a value greater than 8, 
a <b>NoSuchMethodException</b> will be thrown.</p>
<blockquote>
	<p><i>(Note that the constructor for the class 
that implements <b>GraphIntfc08</b> must not require any parameters due to the use of 
the <b>newInstance</b> method of the <b>Class</b> class to instantiate an object of that class.)</i></p>
</blockquote>
<p>If the number of functions to be plotted is less than 8, then the absent method names 
must begin with f8 and work downward toward f1.&nbsp; For example, if the number of 
functions to be plotted is 3, then the program will expect to call methods named 
<b>f1</b>, <b>f2</b>, and 
<b>f3</b>.</p>
<p><font color="#FF0000"><b>The appearance of the graphic output</b></font></p>
<p>The plotting 
areas have alternating white and gray backgrounds to make them easy to separate 
visually.&nbsp; <i>(See <a href="#Figure_1">Figure 1</a> for an example.)</i></p>
<p>All curves are plotted in black.&nbsp; A Cartesian coordinate system with 
axes, tic marks, and labels is drawn in red in each plotting area.&nbsp; The 
Cartesian 
coordinate system in each plotting area has the same horizontal and vertical 
scale, as well as the same tic marks and labels on the axes.&nbsp; The labels displayed 
on the axes correspond to the values of the extreme edges of the plotting area.</p>
<p><font color="#FF0000"><b>A self-test main method</b></font></p>
<p>The <b>main</b> method also compiles a sample class named <b>junk</b>, which 
implements <b>GraphIntfc08</b>, and which defines the eight 
methods listed above plus the method named <b>getNmbr</b>.&nbsp; This class is used to test 
the 
plotting capability on a stand-alone basis.</p>
<p><font color="#FF0000"><b>Running the program</b></font></p>
<p>At runtime, the name of the class that implements 
the interface named <b>GraphIntfc08</b> must be provided as a command-line parameter.&nbsp; If this 
parameter is not provided, the program instantiates an object from the internal class 
named <b>junk</b> and plots the data provided by that class.&nbsp; Thus, you can test the 
program by running it with no command-line parameter.</p>
<p><font color="#FF0000"><b>User input</b></font></p>
<p>This class named <b>Graph08</b> provides the 
following text fields for user input, along with a button labeled <b>Graph</b>.&nbsp; This 
allows the user to adjust the plotting parameters and to replot the graph as many times with 
as many sets of plotting parameters as may be needed</p>
<ul>
	<li><b>xMin</b>: minimum x-axis value</li>
	<li><b>xMax</b>: maximum 
x-axis value</li>
	<li><b>yMin</b>: minimum y-axis value</li>
	<li><b>yMax</b>: maximum y-axis value</li>
	<li><b>xTicInt</b>: tic mark interval on the x-axis</li>
	<li><b>yTicInt</b>: tic mark interval on the y-axis</li>
	<li><b>xCalcInc</b>: calculation interval</li>
</ul>
<p>The user can modify any of these parameters and then click the <b>Graph</b> 
button to cause the eight functions to be re-plotted according to the new parameters.</p>
<p><font color="#FF0000"><b>Behavior of the Graph button</b></font></p>
<p>Whenever the <b>Graph</b> button is clicked, the event handler instantiates 
a new object of the class that implements the <b>GraphIntfc08</b> interface.&nbsp; Depending on 
the nature of that class, this may be redundant.&nbsp; However, it is 
useful in those cases where it is necessary to refresh the values of instance 
variables defined in the class <i>(such as a counter, for example)</i>.</p>
<p><font color="#FF0000"><b><a name="The_classes_named_ImgMod33_and_ImgMod33a">The classes named ImgMod33 and ImgMod33a</a></b></font></p>
<p>The classes named <b>ImgMod33</b> and <b>ImgMod33a</b> are the primary 
classes for which this lesson was written.&nbsp; Each of these classes provides a general 
purpose 2D image convolution and color filtering capability in Java.&nbsp; Both 
classes are 
designed to be driven by the class named <b>ImgMod02a</b>.&nbsp; </p>
<blockquote>
	<p><i>(The class named <b>ImgMod02a</b> was explained in the earlier lesson entitled
	<a href="http://www.developer.com/java/other/article.php/3441391">Processing 
Image Pixels Using Java: Controlling Contrast and Brightness</a>.&nbsp; I will 
	explain <b>ImgMod33</b> and <b>ImgMod33a</b>, and the differences between 
	the two in this lesson.)</i></p>
</blockquote>
<p>The image file to be processed through convolution is specified 
on the command line.</p>
<p><font color="#FF0000"><b>Convolution filters are provided as text files</b></font></p>
<p>The name of a file containing the 2D convolution filter is 
provided via a <b>TextField</b> on an interactive control panel after the program starts running.&nbsp; 
</p>
<blockquote>
	<p><i>(See <a href="#Figure_4">Figure 4</a> for an example of the interactive 
	control panel containing 
	four <b>TextField</b>s.)</i></p>
</blockquote>
<p>Different convolution filter files can be specified and applied to the image 
without a requirement to restart the program for each new filter.</p>
<p><font color="#FF0000"><b><a name="Color_filtering">Color filtering</a></b></font></p>
<p>Multiplicative 
factors, which are applied to the individual color planes following convolution 
and normalization, are also provided 
through three <b>TextField</b>s on the interactive control panel after the program starts running.</p>
<p><font color="#FF0000"><b>Running the programs</b></font></p>
<p>Enter one of the following at the command line to run one or the other of 
these programs where 
<b>ImageFileName</b> is the name of a .gif or .jpg file to be processed, 
including the extension:</p><b>
<pre><font size="3">java ImgMod02a ImgMod33 ImageFileName</font></pre>
<pre><font size="3">java ImgMod02a ImgMod33a ImageFileName</font></pre></b>
<p></p>
<p>Then 
enter the name of a file containing a 2D convolution filter in the <b>TextField</b> 
that appears in the interactive control panel.&nbsp; Click the <b>Replot</b> button on the 
<b>Frame</b> that displays the 
image to cause the convolution filter to be applied to the image.</p>
<blockquote>
	<p><i>(See <a href="#Figure_3">Figure 3</a> for an example of the Frame containing the original 
	image, the processed image, and the Replot button.&nbsp; See comments at the 
beginning of the method named <b>getFilter</b> in the class named <b>ImgMod33</b> for a description and an example of the 
required format for the file containing the 2D convolution filter.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Color filtering</b></font></p>
<p>You can modify 
the multiplicative factors in the three <b>TextFields</b> labeled <b>Red</b>, <b>Green</b>, and 
<b>Blue</b> 
in the interactive control panel 
before clicking the <b>Replot</b> button to cause the corresponding color values to be scaled by the 
respective multiplicative factors.&nbsp; The default multiplicative factor for each 
color plane is 1.0.&nbsp; When you click the <b>Replot</b> button:</p>
<ul>
	<li>The image in the top of the <b>Frame</b> will be convolved with the filter contained in the specified file.</li>
	<li>The color values in the color planes will be scaled by the corresponding 
	multiplicative factors after the convolution has been completed and the 
	image has been normalized.</li>
	<li>The filtered image will appear in the bottom of the <b>Frame</b>.</li>
</ul>
<body>
<blockquote>
	<p><i>(<a href="#Figure_6">Figure 6</a> shows the result of reducing the 
	Green and Blue multiplicative factors each to 0.5 and clicking the Replot 
	button.)</i></p>
</blockquote>

</body>
<p><font color="#FF0000"><b>Wave number data</b></font></p>
<p>Each time you click the <b>Replot</b> button, <a href="#Figure_41">two additional 
graphs</a> are produced that show the following information in a color contour map format:</p>
<ul>
	<li>The 2D convolution filter.</li>
	<li>The wave number response of the 2D convolution filter.</li>
</ul>
<p><i>(Note that the maps appear on top of one another.&nbsp; You must move 
	the one on the top to see the one on the bottom.)</i></p>
<p><font color="#FF0000"><b>Testing</b></font></p>
<p>All of the code in this lesson was tested 
using J2SE 5.0 and WinXP</p>
<h2 align="center"><a name="Experimental_Results">Experimental Results</a></h2>
<p align="left">Before getting into the programming details for the programs 
presented in this lesson, I will show you some experimental results 
produced using those programs.&nbsp; My objective is to teach you what happens when you convolve a 2D convolution filter with an image.&nbsp;I will present and discuss the results for several different 
types of 
convolution filters:</p>
<ul>
	<li>A simple copy filter <i>(See <a href="#Figure_3">Figure 3</a>.)</i></li>
	<li>Smoothing or softening filters <i>(See <a href="#Figure_55">Figure 55</a>.)</i></li>
	<li>Bipolar filters</li>
	<ul>
		<li>Embossing filters that produce a 3D-like effect <i>(See
		<a href="#Figure_57">Figure 57</a>.)</i></li>
		<li>Edge detection filters <i>(See <a href="#Figure_59">Figure 59</a>.)</i></li>
		<li>Sharpening filters <i>(See <a href="#Figure_54">Figure 54</a>.)</i></li>
	</ul>
</ul>
<blockquote>
	<p><i>(The last three types of filters in the above list could all 
be considered to be special cases of edge detection filters.&nbsp; More 
generally, they are filters having both positive and negative coefficient 
values.)</i></p>
</blockquote>
<p>&nbsp;I will also teach you about two alternative normalization schemes.</p>
<p><font color="#FF0000"><b>Two normalization schemes</b></font></p>
<p>As mentioned earlier, normalization is a very important issue in image 
convolution.&nbsp; I will begin by using the classes <b>ImgMod33</b> and <b>ImgMod32</b> and the 
normalization scheme embodied in the class named <b>ImgMod32</b>.&nbsp; I will 
continue using those two classes until I notify you that I am switching to the 
use of the classes <b>ImgMod33a</b> and <b>ImgMod32a</b>.</p>
<p>By making the 
switch, I will be switching to the normalization 
scheme embodied in the class named <b>ImgMod32a</b>.&nbsp; At about that point, I will 
explain both normalization schemes in detail and I will explain the reasons for switching 
from one to the other.</p>
<p><font color="#FF0000"><b>Start simple in one dimension</b></font></p>
<p>In many cases, I will begin my explanation of a 2D convolution experiment with an explanation of a simplified 
version of the convolution process based on a one-dimensional convolution 
filter.&nbsp; Following that explanation, I will proceed to the more complex case based on a 2D convolution 
filter.&nbsp; My hope is that by first understanding the simplified one-dimensional 
case, you will be better prepared to understand the more complex 2D case.</p>
<p align="left">In the one-dimensional case, I will relate convolution in the 
time domain to 
multiplicative filtering in the frequency domain, and explain the ramifications 
of that relationship.</p>
<p align="left">In the two-dimensional case, I will 
relate convolution in the image domain to multiplicative filtering in the wave number domain.</p>
<h3 align="center"><a name="A_simple_copy_filter">A simple copy filter</a></h3>
<p align="left">I will begin with the simplest convolution filter that I know 
how to devise.&nbsp; This is a convolution filter consisting of a single 
impulse.&nbsp; I will explain this filter in the time domain, the frequency 
domain, the image domain, and the wave number domain.&nbsp; Along the way, I 
will prepare you to understand the different kinds of output displays that are 
produced by the programs being used.</p>
<p align="left"><font color="#FF0000"><b>The one-dimensional case</b></font></p>
<p align="left">I will begin with a one-dimensional explanation in the time and 
frequency domains as shown in <a name="Figure_1">Figure 1</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412aa1.jpg" width="409" height="431"><br></pre>
			<pre><b>Figure 1</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p><font color="#FF0000"><b>Six different graphs in one display</b></font></p>
<p><a href="#Figure_1">Figure 1</a> shows six different graphs, each plotted in 
Cartesian coordinates within its own plotting area.</p>
<blockquote>
	<p><i>(This is the type of graphic output 
produced by the class named <b>Dsp041</b> working in conjunction with the class 
	named <b>Graph08</b>.)</i></p>
</blockquote>
<p>The individual plotting areas are alternately colored 
white and grey to make it easier to separate them visually.&nbsp; Going from top to bottom, the graphs show:</p>
<ol>
	<li>The signal waveform as a time 
series.</li>
	<li>The convolution filter waveform as a time series.</li>
	<li>The output waveform.&nbsp; This is the result of 
applying the convolution filter to the signal.&nbsp; The output waveform includes the impulse response of 
the filter.</li>
	<li>The amplitude spectrum of the signal expressed in decibels <i>(db)</i>.</li>
	<li>The 
amplitude frequency response of the convolution filter expressed in db.</li>
	<li>The amplitude spectrum of the output expressed in db.</li>
</ol>
<p><font color="#FF0000"><b>The signal waveform</b></font></p>
<p>The signal waveform shown in the top graph in <a href="#Figure_1">Figure 1</a> 
is the waveform that will be used for all of the one-dimensional examples in this 
lesson.&nbsp; Going from left to right, the signal contains the following 
wavelets:</p>
<ul>
	<li>An impulse consisting of a single value.</li>
	<li>A rectangular pulse.</li>
	<li>A triangular pulse with a high slope.</li>
	<li>A triangular pulse with a smaller slope.</li>
</ul>
<p>All of these wavelets are made up of positive values and are riding on a 
positive, non-zero baseline.&nbsp; The intent is to start with an idealized 
version of the kinds of 
values that might be found in a single row of pixels in a single color plane in 
an image.</p>
<blockquote>
	<p><i>(Note that although the rectangular pulse appears to have sloping sides, that is an 
artifact of the plotting process.&nbsp; A straight line is drawn from the last 
value in the baseline before the pulse and the first value in the pulse.&nbsp; 
Because there is some distance between the two, the line has a slope.&nbsp; Also 
	note that the sides of the triangles are straight lines.&nbsp; The small 
	deviations from a straight line are also artifacts of the plotting process.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>The convolution filter</b></font></p>
<p>For this case, the convolution filter consists of an impulse, or a single 
value shown at the origin in the second graph from the top.</p>
<p><font color="#FF0000"><b>The output from the convolution process</b></font></p>
<p>The output from the convolution process is shown in the third graph from the 
top.&nbsp; The convolution of an impulse with a time series simply reproduces 
the time series.&nbsp; Thus, the output produced by convolving the impulse with 
the signal in this case looks just like the signal.</p>
<blockquote>
	<p><i>(Convolving a convolution filter with an impulse produces the impulse 
	response of the filter.&nbsp; Thus, the first feature in the output graph is 
	the so-called impulse response of the filter, which in this case, is just 
	another impulse.&nbsp; For subsequent experiments, however, the impulse 
	response will have a different waveform.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>The spectral data</b></font></p>
<p>Convolution in the time domain is equivalent to multiplication in the 
frequency domain.&nbsp; In other words, when you convolve a convolution 
filter with a time series, the frequency spectrum of the result is the same as 
the product 
of the frequency spectrum of the time series and the frequency response of the 
filter.</p>
<p><font color="#FF0000"><b>A peak at zero frequency</b></font></p>
<p>The frequency spectrum of the signal is shown in the fourth graph in
<a href="#Figure_1">Figure 1</a>.&nbsp; All of 
the spectral displays using this format in this lesson will extend from a 
frequency of zero to the
<a href="http://en.wikipedia.org/wiki/Nyquist_frequency">Nyquist</a> folding 
frequency, which is one-half the sampling frequency.</p>
<blockquote>
	<p><i>(As you can see, the spectrum has a peak at a frequency of zero.&nbsp; 
	This is because all of the signal values are positive and therefore, the 
	mean value of the signal is positive.&nbsp; The spectrum analysis process 
	measures the mean value of the signal and uses the result of that 
	measurement to represent the spectral value at a frequency of zero.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Peaks and valleys</b></font></p>
<p>The spectrum of the signal contains various peaks and valleys.&nbsp; It also has a general 
downward slope off to the right <i>(the direction of increasing frequency)</i>.&nbsp; 
The absolute shape of the signal spectrum won't mean much to us except to the 
extent that the spectrum of the output is a modified version of the spectrum of 
the signal.</p>
<p><font color="#FF0000"><b>Frequency response of the convolution filter</b></font></p>
<p>The frequency response of the 
convolution filter is shown in the fifth graph in <a href="#Figure_1">Figure 1</a>.</p>
<blockquote>
	<p><i>(Note that all three spectral graphs are plotted in 
	<a href="http://en.wikipedia.org/wiki/Decibel">decibels</a> or db.&nbsp; This 
	was done to preserve the plotting dynamic range.&nbsp; To make a long story 
	short, converting to decibels means multiplying a value by a constant, and replacing 
	the resultant product by the log to the base 10 of 
	that product.&nbsp; I discussed this to some extent in the earlier lessons 
	entitled <a href="http://www.developer.com/java/other/article.php/3508706">Plotting 3D Surfaces using Java</a>, and
	<a href="http://www.developer.com/java/other/article.php/10936_3549991_2">Adaptive Filtering in Java, Getting Started</a>. You will also find a good 
	discussion of decibels on the <a href="http://en.wikipedia.org/wiki/Decibel">Wikipedia</a> web site.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Frequency spectrum of the output</b></font></p>
<p>The frequency spectrum of 
the output time series produced by the convolution process is shown in the sixth 
graph.</p>
<p>The frequency response of the convolution filter in the fifth graph in 
<a href="#Figure_1">Figure 1</a> is perfectly flat <i>(the frequency spectrum of an impulse is always flat)</i>.&nbsp; 
Thus, the product of the frequency response of the filter in the fifth graph and 
the spectrum of the signal in the fourth graph simply reproduces the spectrum of 
the signal as shown in the sixth graph in <a href="#Figure_1">Figure 1</a>.</p>
<p><font color="#FF0000"><b>The corresponding 2D example</b></font></p>
<p>The left panel in <a name="Figure_2">Figure 2</a> shows a 2D convolution 
filter consisting of a single impulse.&nbsp; </p>
<p></p>
<table border="1" bgcolor="#ccffff">
	<tr>
		<td><img border="0" src="java412aa4.jpg" width="137" height="180"></td>
		<td><img border="0" src="java412aa5.jpg" width="137" height="180"></td>
	</tr>
	<tr>
		<td colspan="2" >
		<pre><b>Figure 2</b></pre></td>
	</tr>
</table>
<blockquote>
	<p>(<i>The plotting format used in <a href="#Figure_2">Figure 2</a> was discussed in detail in the 
	earlier lesson entitled
	<a href="http://www.developer.com/java/other/article.php/3508706">Plotting 
	3D Surfaces using Java</a>.&nbsp; Briefly, <a href="#Figure_2">Figure 2</a> 
	contains a pair of 3D plots with the 
	elevation represented by color.&nbsp; The elevation color scale is shown at 
	the bottom of each plot.&nbsp; Black and dark blue represent the lowest 
	elevations.&nbsp; Red and white represent the highest elevations.&nbsp; 
	Yellow, green, and light blue represent the elevations in between.</i>)</p>
</blockquote>
<p>Thus, the single impulse in the 2D convolution filter shown in
<a href="#Figure_2">Figure 2</a> is represented by a single value at the maximum 
elevation <i>(white)</i> protruding from a surface that is otherwise at the 
lowest elevation <i>(black)</i>.</p>
<p><font color="#FF0000"><b>The wave number response</b></font></p>
<p>The right panel in <a href="#Figure_2">Figure 2</a> shows the wave number response of the convolution 
filter in the left panel.&nbsp; <i>(This is analogous to the frequency response 
of the one-dimensional convolution filter in <a href="#Figure_1">Figure 1</a>.)</i>&nbsp; Although it 
isn't very pretty, this is a flat wave number response.&nbsp; The 
ratio of the highest to the lowest points in the right panel of 
<a href="#Figure_2">Figure 2</a> is 1.0000000000000002.</p>
<p><font color="#FF0000"><b>The output image</b></font></p>
<p>The bottom panel in <a href="#Figure_3">Figure 3</a> shows the result of 
applying this convolution filter to the image in the top panel of 
<a name="Figure_3">Figure 3</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412aa2.jpg" width="310" height="476"><br></pre>
			<pre><b>Figure 3</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>As you can see, this convolution filter consisting of a single impulse simply 
copies the input image into the output.&nbsp; The only differences between the 
two are differences resulting from computational inaccuracies.</p>
<p><font color="#FF0000"><b>Possible display problems</b></font></p>
<p>The display screen on my HP laptop computer causes colors to become 
progressively lighter going down the screen from top to bottom.&nbsp; Therefore, 
the image in the bottom panel of <a href="#Figure_3">Figure 3</a> looks lighter than the image in the top 
panel of 
<a href="#Figure_3">Figure 3</a> on my computer.&nbsp; However, if I copy the entire frame containing 
both images out to a graphics program and turn the frame upside down, the 
bottom image, which looked darker when it was at the top looks lighter when it 
is at the bottom.</p>
<p>If the bottom image in <a href="#Figure_3">Figure 3</a> doesn't match the top image on your computer, 
your display may suffer from some similar problem.</p>
<p><font color="#FF0000"><b>An interactive control panel</b></font></p>
<p>The interactive control panel produced by the classes named <b>ImgMod33</b> 
and <b>ImgMod33a</b> is shown in 
<a name="Figure_4">Figure 4</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412aa3.jpg" width="461" height="126"><br></pre>
			<pre><b>Figure 4</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>As you can see from the top <b>TextField</b> in <a href="#Figure_4">Figure 4</a>, this 2D convolution filter was stored in and 
retrieved from a file named <b>Filter04.txt</b>.</p>
<blockquote>
	<p><i>(I will come back and discuss 
the fields named Red, Green, and Blue later in this lesson.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Contents of the filter file</b></font></p>
<p>The actual contents of the filter file 
named Filter04.txt are shown in <a name="Figure_5">Figure 5</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><b>//File Filter04.txt
//A single impulse copy filter
1
1

1</b><br></pre>
			<pre><b>Figure 5</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>Briefly, the first two lines in <a href="#Figure_5">Figure 5</a> are comments that are ignored when 
reading the filter values from the file.&nbsp; The blank line is a separator, 
which is also ignored when reading the filter values from the file.&nbsp; The 
third and fourth lines specify that the 
filter has one row and one column in that order.&nbsp; The last line with a value of 1 specifies the value of the 
single filter coefficient to 
be 1.&nbsp; The coefficient value is converted to type <b>double</b> by the program and 
therefore, is interpreted to have a value of 1.0.</p>
<p><font color="#FF0000"><b>Color filtering</b></font></p>
<p>As you can see in <a href="#Figure_4">Figure 4</a>, the multiplicative values 
for Red, Green, and Blue were at their default values of 1.0 when the image of 
the interactive control panel was captured.&nbsp; Therefore, 
no color filtering was applied to the image in the bottom panel of
<a href="#Figure_3">Figure 3</a>.</p>
<p><a name="Figure_6">Figure 6</a> shows 
the result of reducing the Green and Blue multiplicative factors each to 0.5 and 
clicking the <b>Replot</b> button.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412aa6.jpg" width="310" height="476"><br></pre>
			<pre><b>Figure 6</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>This caused the green and blue components of every pixel to be reduced to 
one-half of their original value, leaving the red component to dominate the image.&nbsp; 
As you will see later, image convolution can sometime produce undesirable color 
changes.&nbsp; In those cases, it may sometimes be possible to apply color filtering 
following convolution as 
described above to correct the problem.</p>
<h3 align="center"><a name="A_smoothing_or_softening_filter">A smoothing or softening filter</a></h3>
<p>The next convolution filter that we will examine is a smoothing or softening 
filter.&nbsp; We will examine a four-point convolution filter in the 
one-dimensional time domain.&nbsp; Then we will examine a 1x4 convolution filter 
in the 2D image domain, followed by a 4x4 convolution filter in the 2D image 
domain.&nbsp; In all three cases, all of the filter coefficients that make up 
the convolution filter have the same positive value.</p>
<blockquote>
	<p><i>(Having the same value is not a requirement of smoothing filters.&nbsp; Although the 
	coefficients in smoothing filters almost always have positive values, 
	smoothing filters can be designed having a wide variety of combinations of 
	coefficient values.&nbsp; Each combination of coefficient values provides 
	somewhat different results.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>The one-dimensional case</b></font></p>
<p>The third graph in <a name="Figure_7">Figure 7</a> shows the result of 
applying a four-point convolution filter to the signal in the first graph.&nbsp; 
The convolution filter is shown by the small flat-topped pulse at the left end 
of the second graph.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ab1.jpg" width="409" height="575"><br></pre>
			<pre><b>Figure 7</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>The convolution filter in <a href="#Figure_7">Figure 7</a> consists of four coefficients, each having 
a value of 0.25.&nbsp; As the filter moves across the signal, the effect is to 
produce each output sample as the average of four consecutive input samples.&nbsp; 
Thus, the process tends to average out or smooth out the bumps in the signal.</p>
<p><font color="#FF0000"><b>The impulse response</b></font></p>
<p>For example, the single impulse at the left end of the input signal results 
in a replica of the convolution filter in the output.&nbsp; As mentioned 
earlier, this is often 
referred to as the <i>impulse response </i>of the convolution filter.</p>
<p>In effect, the 
impulse in the signal is turned into a plateau having a lower amplitude in the 
output.&nbsp; If you consider 
this to be image color data, the impulse would represent a single very bright 
pixel in the input.&nbsp; The output would consist of a line of four pixels 
having much less brightness.</p>
<p><font color="#FF0000"><b>A filtered rectangular pulse</b></font></p>
<p>The application of the convolution filter to the rectangular pulse in the 
input produced 
an output pulse of the same height.&nbsp; However, the base of the output pulse 
is broader than the input and the top of the output pulse is narrower than the 
input.</p>
<p>If you consider this to be color data, the input would represent a bright 
line ten pixels in length against a dark background.&nbsp; The total length of 
this feature in the output would be longer than ten pixels <i>(13 pixels)</i>, but the bright 
portion would be shorter than ten pixels <i>(7 pixels)</i>.&nbsp; Each end of the line would 
progress from dark to bright, or from bright to dark in a gradual, but linear 
fashion.</p>
<p><font color="#FF0000"><b>A filtered triangle</b></font></p>
<p>The application of the smoothing filter to the two triangular pulses caused 
the base of each output waveform to be broader than the base of the input.&nbsp; 
It also caused the sharp corners to be rounded or softened.&nbsp; 
<i>(Hence the commonly used 
name of a softening or smoothing filter.)</i>&nbsp; When viewed as color data, for both 
triangles, the intensity of the color of the input would transition from dark to 
bright and back to dark in a linear fashion with abrupt transitions at the 
beginning, the middle, and the end.&nbsp; The transitions from dark to bright 
and from bright to dark would be much smoother in the output.&nbsp; The 
transitions would also be longer.</p>
<p><font color="#FF0000"><b>The spectral results</b></font></p>
<p>Since the input signal in <a href="#Figure_7">Figure 7</a> is the same as the input signal in
<a href="#Figure_1">Figure 1</a>, the frequency spectrum of the input signal shown in the fourth graph in 
<a href="#Figure_7">Figure 7</a> hasn't changed.</p>
<blockquote>
	<p><i>(However, I did expand the vertical scale of <a href="#Figure_7">Figure 7</a> relative to
	<a href="#Figure_1">Figure 1</a>, so it may look a little different.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Multiplication in the frequency domain</b></font></p>
<p>I told you earlier that the output spectrum shown in the sixth graph in 
<a href="#Figure_7">Figure 7</a> should be the product of the filter response shown in the fifth graph 
and the input spectrum shown in the fourth graph.&nbsp; I now need to qualify 
that statement.</p>
<p><font color="#FF0000"><b>Decibel addition is equivalent to multiplication</b></font></p>
<p>It is true that convolution in the time domain is equivalent to 
multiplication in the frequency domain.&nbsp; However, the spectral values in 
the graph shown in <a href="#Figure_7">Figure 7</a> underwent a logarithmic transformation 
prior to plotting in order to preserve the plotting dynamic range.&nbsp; <i>(The 
raw spectral values were converted to decibels prior to plotting.)</i>&nbsp; If you 
are familiar with logarithms, you may 
recall that the addition of values that have undergone a logarithmic 
transformation is equivalent to the multiplication of the raw data.</p>
<blockquote>
	<p><i>(For example, one way to multiply two numbers is to compute the 
	logarithm of each number, add the logarithmic values, and then compute the 
	so-called <a href="http://www.thefreedictionary.com/antilogarithm">antilogarithm</a> of the sum.&nbsp; The result will be the product of the 
	two original numbers.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Need to add results expressed in decibels</b></font></p>
<p>Thus, when the individual spectra are viewed in decibel form, the spectral 
output of a convolution process is obtained by adding the spectrum of the input 
and the spectral response of the convolution filter.</p>
<blockquote>
	<p><i>(When plotting the result, it is often necessary to slide the result 
	up or down on the page to make it fit in the plotting window.&nbsp; Sliding 
	a decibel plot up or down on the page is equivalent to multiplying every raw 
	value in the plot by the same constant value.)</i></p>
</blockquote>
<p>As you can see, the spectrum of the output shown in the sixth graph in
<a href="#Figure_7">Figure 7</a> is the sum of the fourth and fifth graphs in
<a href="#Figure_7">Figure 7</a>.</p>
<p><font color="#FF0000"><b>The decibel scale</b></font></p>
<p>Now let's discuss the significance of the vertical scale on the spectral 
plots in <a href="#Figure_7">Figure 7</a>.&nbsp; The values of +100 and -100 occur at the transitions 
between white and grey in <a href="#Figure_7">Figure 7</a>.&nbsp; Thus, the plotting area for each graph 
extends from 100 units below the axis <i>(-100)</i> to 100 units above the axis
<i>(+100)</i>.&nbsp; Each 
tic mark on the vertical axis in <a href="#Figure_7">Figure 7</a> represents 20 units.</p>
<p>In preparation for plotting, the data was scaled so that each plotting unit 
would 
represent one-fourth of a decibel.&nbsp; Thus, 100 plotting units represents 25 decibels 
and each tic mark represents 5 decibels.</p>
<p><font color="#FF0000"><b>Relationship of decibels to the real world</b></font></p>
<p>Each three-decibel change in the spectral response represents a doubling or 
halving of the power at that frequency.&nbsp; Thus, when the frequency 
response in the fifth graph drops from 100 units at the origin to about 50 units 
at the top of the first lobe to the right, that corresponds to a reduction of the response by 
about 12.5 db.&nbsp; This, in turn, corresponds to a reduction in the power in 
the output relative to the power in the input at that frequency by a factor of 
about sixteen.&nbsp; Thus, small changes in a decibel plot represent large 
changes in power in the real world.&nbsp; That is why the logarithmic decibel 
scale is chosen to preserve plotting dynamic range.</p>
<p><font color="#FF0000"><b>The filter response</b></font></p>
<p>The filter response in the fifth graph in <a href="#Figure_7">Figure 7</a> is down by at least 11 or 
12 db at all frequencies greater than about twenty-percent of the sampling 
frequency.&nbsp; This means that the power in the output at those frequencies 
will be 
significantly reduced relative to the power in the input.</p>
<p>It is a 
well-known fact that in order for the values in a time series to make rapid 
transitions from low values to high values and back to low values, the time 
series must contain significant high-frequency components.&nbsp; Thus, the 
elimination of high-frequency components by the convolution filter eliminates 
the possibility of such rapid transitions.&nbsp; 
This is evidenced by comparing the first and third graphs in <a href="#Figure_7">Figure 7</a>.
<i>(The 
transitions take longer to occur in the output than is the case in the input.)</i></p>
<p><font color="#FF0000"><b>Extension to image data</b></font></p>
<p>Extending this concept to images, the elimination of high wave number components 
by filtering the image using a convolution filter eliminates the ability of the color values in the image to make rapid 
transitions.&nbsp; This, in turn causes the transitions to become smoother or 
softer.&nbsp; In fact, as you will see later, extreme elimination of high wave number components 
can cause the image to appear to be significantly out of focus with no sharp 
edges anywhere in the image.</p>
<p><font color="#FF0000"><b>Applying a smoothing filter to an image</b></font></p>
<p>Now, let's examine the result of applying a one-dimensional smoothing filter 
to a 2D image.&nbsp; The following experiment was performed using the class named
<b>ImgMod33</b>.</p>
<p>The filter and the wave number response of the filter are shown in
<a name="Figure_8">Figure 8</a>.&nbsp; The filter is shown in the left panel and 
the wave number response is shown in the right panel.</p>
<p></p>
<table border="1" bgcolor="#ccffff">
	<tr>
		<td><img border="0" src="java412ab2.jpg" width="137" height="180"></td>
		<td><img border="0" src="java412ab3.jpg" width="137" height="180"></td>
	</tr>
	<tr>
		<td colspan="2" >
		<pre><b>Figure 8</b></pre></td>
	</tr>
</table>
<p><font color="#FF0000"><b>The filter coefficient values</b></font></p>
<p>The contents of the text file <i>(Filter07.txt)</i> containing this filter are shown in
<a name="Figure_9">Figure 9</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><b>//File Filter07.txt
//One-dimensional soft smoothing filter

4
1

1
1
1
1</b><br></pre>
			<pre><b>Figure 9</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>As you can see from the left panel of <a href="#Figure_8">Figure 8</a> and from the first two 
non-comment lines in <a href="#Figure_9">Figure 9</a>, this filter 
is defined in four rows with one column.&nbsp; There are four filter 
coefficients, each having a value of 1.0.</p>
<blockquote>
	<p><i>(Note that the 2D convolution algorithm used by <b>ImgMod33</b> divides each sum of products 
	by the number of filter coefficients.&nbsp; Therefore, it isn't necessary to 
	scale the coefficient values down to 0.25 as was the case for the one-dimensional filter in 
	<a href="#Figure_7">Figure 7</a>.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>The wave number response</b></font></p>
<p>The wave number response of the convolution filter shown in the right panel of 
<a href="#Figure_8">Figure 8</a> 
is a 2D version of the frequency response of the filter shown in the fifth graph 
of <a href="#Figure_7">Figure 7</a>.&nbsp; The elevation values for a vertical slice taken through the 
center of the wave number response in <a href="#Figure_8">Figure 8</a> would be very similar to the 
frequency response shown in <a href="#Figure_7">Figure 7</a>.</p>
<blockquote>
	<p><i>(However, the wave number response was not converted to decibels prior 
	to display in <a href="#Figure_8">Figure 8</a> as was the case for the frequency response in
	<a href="#Figure_7">Figure 7</a>.&nbsp; This would cause the two to have a 
	different appearance.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Wave number range covered</b></font></p>
<p>The response at a wave number of zero is shown at the center of the right 
panel of <a href="#Figure_8">Figure 8</a>.&nbsp; The wave number response extends to the Nyquist folding 
wave number at the North, South, East, and West edges of the panel.</p>
<p><font color="#FF0000"><b>Peaks and troughs in the wave number response</b></font></p>
<p>The red and white horizontal band in the center of the wave number response 
in <a href="#Figure_8">Figure 8</a> is analogous to the peak at zero frequency in the frequency response at the left end 
of the fifth graph in <a href="#Figure_7">Figure 7</a>.</p>
<blockquote>
	<p><i>(The highest value in the wave number response in <a href="#Figure_8">Figure 8</a> is 
	represented by white with red coming in as a close second.&nbsp; The lowest 
	value is represented by black.&nbsp; See the color scale at the bottom of 
	the image.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>What about the left end of the fifth graph in 
Figure 7?</b></font></p>
<p>The fifth graph in <a href="#Figure_7">Figure 7</a> is analogous to only one-half of a 
vertical slice through the center of <a href="#Figure_8">Figure 8</a>.&nbsp; For the two to be completely analogous, 
we would need to construct a mirror image of the fifth graph in
<a href="#Figure_7">Figure 7</a> and 
attach it to the left end of the graph in <a href="#Figure_7">Figure 7</a>.&nbsp; This would produce a 
graph that is symmetric about its center in the same way that a vertical slice 
through the wave number response in <a href="#Figure_8">Figure 8</a> is symmetric about its center.</p>
<p><font color="#FF0000"><b>Deep troughs</b></font></p>
<p>The two black bands closest to and on either side of the red band in the wave number response 
in <a href="#Figure_8">Figure 8</a> are 
analogous to the deep trough shown to the right of the peak in the frequency response in the 
fifth graph in <a href="#Figure_7">Figure 7</a>.</p>
<p>The black band at the top and the dark blue band at the bottom of the 
wave number response in <a href="#Figure_8">Figure 8</a> are analogous to the developing trough at the right edge of 
the fifth graph in <a href="#Figure_7">Figure 7</a>.</p>
<p><font color="#FF0000"><b>Secondary peaks</b></font></p>
<p>The light blue bands near the top and bottom 
edges of the wave number response in <a href="#Figure_8">Figure 8</a> are analogous to the peak in the frequency 
response about three-fourths of the way across the fifth graph in
<a href="#Figure_7">Figure 7</a>.</p>
<p><font color="#FF0000"><b>Infer some conclusions</b></font></p>
<p>From the wave number response of the filter shown in <a href="#Figure_8">Figure 8</a>, we can infer the
<a name="conclusion">following</a>:</p>
<ol>
	<li>Transitions along edges in the image that are parallel to the red band will 
	experience the maximum amount of smoothing.</li>
	<li>Transitions along edges that are perpendicular to the red band will not experience 
	any smoothing at all.</li>
	<li>Transitions along edges that are at some other angle relative to the red band will 
	experience some amount of smoothing, with the amount of smoothing increasing 
	as the edge becomes more nearly parallel to the red band.</li>
</ol>
<p><font color="#FF0000"><b>A filtered Stick Man</b></font></p>
<p>Let's see if these <a href="#conclusion">conclusions</a> are borne out in reality.&nbsp; 
<a href="#Figure_10">Figure 10</a> 
shows the application of this convolution filter <i>(Filter07.txt)</i> to an image 
<i>(stickman2.gif)</i> of a black 
Stick Man 
on a white background.&nbsp; <i>(As you will see later, transitions from white 
to black behave differently from transitions from black to white in some cases.)</i>&nbsp; The image has lots of sharp edges at 
different angles.</p>
<blockquote>
	<p><i>(In the previous paragraph, I made reference to an image file named 
	stickman2.gif.&nbsp; For my own records, I will frequently refer to such 
	files so that I will be able to identify the file in the event that I need 
	to repeat the experiment sometime in the future.)</i></p>
</blockquote>
<p>The top panel in <a name="Figure_10">Figure 10</a> shows the original image.&nbsp; The bottom panel 
shows the image that resulted from performing the convolution.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ab4.jpg" width="114" height="304"><br></pre>
			<pre><b>Figure 10</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p><font color="#FF0000"><b>Lots of sharp edges</b></font></p>
<p>The fact that this image contains sharp edges with transitions from white to black, and 
from black to white indicates that the color values exhibit large transitions at 
different points in the image.&nbsp; Generally, the white background indicates high 
color values and the black areas indicate low color values.</p>
<p><font color="#FF0000"><b>Fuzzy forearms and shoulders</b></font></p>
<p>Note first the fuzziness of the forearms and the shoulders in the output image.&nbsp; 
The edges of the forearms and shoulders are almost parallel to the red band in 
the wave number response of <a href="#Figure_8">Figure 8</a>.&nbsp; The fuzziness at these edges 
indicates that the high wave number components required to support these transitions have been significantly reduced.&nbsp; This agrees 
with the first <a href="#conclusion">conclusion</a> listed above.</p>
<p><font color="#FF0000"><b>No fuzz on the torso</b></font></p>
<p>Now note the torso, which is perpendicular to the red band in the wave number 
response.&nbsp; The edges of the torso are still crisp and free of fuzz.&nbsp; 
Therefore, those edges must still have their high wave number components.&nbsp; 
This agrees with the second 
<a href="#conclusion">conclusion</a> listed 
above.</p>
<p>Now note the arms, legs, and feet, for which the edges are at 
various angles relative to the red band in the wave number response in 
<a href="#Figure_8">Figure 8</a>.&nbsp; 
These edges exhibit differing amounts of fuzz, depending on the angle between 
the respective edge and the red band in the wave number response in 
<a href="#Figure_8">Figure 8</a>.&nbsp; This agrees with the third <a href="#conclusion">conclusion</a> listed 
above.</p>
<p><font color="#FF0000"><b>Input versus output wave number spectra</b></font></p>
<p>I would like very much to be able to show you the wave number spectrum of the 
input and the output so that you can see that the output wave number spectrum is 
the product of the input wave number spectrum and the wave number response of 
the convolution filter.</p>
<p>However, the time required to compute and display such a wave number spectrum is prohibitive 
on my computer, even for a small image like the Stick Man.&nbsp; To begin with, 
it is necessary to compute the wave number spectrum for each of three color 
planes in order to make any sense out of the results.&nbsp; Beyond that, the 
computation of the wave number spectrum for only one color plane requires more time 
than my limited patience will allow.</p>
<p><font color="#FF0000"><b>A true 2D convolution</b></font></p>
<p> 
<a href="#Figure_10">Figure 10</a> 
shows the result of performing a convolution between a 1x4 convolution filter 
and a 2D image.&nbsp; Thus, although the 2D convolution algorithm was used, the 
experiment wasn't fully a 2D experiment because the filter wasn't a 2D filter.</p>
<p><a name="Figure_11">Figure 11</a> shows the filter and its wave number 
response for a true 2D version of the four-point smoothing filter.</p>
<table border="1" bgcolor="#ccffff">
	<tr>
		<td><img border="0" src="java412ab5.jpg" width="137" height="180"></td>
		<td><img border="0" src="java412ab6.jpg" width="137" height="180"></td>
	</tr>
	<tr>
		<td colspan="2" >
		<pre><b>Figure 11</b></pre></td>
	</tr>
</table>
<p><font color="#FF0000"><b>A 4x4 convolution filter</b></font></p>
<p>The filter <i>(Filter05.txt)</i> shown in <a href="#Figure_11">Figure 11</a> consists of a 4x4 block 
of filter coefficients, each having a value of 1.0.</p>
<p><font color="#FF0000"><b>Wave number response comparison</b></font></p>
<p>If you compare the wave number response in <a href="#Figure_11">Figure 11</a> with the wave number 
response in <a href="#Figure_8">Figure 8</a>, you should see a strong correlation between the 
two.&nbsp; A horizontal or vertical slice through the center of the wave number 
response in <a href="#Figure_11">Figure 11</a> generally matches a vertical slice through the center of 
the wave number response in <a href="#Figure_8">Figure 8</a>.</p>
<blockquote>
	<p><i>(However, a horizontal slice through the center of the wave number 
	response in <a href="#Figure_8">Figure 8</a> is perfectly flat and doesn't have any resemblance to a 
	horizontal slice through the center of the wave number response in <a href="#Figure_11">Figure 11</a>.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Suppress high wave number components at all angles</b></font></p>
<p>The wave number response in <a href="#Figure_11">Figure 11</a> indicates that this filter will 
suppress the high wave number components necessary to support any transition edge 
in an image, regardless of the angle of that edge relative to the horizontal.</p>
<p>Also, because there are no light blue areas on the diagonals, high wave number suppression at those 
angles will probably be more severe than for edges that are horizontal or vertical.</p>
<blockquote>
	<p><i>(It isn't likely that we will be able to see the difference 
	between suppression on the diagonals and suppression on the horizontal and 
	vertical axes.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>A 2D smoothing convolution on the Stick Man</b></font></p>
<p>The bottom panel of <a name="Figure_12">Figure 12</a> shows the result of 
applying this 2D convolution filter <i>(Filter05.txt)</i> to the 2D Stick Man image<i> (stickman2.gif)</i> in the top panel.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ab7.jpg" width="114" height="304"><br></pre>
			<pre><b>Figure 12</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>The result of the smoothing operation is obvious.&nbsp; As 
indicated above, the amount of smoothing is generally independent of the angle 
of the edge relative to the horizontal.</p>
<p>As mentioned earlier, the amount of smoothing that will be experienced is 
dependent on the design of the 2D convolution filter.&nbsp; Before leaving the 
Stick Man, I want to show you the result of applying a more severe smoothing 
filter to the Stick Man.</p>
<p><font color="#FF0000"><b>A pyramid-shaped convolution filter</b></font></p>
<p>The convolution filter and its wave number response for this case are shown in
<a name="Figure_13">Figure 13</a>.&nbsp; As before, the filter <i>(Filter03.txt)</i> is shown in the left panel and the wave number response is 
shown in the right panel.</p>
<p></p>
<table border="1" bgcolor="#ccffff">
	<tr>
		<td><img border="0" src="java412ab8.jpg" width="137" height="180"></td>
		<td><img border="0" src="java412ab9.jpg" width="137" height="180"></td>
	</tr>
	<tr>
		<td colspan="2" >
		<pre><b>Figure 13</b></pre></td>
	</tr>
</table>
<p><font color="#FF0000"><b>A 10x10 
filter</b></font></p>
<p>This is a 10x10 convolution filter, and as mentioned above, it has the shape 
of a pyramid <i>(as opposed to a block, which was the case for the filter shown 
in <a href="#Figure_11">Figure 11</a>)</i>.&nbsp; The value for each of the coefficients is shown in
<a name="Figure_14">Figure 14</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><b>1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0
1.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 1.0
1.0 2.0 3.0 3.0 3.0 3.0 3.0 3.0 2.0 1.0
1.0 2.0 3.0 4.0 4.0 4.0 4.0 3.0 2.0 1.0
1.0 2.0 3.0 4.0 5.0 5.0 4.0 3.0 2.0 1.0
1.0 2.0 3.0 4.0 5.0 5.0 4.0 3.0 2.0 1.0
1.0 2.0 3.0 4.0 4.0 4.0 4.0 3.0 2.0 1.0
1.0 2.0 3.0 3.0 3.0 3.0 3.0 3.0 2.0 1.0
1.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 1.0
1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0</b><br></pre>
			<pre><b>Figure 14</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p><font color="#FF0000"><b>The wave number response of the 10x10 pyramid filter</b></font></p>
<p>If you compare the wave number response in <a href="#Figure_13">Figure 13</a> with the wave number 
response in <a href="#Figure_11">Figure 11</a>, you will see that this is a much more severe filter 
with respect to the suppression of high wave number components.&nbsp; 
The red and yellow area indicating the peak at a wave number of zero in <a href="#Figure_13">Figure 13</a> is very small, indicating that the response falls off very quickly with 
increasing wave number.</p>
<blockquote>
	<p><i>(Even the green and light blue area surrounding the peak in <a href="#Figure_13">Figure 13</a>  
	isn't much larger than the red area in <a href="#Figure_11">Figure 11</a>.)</i></p>
</blockquote>
<p>Outside of the small light blue area, everything is either dark blue or 
black.&nbsp; Energy at all wave numbers outside the small red, yellow, and green 
area will be suppressed, and all energy outside the small light blue area will 
be suppressed in a very significant way.</p>
<p><font color="#FF0000"><b>The poor Stick Man</b></font></p>
<p>This assessment is borne out by the filtered Stick Man in the bottom panel of
<a name="Figure_15">Figure 15</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ab10.jpg" width="114" height="304"><br></pre>
			<pre><b>Figure 15</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>Applying this filter<i> (Filter03.txt)</i> to the image in the top panel of 
<a href="#Figure_15">Figure 15</a> caused 
the poor Stick Man to be reduced to a mere shadow of himself.&nbsp; There isn't 
a sharp edge anywhere in the image.&nbsp; He looks completely soft and furry as a result of 
applying this severe softening filter.&nbsp; This is what happens when you 
suppress the high wave number components in an image in a very significant way.</p>
<p><font color="#FF0000"><b>The Stick Man becomes a ghost</b></font></p>
<p>Just for fun, I'm going to show you one more image <i>(stickman2a.gif) </i>involving 
the Stick Man and the 10x10 smoothing filter.&nbsp; However, in this case, the 
subject will be a white Stick Man on a black background instead of a black Stick 
Man on a white background.</p>
<p>The bottom panel in <a href="#Figure_16">Figure 16</a> shows the result of applying the same 10x10 
smoothing filter to the Stick Man shown in the top 
panel of <a name="Figure_16">Figure 16</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ab14.jpg" width="114" height="304"><br></pre>
			<pre><b>Figure 16</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>In this case, the Stick Man was turned into a ghost.</p>
<p><font color="#FF0000"><b>Enough already!</b></font></p>
<p>Although the Stick Man is very useful for illustrating image convolution 
concepts, we rarely have real images that are as clean and uncluttered as the 
Stick Man.&nbsp; Before leaving the topic of smoothing or softening filters, I 
want to show you the results of applying the same smoothing filters to a real 
photographic image<i> (background02.gif)</i>.</p>
<p><font color="#FF0000"><b>Applying the 4x1 smoothing filter</b></font></p>
<p><a name="Figure_17">Figure 17</a> shows the result of applying the 4x1 
smoothing filter contained in the file named Filter07 to the image.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ab11.jpg" width="310" height="476"><br></pre>
			<pre><b>Figure 17</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>This is the same filter that was applied to the Stick Man in  
<a href="#Figure_10">Figure 10</a>.&nbsp; 
As we would expect from what we learned earlier, the output image in the bottom 
panel of <a href="#Figure_17">Figure 17</a> exhibits some fuzz on the horizontal 
edges <i>(although clearly not as obvious as with the Stick Man in  
<a href="#Figure_10">Figure 10</a>)</i>.&nbsp; 
<a href="#Figure_17">Figure 17</a> exhibits little or no new fuzz on the edges that are near to the 
vertical.</p>
<p><font color="#FF0000"><b>Applying the 4x4 smoothing filter</b></font></p>
<p><a name="Figure_18">Figure 18</a> shows the result of applying the 4x4 
smoothing filter <i>(Filter05.txt)</i> to the same image of the starfish.&nbsp; 
This is the same filter that was applied to the Stick Man in 
<a href="#Figure_12">Figure 12</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ab12.jpg" width="310" height="476"><br></pre>
			<pre><b>Figure 18</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>As with the Stick Man in  
<a href="#Figure_12">Figure 12</a>, all of the edges have been softened in
<a href="#Figure_18">Figure 18</a>, regardless of their angle relative to the 
horizontal.&nbsp; If we were to reduce the filter to a 3x3 filter, or perhaps a 
2x2 filter, the degree of softening would be less.&nbsp; If we were to increase 
the filter to a 5x5 or a 6x6, the degree of softening would be greater.</p>
<p><font color="#FF0000"><b>Applying the 10x10 smoothing filter</b></font></p>
<p><a name="Figure_19">Figure 19</a> shows the result of applying the 10x10 
filter <i>(Filter03)</i> to the image of the starfish.&nbsp; This is 
the same filter that was applied to the Stick Man in  
<a href="#Figure_15">Figure 15</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ab13.jpg" width="310" height="476"><br></pre>
			<pre><b>Figure 19</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>Oops!&nbsp; It looks like we went a little overboard with the smoothing and 
softening in this case.&nbsp; Now you know how to process an image if you want 
to make it look like you are viewing it through a foggy window.</p>
<p><font color="#FF0000"><b><a name="A_color_shift">A color shift</a></b></font></p>
<p>There also seems to be some color shifting in the output of this filter 
relative to the input in <a href="#Figure_19">Figure 19</a>.&nbsp; <i>(The starfish looks too red to me.)</i>&nbsp; In an earlier lesson entitled
<a href="http://www.developer.com/java/other/article.php/3441391">Processing 
Image Pixels Using Java: Controlling Contrast and Brightness</a>, I explained 
and gave examples of what happens when you change the distribution of the color 
values in an image.&nbsp; That may be what is happening here.&nbsp; It may, or 
may not be possible to correct for the color shift by changing the 
multiplicative factors that are applied to the Red, Green, and Blue planes <i>(see 
<a href="#Figure_4">Figure 4</a> and the corresponding discussion of
<a href="#Color_filtering">color filtering</a>)</i>.</p>
<blockquote>
	<p><i>(I will have a great deal more to say about color shifting later when 
	we switch from the use of the normalization scheme in <b>ImgMod32</b> to the 
	normalization scheme in <b>ImgMod32a</b>.)</i></p>
</blockquote>
<p>Now that you have learned all about 2D smoothing or softening filters, I 
encourage you to compile the class named <b>ImgMod033</b> and experiment with 
smoothing filters of your own design using your own images.&nbsp; As for this 
lesson, we are going to move along at this point to another type of filter.</p>
<h3 align="center"><a name="Bipolar_filters">Bipolar filters</a></h3>
<p>This kind of filter opens up the possibility of having lots of fun with image 
convolution using some very simple filters.&nbsp; Generally, this kind of filter 
has a combination of positive and negative coefficient values.</p>
<p><font color="#FF0000"><b>Very similar results</b></font></p>
<p>With filters having only positive filter coefficients, changing the 
number of coefficients, or the values of the coefficients generally results in 
more or less the same general behavior.&nbsp; High wave number components may be 
suppressed to some degree but that is not always the case.&nbsp; Filters with 
all positive coefficients usually tend to smooth out the discontinuities causing the edges 
in the image to become less sharp.</p>
<p><font color="#FF0000"><b>Wildly different results</b></font></p>
<p>However, once we include both positive and 
negative coefficient values in a filter, we can get wildly different results by 
making small changes in the coefficient values, the signs of the coefficients, 
or the number of coefficients.</p>
<p>We will investigate the use of bipolar filters to produce filters that 
behave in the following ways:</p>
<ul>
	<li>Embossing filters that produce a 3D-like effect<i> (See
	<a href="#Figure_57">Figure 57</a>.)</i> </li>
	<li>Edge detection filters<i> (See <a href="#Figure_59">Figure 59</a>.)</i>
	</li>
	<li>Sharpening filters<i> (See <a href="#Figure_54">Figure 54</a>.)</i> </li>
</ul>
<p>We will begin our investigation with embossing filters.</p>
<h4 align="center"><b><a name="Embossing_Filters_that_produce_a_3D-like_effect">Embossing filters that produce a 3D-like effect</a></b></h4>
<p>Before we continue, I need to explain how the word embossing comes into play 
here.&nbsp; Embossed writing stationary is run through a machine 
that causes some portions of a picture to protrude from the surface of the paper 
and other portions to be recessed relative to the surface of the paper.&nbsp; 
The result is to create a very shallow 3D image on the paper.&nbsp; Although we can't create 
a true 3D image on the computer screen, we can create an optical illusion 
that results in a 3D-like effect.&nbsp; <a href="#Figure_34">Figure 34</a> and
<a href="#Figure_57">Figure 57</a> show examples of a processed image that looks very much like embossed writing stationary.</p>
<p><font color="#FF0000"><b>How do you create a 3D optical illusion?</b></font></p>
<p>I will begin by showing you a couple of examples that illustrate what I 
mean by an embossing filter that produces a 3D-like effect.&nbsp; I will also 
discuss the methodology for creating the 3D optical illusion.&nbsp; After all, 
if we are going to design a convolution filter that creates a 3D optical 
illusion, we need to understand what it is that causes the optical 
illusion.&nbsp; Once we understand that, we will be better prepared to design 
the filter.</p>
<p><font color="#FF0000"><b>An example of a 3D optical illusion</b></font></p>
<p>The bottom panel in <a name="Figure_20">Figure 20</a> shows the result of 
applying a specific 2D convolution filter <i>(Filter02.txt)</i> to the image <i>(box01.jpg) 
</i>in the 
top panel.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ac01.jpg" width="113" height="116"><br></pre>
			<pre><b>Figure 20</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>I believe that most people who work with computers would consider the image 
in the bottom panel of <a href="#Figure_20">Figure 20</a> to have a 3D effect.&nbsp; Further, I believe 
that most of those people would agree that it appears that the box in the bottom 
panel in <a href="#Figure_20">Figure 20</a> is protruding from the screen.</p>
<p><font color="#FF0000"><b>Another example of a 3D optical illusion</b></font></p>
<p>Similarly, I believe that those same people would consider the bottom panel in 
<a name="Figure_21">Figure 21</a> to have a 3D effect, in which the square in the bottom panel is 
recessed into the screen.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ac02.jpg" width="113" height="116"><br></pre>
			<pre><b>Figure 21</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<blockquote>
	<p><i>(Disclaimer:&nbsp; Optical illusions have different 
	effects on different people, so you may be one of those people who see the 
	above images in ways different from what I have described.&nbsp; For 
	example, there is one famous optical illusion where some people see a young 
	woman and others see an old hag.&nbsp; Sometimes I see one, and sometimes I 
	see the other when I look at
	<a href="http://www.norfacad.pvt.k12.va.us/puzzles/illusion.htm">that 
	picture</a>.&nbsp; Which do you see?)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Same convolution filter, different results</b></font></p>
<p>The same convolution filter was applied to the images in <a href="#Figure_20">Figure 20</a> and 
<a href="#Figure_21">Figure 
21</a>, but the results were very different.&nbsp; <i>(The image in 
<a href="#Figure_21">Figure 
21</a> is stored in the file named box02.jpg.)</i>&nbsp; Can you figure out 
why the results were so different?</p>
<p><font color="#FF0000"><b>What produces the 3D optical illusion?</b></font></p>
<p>The first thing that we need to establish is just what it is that produces 
the optical illusion of a 3D effect for a picture that is rendered on a flat 
computer screen <i>(or painted on a flat piece of canvas for that matter)</i>.</p>
<p><font color="#FF0000"><b>Compare with GUI buttons</b></font></p>
<p>Compare the bottom image in <a href="#Figure_20">Figure 20</a> with the three small buttons in the top 
right corner of the Frame and the large button labeled <b>Replot</b> in the bottom 
of the Frame in <a href="#Figure_20">Figure 20</a>.&nbsp; The GUI designers at Microsoft and Sun certainly want you to see 
those buttons in 3D and they want them to appear to be protruding from the 
screen.&nbsp; What do you see that is common between the GUI buttons and 
the bottom image in <a href="#Figure_20">Figure 20</a>?</p>
<p>Now compare the bottom image in  
<a href="#Figure_21">Figure 
21</a> with the same four buttons.&nbsp; 
What do you see that is different between those GUI buttons and the bottom image in 
<a href="#Figure_21">Figure 
21</a>?</p>
<p><font color="#FF0000"><b>The secret is...</b></font></p>
<p>In case you haven't figured out the feature that produces the 3D effect in 
both cases, I will let you in on the secret of this particular optical illusion.&nbsp; 
That feature is a secret that most successful artists <i>(and all successful 2D 
GUI designers)</i> understand.&nbsp; It all 
has to do with light and shadows.</p>
<p><font color="#FF0000"><b>Illumination from above</b></font></p>
<p>Assume that a 3D button is illuminated by a light source 
shining down from above and to the left.&nbsp; The top edge and the left 
edge of the protruding button would be illuminated more brightly than the face of 
the button.&nbsp; As you can see, the top and left edges of the four GUI rectangles that 
represent the GUI buttons in <a href="#Figure_20">Figure 20</a> are brighter than the face of the rectangle.</p>
<p>The illumination of a protruding button from above and to the left would 
cause the right edge and the bottom of the button to be in a shadow zone.&nbsp; 
Those edges would be darker than the face of the button.&nbsp; The right and 
bottom edges of the GUI rectangles that represent the buttons in
<a href="#Figure_20">Figure 20</a> are darker than 
the face of the rectangles.</p>
<p><font color="#FF0000"><b>A combination of light and shadow</b></font></p>
<p>This is the combination of light and shadow that causes the four GUI 
rectangles in <a href="#Figure_20">Figure 20</a> to look like buttons that protrude from the screen.&nbsp; 
The left and top edges of the rectangles are brighter than the face of the 
rectangle.&nbsp; The right and bottom edges of the rectangle are darker than the 
face of the rectangle.&nbsp; The result is that to most people, the rectangles 
look like buttons that protrude from the screen.</p>
<p>That same technique involving light and shadow was applied to the bottom 
image in <a href="#Figure_20">Figure 20</a> causing it to look like it is protruding from the screen.</p>
<p><font color="#FF0000"><b>A recessed square</b></font></p>
<p>Now consider the bottom image in  
<a href="#Figure_21">Figure 
21</a>.&nbsp; If a square were indeed 
recessed into the face of a wall and illuminated from above and to the left, the 
right and bottom edges would be illuminated more brightly than the face of the 
square.&nbsp; The top and left edges would be in a shadow zone and would be 
darker than the face of the square.&nbsp; </p>
<p><font color="#FF0000"><b>Check out a 3D Windows button</b></font></p>
<p>If you happen to be running Windows <i>(with the classic look and feel)</i>, start the Notepad program.&nbsp; Then 
press and hold the <i>minimize</i> button.&nbsp; When you do that, the top and 
left edges of the GUI rectangle that represents the button become darker than the 
face of the rectangle.&nbsp; The bottom edge of the rectangle becomes brighter 
than the face of the rectangle.&nbsp; It's hard to tell what happens to the 
right edge of the rectangle due to its proximity to the rectangle that 
represents the <i>maximize</i> button.&nbsp; Most computer users would agree 
that this optical illusion causes the rectangle to look like a button that has 
been pushed into the computer screen.</p>
<p>The same effect of light and shadow was applied to the bottom image in  
<a href="#Figure_21">Figure 
21</a>.&nbsp; That is what causes the 3D optical illusion to look like a recessed 
square to most computer users.</p>
<p><font color="#FF0000"><b>How do we do that using image convolution?</b></font></p>
<p>So, the big question at this point has to do with how one convolution filter can produce 
these different 3D effects.&nbsp; That is what I will explain in the 
sections that follow.</p>
<p>More generally, the question is how do we design a convolution filter that 
will produce the 3D optical illusion when applied to an image?&nbsp; That is the 
problem that we will tackle next.</p>
<p><font color="#FF0000"><b>Let's take inventory of what we know</b></font></p>
<p>Let's begin by taking inventory of what we already know to see if that will 
help us to design the convolution filter.</p>
<p>First, we know that in order to produce the 3D optical illusion, the filter 
will need to operate on edges that appear in the image.&nbsp; After all, the 
optical illusion is produced by highlighting some edges and making other edges 
darker.</p>
<p>We know that the process will probably need to emphasize the edges.&nbsp; 
That immediately eliminates the entire class of smoothing filters, which tend to 
de-emphasize the edges.&nbsp; That strongly suggests 
that the filter probably needs to be a bipolar filter because most filters 
containing only positive coefficient values tend to be smoothing filters.</p>
<p><font color="#FF0000"><b>Frequency domain considerations</b></font></p>
<p>We know that when viewed in the frequency or wave number domain, most 
smoothing filters are low-pass filters that tend to suppress high frequency or 
high wave number components.&nbsp; Since we know that we don't want a smoothing 
filter, we know that we probably don't want a low-pass filter.&nbsp; Assuming 
that we aren't going to create filters with lots of peaks and 
valleys in 
the frequency domain, that leaves only two possibilities:</p>
<ol>
	<li>Filters with a flat response</li>
	<li>High-pass filters</li>
</ol>
<p>We saw the result of applying a filter with a flat frequency response in 
<a href="#Figure_3">Figure 3</a> and it certainly didn't produce a 3D effect.&nbsp; This suggests that 
we should concentrate on the use of a high-pass filter.&nbsp; Unfortunately, 
there are an infinite number of different high-pass filters that we 
could try, so we need to zero in a little closer.</p>
<p><font color="#FF0000"><b>Symmetry or the lack thereof</b></font></p>
<p>We know that in order to produce the 3D effect, the convolution process should not treat symmetrical features in 
the image in a symmetrical way.&nbsp; Rather, such features should be treated in 
a non-symmetrical way so as to highlight the edges on two sides of the feature 
and to darken the edges on the opposing sides.&nbsp; We know that the application 
of a symmetrical convolution filter to a symmetrical feature will produce a symmetrical result.&nbsp; 
That tells us that our filter needs to be non-symmetrical.</p>
<p><font color="#FF0000"><b>Summary of what we already know</b></font></p>
<p>In summary, we know that the filter should probably include both positive and 
negative coefficients, should be non-symmetrical, and should be a high-pass 
filter.</p>
<p><font color="#FF0000"><b>A very simple filter</b></font></p>
<p>Let's give it a try using the simplest non-symmetrical high-pass filter that 
I know of.&nbsp; If that filter seems to be going in the right direction, we can work 
to improve it in order to come up with a better 3D embossing filter.</p>
<p>This simple filter has only two coefficients.&nbsp; 
Those coefficients have values of -1 and +1.&nbsp; This is a non-symmetrical 
high-pass filter with an output that is proportional to the slope of the signal.&nbsp; 
For those of you familiar with differential calculus, the output of this filter approximates the first derivative of the 
signal.</p>
<p><font color="#FF0000"><b>Experimental results</b></font></p>
<p>The third graph in <a href="#Figure_22">Figure 22</a> shows the result of applying this filter to the 
signal in the first graph in <a href="#Figure_22">Figure 22</a>.&nbsp; The convolution filter is shown at the left end 
of the second graph in <a name="Figure_22">Figure 22</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ad01.jpg" width="409" height="574"><br></pre>
			<pre><b>Figure 22</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p><font color="#FF0000"><b>Think color</b></font></p>
<p>Once again, think of the input in the first graph in <a href="#Figure_22">Figure 22</a> and the output 
in the third graph as a single row of color values in an image.&nbsp; From that 
viewpoint, this filter 
has a lot of promise.</p>
<p><font color="#FF0000"><b>The impulse response</b></font></p>
<p>For example, look what this filter did to the impulse in the signal.&nbsp; The impulse 
started out as a single bright spot in the image.&nbsp; It was converted to a 
bright spot followed by a black spot.&nbsp; Hence, it caused the left side of 
the impulse to be highlighted and the right side of the impulse to be darkened.&nbsp; 
That is just what we said earlier that we need.</p>
<p><font color="#FF0000"><b>The rectangular pulse</b></font></p>
<p>Now look at what it did to the rectangular pulse.&nbsp; It eliminated the 
pulse entirely replacing the left side of the pulse with a bright spot and 
replacing the right side of the pulse with a black spot.&nbsp; That also matches 
what we think we need.&nbsp; Unfortunately, it 
caused the body of the pulse to have the same brightness as the general 
background.&nbsp; That may not be what we need.&nbsp; We'll see later.</p>
<p><font color="#FF0000"><b>The triangular pulses</b></font></p>
<p>Now look what it did to the two triangular pulses.&nbsp; The left half of each 
triangle was replaced by a rectangular pulse somewhat brighter than the general 
background.&nbsp; The right half of each triangle was replaced by a rectangular 
pulse somewhat darker than the general background.</p>
<p><font color="#FF0000"><b>The distribution of color values</b></font></p>
<p>The general background level in the 
input signal was very low but not zero.&nbsp; The general background in the 
output was at approximately the mid point between the lowest and highest 
possible values of 0 and 100.&nbsp; Thus, except for the black spots and the 
very bright spots, the 
overall contrast between the darkest and brightest part of the image was 
reduced.&nbsp; If you were to compute a distribution of the color value in the 
output, it would probably be narrower than a distribution of the color values in 
the input.</p>
<blockquote>
	<p><i>(I explained what happens when you change the distribution of the 
	color values in an image in an earlier lesson entitled
	<a href="http://www.developer.com/java/other/article.php/3441391">Processing 
	Image Pixels Using Java: Controlling Contrast and Brightness</a>.&nbsp; You 
	might find it useful to go back and review that lesson.&nbsp; I will also 
	have quite a lot more to say about the distribution of color values later in 
	this lesson.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Spectral data</b></font></p>
<p>As indicated earlier, this is a high-pass filter as evidenced by the 
frequency response of the filter shown in the fifth graph in <a href="#Figure_22">Figure 22</a>.&nbsp; 
Consequently, except for zero frequency, the energy at low frequencies in the 
output is much lower than the energy at low frequencies in the input.&nbsp; 
High-frequency energy is preserved from input to output.</p>
<blockquote>
	<p><i>(The peak at zero frequency in the output is an artifact resulting 
	from the fact that the convolution algorithm strives to cause the output to 
	have the same mean value as the input.&nbsp; Otherwise, the energy at zero 
	frequency in the output would be zero because this particular filter has a 
	zero response at zero frequency.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Application of the filter to a 2D image</b></font></p>
<p>Let's apply this filter to a real 2D image and see what we get.</p>
<p>We will begin by creating a 2D filter having one row and two columns and 
applying it to two different 2D images.&nbsp; The filter 
coefficient values will be +1 and -1.&nbsp; <i>(The filter is stored 
in a file named Filter06.txt.)</i></p>
<p>The left panel in <a href="#Figure_23">Figure 23</a> shows the filter.&nbsp; The right panel in
<a name="Figure_23">Figure 23</a> shows the wave number response of the filter 
in the same format as before.</p>
<table border="1" bgcolor="#ccffff">
	<tr>
		<td><img border="0" src="java412ad02.jpg" width="137" height="180"></td>
		<td><img border="0" src="java412ad03.jpg" width="137" height="180"></td>
	</tr>
	<tr>
		<td colspan="2" >
		<pre><b>Figure 23</b></pre></td>
	</tr>
</table>
<p><font color="#FF0000"><b>The 
wave number response</b></font></p>
<p>As you can see from the 
black/blue band in the center, and the red/white band at the edges, this filter 
will suppress components with a low wave number and enhance components with high 
wave numbers <i>for vertical edges.</i></p>
<p>However, the filter will have no effect on the wave number components 
belonging to <i>horizontal edges</i>.&nbsp; For edges that are somewhere between horizontal 
and 
vertical, the effect will be roughly proportional to the angle of the edge 
relative to the vertical.</p>
<p><font color="#FF0000"><b>The output image</b></font></p>
<p>The result of applying this filter to the white square in the top image <i>(box01.jpg)</i> of 
<a href="#Figure_24">Figure 24</a> is shown in the bottom image of
<a name="Figure_24">Figure 24</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ad04.jpg" width="113" height="116"><br></pre>
			<pre><b>Figure 24</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>This is beginning to look like what we are after.&nbsp; Each row in the white 
square in the input image is analogous to the rectangular pulse in the input 
signal in the first graph in <a href="#Figure_22">Figure 22</a>.&nbsp; As we predicted, the left edge of 
the square was made very bright and the right edge of the square was made very 
dark.</p>
<p>Also as we predicted from an examination of the wave number response 
in <a href="#Figure_23">Figure 23</a>, the filter had no effect whatsoever on the horizontal edges on the 
top and the bottom of the square.</p>
<p>In addition, the general background was made brighter, and the face of the 
square has the same brightness as the general background.</p>
<p><font color="#FF0000"><b>A 3D effect</b></font></p>
<p>To my eyes, the square has taken on something of a 3D appearance and appears 
to protrude from the screen.&nbsp; In fact, as an optical illusion, my eyes tend 
to construct a very faint horizontal top and bottom on the output square even 
though the top and bottom edges are exactly the same color as the background and 
the face of the square.&nbsp; Optical illusions are very interesting.</p>
<p><font color="#FF0000"><b>Regarding the angle of the edge</b></font></p>
<p>Now, to get an idea how this filter behaves relative to the angle of the edge, 
let's call Stick Man back out of retirement.&nbsp; <i>(The image 
for this experiment is stored in a file named stickman2a.gif.)</i></p>
<p>The bottom panel of <a href="#Figure_25">Figure 25</a> shows the result of applying the same filter
<i>(Filter06.txt)</i> to the Stick Man figure shown in the top panel of
<a name="Figure_25">Figure 25</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ad05.jpg" width="114" height="304"><br></pre>
			<pre><b>Figure 25</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p><font color="#FF0000"><b>Compare the torso with the forearms</b></font></p>
<p>The thing that is the most interesting here is to compare the impact of the 
filter on the torso with the impact of the filter on the forearms.&nbsp; There 
is a solid white edge on the left side of the torso and a solid black edge on 
the right side of the torso.&nbsp; This is because the torso has vertical edges.&nbsp; 
The wave number response in <a href="#Figure_23">Figure 23</a> tells us to expect the maximum effect of 
the filter on vertical edges.</p>
<p>On the other hand, the forearms have only a few black and white dots.&nbsp; 
This is because the forearms are almost horizontal and the wave number response 
in <a href="#Figure_23">Figure 23</a> tells us that the filter will have no effect on horizontal edges.&nbsp; 
The different edges on the Stick Man fall at different angles relative to the 
vertical, and the effect of the filter can be seen to vary with respect to those angles.</p>
<p><font color="#FF0000"><b>Rotate the filter by ninety degrees</b></font></p>
<p>Now we will rotate the filter by ninety degrees and place it in two rows of 
the same column.&nbsp; We will use the same values as before, namely +1 and -1.</p>
<p>The convolution filter <i>(Filter10.txt)</i> and the wave number response of the convolution filter 
are shown in <a name="Figure_26">Figure 26</a> in the same format as before.</p>
<p></p>
<table border="1" bgcolor="#ccffff">
	<tr>
		<td><img border="0" src="java412ad06.jpg" width="137" height="180"></td>
		<td><img border="0" src="java412ad07.jpg" width="137" height="180"></td>
	</tr>
	<tr>
		<td colspan="2" >
		<pre><b>Figure 26</b></pre></td>
	</tr>
</table>
<p>It will probably come as no 
surprise to anyone that the wave number response looks just like <a href="#Figure_23">Figure 23</a>  
except that it has been rotated by ninety degrees.&nbsp; This wave number 
response tells us that the filter will have maximum effect on horizontal edges 
and no effect whatsoever on vertical edges.</p>
<p><font color="#FF0000"><b>Apply the filter to the Stick Man</b></font></p>
<p>This time, I will skip the image of the box and go straight to the Stick Man.&nbsp;
<a name="Figure_27">Figure 
27</a> shows the result of applying this filter to the same Stick Man image <i>(stickman2a.gif)</i> as shown in <a href="#Figure_25">Figure 25</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ad08.jpg" width="114" height="304"><br></pre>
			<pre><b>Figure 27</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p><font color="#FF0000"><b>The Stick Man lost his torso</b></font></p>
<p>Compare this result with the result shown in <a href="#Figure_25">Figure 25</a>.&nbsp; In <a href="#Figure_25">Figure 25</a>, 
the vertical edges on the torso evidenced the maximum impact from the filter, 
showing solid white and black edges.&nbsp; In <a href="#Figure_27">Figure 27</a>, as predicted above, the 
vertical edges on the torso were not impacted at all by the filter.&nbsp; In 
fact, the torso has simply faded into the background.</p>
<p>Also compare the forearms, which are nearly horizontal.&nbsp; In <a href="#Figure_25">Figure 25</a>, 
the forearm was only barely impacted by the filter.&nbsp; In <a href="#Figure_27">Figure 27</a>, as 
predicted above, the forearms were impacted in a significant way.</p>
<p><font color="#FF0000"><b>What we need is a compromise</b></font></p>
<p>We have seen that a one-dimensional horizontal filter does a good job on 
vertical edges and doesn't impact horizontal edges.&nbsp; We have also seen that 
a one-dimensional vertical filter does a good job on horizontal edges and 
doesn't impact vertical edges.</p>
<p><font color="#FF0000"><b>Where is the light source?</b></font></p>
<p>From a 3D viewpoint, the horizontal filter makes it appear that the object is 
being illuminated by a light source that is to the left of and at the same level as 
the object.&nbsp; Since that is a fairly rare occurrence in the real world, that 
doesn't necessarily create the 3D optical illusion that we are looking for.</p>
<p>Also, from a 3D viewpoint, the vertical filter makes it appear that the 
object is being illuminated by a light source that is directly overhead.&nbsp; 
While that is more common than a light source that is at the same level as the 
object, in most cases, the object being illuminated is not directly below the 
light source.</p>
<p>We need a filter that makes it appear that the light source is above the 
object and off to one side or the other.</p>
<blockquote>
	<p><i>(To agree with what some of us have become 
conditioned to expect by working on a daily basis with Windows GUI objects, we 
probably need a filter that makes it appear that the light source is above and 
to the left of the object.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>No need for a rocket scientist here</b></font></p>
<p>Since we know the effect of horizontal and vertical filters, it doesn't take 
a rocket scientist to surmise that the same filter arranged at an angle of 
forty-five degrees may do what we want.&nbsp; We will try that.</p>
<p>For this case, we will use a 2x2 convolution filter having the coefficient 
values shown in <a name="Figure_28">Figure 28</a>.&nbsp; <i>(This filter is 
stored in a file named Filter02.txt.)</i></p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><b>1.0  0.0
0.0 -1.0</b><br></pre>
			<pre><b>Figure 28</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p><font color="#FF0000"><b>Will probably need to scale the output</b></font></p>
<p>Note that two of the filter coefficients have a value of 0 and don't 
contribute anything to the output.&nbsp; Also recall me telling you earlier that 
the 2D convolution algorithm divides each sum of products by the number of 
filter coefficients.&nbsp; To make a long story short, this causes the entire 
output from this filter to be rather dark.&nbsp; To compensate for that, the 
color values in some of the output images that I will show have been 
scaled up to make them brighter.&nbsp; This was accomplished by entering a 
multiplicative factor in the Red, Green, and Blue fields in <a href="#Figure_4">Figure 4</a>.</p>
<p><font color="#FF0000"><b>The 2x2 filter and the wave number response</b></font></p>
<p><a name="Figure_29">Figure 29</a> shows the filter and the wave number 
response of the filter in the same format as before.</p>
<p></p>
<table border="1" bgcolor="#ccffff">
	<tr>
		<td><img border="0" src="java412ad09.jpg" width="137" height="180"></td>
		<td><img border="0" src="java412ad10.jpg" width="137" height="180"></td>
	</tr>
	<tr>
		<td colspan="2" >
		<pre><b>Figure 29</b></pre></td>
	</tr>
</table>
<p>The wave number response of this 
filter is the same as you saw in <a href="#Figure_23">Figure 23</a>, except that it is rotated by 
forty-five degrees.</p>
<p><font color="#FF0000"><b>Apply the filter to the white square</b></font></p>
<p>The bottom panel in <a href="#Figure_20">Figure 20</a>, <i>(which you saw 
earlier)</i> shows the result of 
applying this filter to the white square in the top panel of
<a href="#Figure_20">Figure 20</a>.&nbsp; <i>(This image is stored in a file 
named box01.jpg.)</i>&nbsp; As you will recall, this is the image that 
got us started talking about 3D optical illusions in the first place.&nbsp; As you saw 
earlier, simply applying the filter to the image makes it appear that the image 
is 3D, illuminated from above and off to the left.</p>
<p><font color="#FF0000"><b>Apply the filter to the Stick Man</b></font></p>
<p><a name="Figure_30">Figure 30</a> shows the result of applying this filter to 
the same Stick Man that you saw in <a href="#Figure_25">Figure 25</a> and <a href="#Figure_27">Figure 27</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ad11.jpg" width="114" height="304"><br></pre>
			<pre><b>Figure 30</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>You may or may not agree that the Stick Man looks more 3D in 
<a href="#Figure_30">Figure 30</a> 
than was the case in either of those two earlier figures.&nbsp; In  
<a href="#Figure_30">Figure 30</a>, at 
least, he has all of his body parts.&nbsp; He didn't lose his torso or his 
forearms.</p>
<p><font color="#FF0000"><b>Turn and face the other way</b></font></p>
<p><a name="Figure_31">Figure 31</a> shows what happens when the Stick Man turns and faces the other way, 
presenting body parts with different angles to the light source.&nbsp; <i>(This 
image is stored in the file named stickman3a.gif.)</i></p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ad12.jpg" width="114" height="304"><br></pre>
			<pre><b>Figure 31</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>In my opinion, he still looks pretty good.&nbsp; One of his thighs is fading 
a little, but the edge effect was still sufficient to keep it from fading 
completely into the background.</p>
<blockquote>
	<p><i>(From the wave number response in <a href="#Figure_29">Figure 29</a>, 
	we can see that this filter will ignore edges that are at forty-five degrees 
	to the horizontal in a direction that is perpendicular to the red bands.&nbsp; 
	That is what happened to the thigh in <a href="#Figure_31">Figure 31</a>.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Finally some embossed stationary</b></font></p>
<p>The bottom panel in <a href="#Figure_32">Figure 32</a> shows the result of applying the same embossing 
filter <i>(Filter02.txt)</i> to the photographic image <i>(penny05.jpg)</i> shown in the top panel of
<a name="Figure_32">Figure 32</a> and then scaling all of the color values in 
the output by a factor of 2.0.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ad13.jpg" width="246" height="526"><br></pre>
			<pre><b>Figure 32</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<blockquote>
	<p><i>(Actually, this is the negative of a photographic image.&nbsp; It is 
	interesting that the color of copper doesn't change very much between the 
	positive and the negative.)</i></p>
</blockquote>
<p> <a href="#Figure_32">Figure 32</a> shows what the filter can do to a photographic image of a coin 
containing a fairly limited number of different colors.&nbsp; This almost looks 
like someone put a piece of pink paper on top of the coin and then rubbed it 
causing the paper to be pushed into the depressions in the coin.</p>
<p><font color="#FF0000"><b>An example with many different edges</b></font></p>
<p><a name="Figure_33">Figure 33</a> shows an example of applying the embossing 
filter <i>(Filter02.txt)</i> to an image <i>(imgmod03a.gif)</i> that contains a 
wide variety of edges.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ad15.jpg" width="339" height="740"><br></pre>
			<pre><b>Figure 33</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p><font color="#FF0000"><b>When the input is already 3D</b></font></p>
<p>This is a particularly interesting example due to the different kinds of 
edges that appear in the original image.&nbsp; Some of the features in the 
original image were already intended to have a 3D effect.&nbsp; The output from the 
convolution process for those features still looks 3D but looks entirely 
different.</p>
<p>For example, take a look at the rectangular feature near the top containing 
the label <b><font face="Arial Narrow">BevelBorder LOWERED,2,2</font></b>.&nbsp; 
This feature appears to be a raised rectangular block in the original image due 
to the highlighting on the left and top edges and the darkening on the right and 
bottom edges.&nbsp; It no longer looks like a raised rectangular block in the 
output.&nbsp; Rather, it appears to have a protruding lip on the left and top 
edges and an etched groove on the right and bottom edges.</p>
<p><font color="#FF0000"><b>When the input is not already 3D</b></font></p>
<p>Now look at the feature labeled <font face="Arial Narrow"><b>Compound,Empty + 
LineBorder,10,10</b></font> near the bottom with the light grey 
or silver border.&nbsp; The border had no 3D effect in the original image, but has a 
significant raised 3D appearance in the output image.</p>
<p><font color="#FF0000"><b>The text</b></font></p>
<p>Now consider the text.&nbsp; None of the text had a 3D appearance in the 
original image.&nbsp; However, all of the text has a significant 3D appearance 
in the output image.&nbsp; What's more, most of the text in the output image 
appears to protrude from the screen, but some of the text in the output, such as 
the Copyright statement at the top, appears to be etched into the surface.&nbsp; 
Can you identify the conditions that cause some text to protrude and other text 
to appear etched?</p>
<p><font color="#FF0000"><b>A photograph with lots of colors</b></font></p>
<p><a name="Figure_34">Figure 34</a> shows the result of applying the embossing 
filter <i>(Filter02.txt)</i> to a photographic image <i>(background02.gif)</i> 
containing lots of colors and then multiplying all of the color values by 1.5.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ad16.jpg" width="310" height="476"><br></pre>
			<pre><b>Figure 34</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>To me, the output looks very much like the photograph was embossed onto a 
piece of light blue paper.&nbsp; And this was all accomplished using a 2D 
convolution filter having only four coefficients, two of which had a value of 
zero.&nbsp; It is amazing how much power resides in a convolution filter having 
both positive and negative coefficient values.</p>
<blockquote>
	<p><i>(Later, in <a href="#Figure_57">Figure 57</a>, I will show you another 
	result that was produced by applying the same filter to the same image but 
	using a different normalization scheme to convert the convolution output 
	values back into the required eight-bit unsigned format.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>A depressed Stick Man</b></font></p>
<p>Before leaving the topic of 3D embossing filters, I want to show you one more 
image of the Stick Man 
and leave you with a question.</p>
<p><a href="#Figure_35">Figure 35</a> shows the result of applying the same filter
<i>(Filter02.txt)</i> 
to the image <i>(stickman2.gif)</i> shown in the top panel of 
<a name="Figure_35">Figure 35</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ad14.jpg" width="114" height="304"><br></pre>
			<pre><b>Figure 35</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>To me, this Stick Man appears to be depressed into 
the surface of the screen rather than protruding from the screen as is the case 
in <a href="#Figure_30">Figure 30</a>.&nbsp; Can you figure out why he appears 
to be depressed?&nbsp; Think about what we have discussed so far in this lesson.</p>
<p>Now it is time to move on and discuss edge detection filters.</p>
<h4 align="center"><b><a name="Edge_detection_filters">Edge detection filters</a></b></h4>
<p>Assume that for reasons of your own, you would like to convert an image to a 
sort of line drawing where the lines in the output occur at the edges in the 
original drawing similar to that shown in <a name="Figure_36">Figure 36</a>.&nbsp; This process is commonly referred to as 
<i>edge 
detection</i>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ae01.jpg" width="218" height="554"><br></pre>
			<pre><b>Figure 36</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p><font color="#FF0000"><b>Why would I want to do that?</b></font></p>
<p>The purpose of this section of this lesson is to show you how to do edge 
detection, not 
why to do it.&nbsp; <i>(Go to <a href="http://www.google.com/">Google</a> and 
search for image edge detection and you will probably find more material on the 
topic than you have the time to read.)</i></p>
<p><font color="#FF0000"><b>Embossing filter is an edge detector</b></font></p>
<p>The embossing filter in the previous section is a form of edge detector.&nbsp; 
However, it does some things to those edges that we might not like to see if we 
are simply trying to identify and highlight the edges.</p>
<p><font color="#FF0000"><b>Watch out for symmetry or the lack thereof</b></font></p>
<p>For example, the embossing filter treats symmetrical features in a 
non-symmetrical way, causing the edge on one side to be bright and the edge on 
the other side to be dark.&nbsp; Since that is probably not what we want in a 
general purpose edge detector filter, we probably want to treat symmetrical features in 
a symmetrical way.&nbsp; This suggests that we should probably use a symmetrical 
convolution filter.</p>
<p><font color="#FF0000"><b>Probably need a high-pass filter</b></font></p>
<p>From what we have learned in the earlier sections of this lesson, we know 
that low-pass filters tend to de-emphasize the edges in an image while high-pass 
filters tend to emphasize the edges.&nbsp; This suggests that we probably want 
to use a symmetrical high-pass filter.</p>
<p><font color="#FF0000"><b>Zero response at zero wave number</b></font></p>
<p>Because we want the filter to be a high-pass filter, we probably want the 
filter response at zero frequency or zero wave number to be very low, probably 
zero.&nbsp; Therefore, we probably want the algebraic sum of the filter 
coefficients to be zero.&nbsp; This suggests that we probably want to use a 
symmetrical high-pass filter for which the sum of the coefficients is zero.</p>
<p><font color="#FF0000"><b>How do I design such a filter?</b></font></p>
<p>How does one go about designing such a filter?&nbsp; Well, if you have a lot 
of digital signal processing experience, you can probably come up with something close 
just by thinking about it.&nbsp; If not, you can use a trial-and-error approach.</p>
<p><font color="#FF0000"><b>Trial and error</b></font></p>
<p>For a trial-and-error approach, I suggest that you go to the
<a href="http://sepwww.stanford.edu/oldsep/hale/FftLab.html">FFT Laboratory</a> 
page, check the check box labeled <i>Origin Centered</i>, and then adjust the weights 
in the top-left <i>(Real)</i> box until you get what you want in the bottom-left 
box, making certain that the curve in the bottom-right box is flat at zero.</p>
<blockquote>
	<p><i>(To adjust a weight, just grab one of the circles with the mouse and 
	move it up and down.)</i></p>
</blockquote>
<p>If you make the weights in the top-left box symmetrical about the center, the 
spectrum showing in the bottom-right box should be flat at zero.</p>
<blockquote>
	<p><i>(Once you check the Origin Centered check box, the center of each of the 
	curves is identified by an open circle.&nbsp; The center of the bottom-left box will represent zero frequency 
and the right end will represent the Nyquist folding frequency.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>A very simple convolution filter</b></font></p>
<p>The simplest one-dimensional convolution filter that I can think of that meets all of 
the criteria stated above is a filter having the following three coefficients:</p>
<p><b><font face="Arial Narrow">-0.5, 1.0, -0.5</font></b></p>
<p>This is a high-pass filter with an output that is proportional to the rate of 
change of the slope of the signal. The convolution output approximates the second derivative 
of the signal.</p>
<p>Let's give it a try and see how it performs.</p>
<p><font color="#FF0000"><b>Apply the simple convolution filter</b></font></p>
<p>The third graph in <a href="#Figure_37">Figure 37</a> shows the result of 
applying this convolution filter to the signal shown in the first graph.&nbsp; 
The convolution filter is shown in the second graph in <a name="Figure_37">
Figure 37</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ae02.jpg" width="409" height="583"><br></pre>
			<pre><b>Figure 37</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p><font color="#FF0000"><b>Think color again</b></font></p>
<p>If we think of the signal in the first graph in <a href="#Figure_37">Figure 37</a> as representing the color values on a 
color plane in a 
single row of pixels in an image, this filter seems to have some promise.&nbsp; 
As we have come to expect, the impulse in the signal produces the impulse 
response of the filter in the output.&nbsp; The impulse in the input would represent a single 
bright spot.&nbsp; The impulse response in the output would represent a single bright spot with a black 
spot on each side.&nbsp; This confirms the symmetry that we are looking for.</p>
<p><font color="#FF0000"><b>The rectangular pulse</b></font></p>
<p>Now consider what the filter does to the rectangular pulse in the input.&nbsp; The main 
body of the output for the rectangular pulse is at about the same level as the 
general background level.&nbsp; Going from left to right into the pulse, we 
would see a black spot followed by a bright spot.&nbsp; While the bright spot in 
this case is 
not at the maximum level of brightness, it is still brighter than the general 
background and the main body of the rectangular pulse.</p>
<p>Going from left to 
right when leaving the pulse, we would see a bright spot followed by a black 
spot.&nbsp; These two spots are a mirror image of the two spots on the left side 
of the rectangular pulse.&nbsp; This combination of black and white spots should serve to 
identify the edges of the rectangular pulse feature in the input. </p>
<p><font color="#FF0000"><b>The triangular pulses</b></font></p>
<p>Now consider what the filter does to the triangular pulses.&nbsp; Here we can 
see that the filter produces a positive or negative spike in the output when the 
slope of the input changes.</p>
<blockquote>
	<p><i>(These spikes represent spots that are brighter or darker than the 
	general background.)</i></p>
</blockquote>
<p>The size of the spike is proportional to the amount of change in slope.&nbsp; 
The direction of the spike depends on the direction 
of the change in the slope.&nbsp; When the slope change rotates in a 
counter-clockwise direction, the direction of the spike is toward the negative.&nbsp; When the slope change 
rotates in a clockwise direction, the direction of the spike is toward the positive.&nbsp; This is pretty 
much what we expect for the second derivative of the signal.</p>
<p>Relating that information back to the rectangular pulse and the two spikes in the output at 
the beginning of the rectangular pulse, we see that the slope changes from zero to infinite 
in a counter-clockwise direction, and then changes from infinite to zero again in 
a clockwise direction.&nbsp; This all occurs within two samples.&nbsp; Therefore, the spikes are 
adjacent to one another, they are large, and they have consistent directions.</p>
<p><font color="#FF0000"><b>Edges are determined by a change in slope</b></font></p>
<p>The edges of the features in an image are defined by changes in the slope of 
the surface that defines the image.&nbsp; Therefore, if we can identify the 
changes in the slope of the surface, we can identify the edges.&nbsp; On that 
basis, it looks 
like this filter should do the job.</p>
<p><font color="#FF0000"><b>A high-pass filter</b></font></p>
<p>Before leaving the discussion of <a href="#Figure_37">Figure 37</a>, we should point out that this is 
a high-pass filter as evidenced by the frequency response shown in the fifth 
graph in <a href="#Figure_37">Figure 37</a>.</p>
<p><font color="#FF0000"><b>Apply the filter to a real image</b></font></p>
<p><a name="Figure_38">Figure 38</a> shows this three-point filter <i>(Filter08.txt)</i> 
along with the wave number response of the filter in the same format as before.</p>
<p></p>
<table border="1" bgcolor="#ccffff">
	<tr>
		<td><img border="0" src="java412ae03.jpg" width="137" height="180"></td>
		<td><img border="0" src="java412ae04.jpg" width="137" height="180"></td>
	</tr>
	<tr>
		<td colspan="2" >
		<pre><b>Figure 38</b></pre></td>
	</tr>
</table>
<p>By now, you will recognize that 
this filter will have maximum impact on edges that are parallel to the red 
bands, and no impact whatsoever on edges that are perpendicular to the red 
bands.</p>
<p><font color="#FF0000"><b>Compare with the embossing filter</b></font></p>
<p>If you compare the wave number response of this filter with the wave number 
response of the embossing filter shown in <a href="#Figure_23">Figure 23</a>, you will see that the red/white 
pass bands 
for this filter are somewhat narrower and the black/blue reject band is somewhat 
wider than the pass bands and the reject band in <a href="#Figure_23">Figure 23</a>.&nbsp; You can also 
see this in the fifth graph of <a href="#Figure_37">Figure 37</a> as compared to the fifth graph of <a href="#Figure_22">Figure 22</a>.</p>
<p><font color="#FF0000"><b>Results with a real but simple image</b></font></p>
<p><a name="Figure_39">Figure 39</a> shows the result of applying this filter to an enlarged image 
<i>(stickman2b.gif)</i> of the Stick Man and multiplying all of the color values 
in the output by a factor of 2.0.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ae05.jpg" width="218" height="554"><br></pre>
			<pre><b>Figure 39</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<blockquote>
	<p><i>(This image of the Stick Man was enlarged by a factor of two 
	relative to the original image (stickman2a.gif) without redrawing the image.&nbsp; 
	As a result, this Stick Man suffers from a bad case if the jaggies on the 
	sloping lines.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Comparison with Figure 37</b></font></p>
<p>Let's compare <a href="#Figure_39">Figure 39</a> with the signal in <a href="#Figure_37">Figure 37</a>.&nbsp; For every row of this 
image, all of the color values are either 0 or some very large value.&nbsp; For 
example, the intersection of the row with the Stick Man's neck is very similar 
to the rectangular pulse in the first graph in <a href="#Figure_37">Figure 37</a>.&nbsp; <i>(However, the 
baseline for the signal in <a href="#Figure_37">Figure 37</a> is a little above zero.)</i> Therefore, we 
would expect the output for that row in this image to be very similar to the 
output for the rectangular pulse shown in <a href="#Figure_37">Figure 37</a>.</p>
<p>If that is our expectation, we won't be disappointed.&nbsp; If you examine the neck 
portion of the output very 
carefully, you will see that there are black and white vertical lines on the left 
side of the neck.&nbsp; Similarly, there are white and black vertical lines on the right 
side of the neck as a mirror image of the left side.&nbsp; The inner portion of 
the neck is essentially the same color as the general background as is the case 
in the output for the rectangular pulse in <a href="#Figure_37">Figure 37</a>.</p>
<p>All of the features in the Stick Man image consist of rectangular pulses when 
viewed as a single row of pixels.&nbsp; There are no triangular pulses or 
impulses.</p>
<p><font color="#FF0000"><b>Vertical is good, horizontal is not so good</b></font></p>
<p>As you probably predicted, this filter does a reasonably good job of 
identifying the vertical edges in the Stick Man image, and does a rather poor job of identifying the 
edges that are nearly horizontal, such as the forearms.&nbsp; </p>
<blockquote>
	<p><i>(For example, there are 
horizontal edges on the stair steps that make up all of the sloping lines, and 
those horizontal edges aren't identified at all.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Upgrade the filter</b></font></p>
<p>Now let's try upgrading the filter to get better results for horizontal 
edges.&nbsp; We will begin by expanding the filter from a 1x3 filter to a 3x3 
filter using the filter coefficient values shown in <a name="Figure_40">Figure 40</a>.</p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><b> 0.0 -0.25 0.0
-0.25 1.0 -0.25
 0.0 -0.25 0.0</b><br></pre>
			<pre><b>Figure 40</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>Note that the four corner values in <a href="#Figure_40">Figure 40</a> are 0.0.&nbsp; Therefore, as a 
practical matter, this filter has only five coefficients.</p>
<p>Note also that the sum of all of the coefficients in this filter <i>(Filter11.txt)
</i>is zero, ensuring that the wave number response will be zero at a wave 
number of zero.</p>
<p><font color="#FF0000"><b>The filter and the wave number response</b></font></p>
<p><a name="Figure_41">Figure 41</a> shows the filter and the wave number 
response of the filter in the same format as before.</p>
<p></p>
<table border="1" bgcolor="#ccffff">
	<tr>
		<td><img border="0" src="java412ae06.jpg" width="137" height="180"></td>
		<td><img border="0" src="java412ae07.jpg" width="137" height="180"></td>
	</tr>
	<tr>
		<td colspan="2" >
		<pre><b>Figure 41</b></pre></td>
	</tr>
</table>
<p>The wave number response tells 
us that the filter should provide wider angular coverage for the edges than was 
the case with the filter shown in <a href="#Figure_38">Figure 38</a>.&nbsp; In other words, we should 
expect equal treatment of both horizontal and vertical edges in the image.</p>
<p><font color="#FF0000"><b>Apply the filter to the Stick Man</b></font></p>
<p><a name="Figure_42">Figure 42</a> shows the result of applying this filter <i>(Filter11.txt)</i> to 
the same Stick Man image <i>(stickman2b.gif</i>)<i> </i>and multiplying all of 
the color values in the output by a factor of 5.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ae08.jpg" width="218" height="554"><br></pre>
			<pre><b>Figure 42</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p><font color="#FF0000"><b>Better in some ways, worse in others</b></font></p>
<p>When compared with <a href="#Figure_39">Figure 39</a>, this filter provides much better performance on 
the nearly horizontal surfaces such as the forearms.&nbsp; However, the overall 
contrast between the background and the white lines that identify the edges 
doesn't seem to be as good in <a href="#Figure_42">Figure 42</a> as in
<a href="#Figure_39">Figure 39</a>.</p>
<p><font color="#FF0000"><b>Gaps in the wave number response</b></font></p>
<p>An examination of the wave number response in <a href="#Figure_41">Figure 41</a> indicates that we 
might be able to improve on this filter.&nbsp; One problem with the filter, as 
evidenced by the wave number response in <a href="#Figure_41">Figure 41</a>, is the lack of a red 
pass band in the 
North, South, East, and West directions.&nbsp; It might be good if we can get 
more red coverage in the high wave number areas around the entire perimeter of the 
plot.</p>
<p><font color="#FF0000"><b>Use a true nine-point filter</b></font></p>
<p>We might be able accomplish this by filling in the four filter coefficients 
that have values of zero in <a href="#Figure_40">Figure 40</a>.&nbsp; We will see what we can accomplish with the 
filter <i>(Filter12.txt)</i> shown in <a name="Figure_43">Figure 43</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><b>-0.125 -0.125 -0.125
-0.125  1.0   -0.125
-0.125 -0.125 -0.125</b><br></pre>
			<pre><b>Figure 43</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>Once again, note that the sum of the filter coefficients is zero for the 
reasons given earlier.</p>
<p><font color="#FF0000"><b>The filter and the wave number response</b></font></p>
<p><a name="Figure_44">Figure 44</a> shows this filter <i>(Filter12.txt)</i> and the wave number 
response of the filter in the same format as before.</p>
<p></p>
<table border="1" bgcolor="#ccffff">
	<tr>
		<td><img border="0" src="java412ae09.jpg" width="137" height="177"></td>
		<td><img border="0" src="java412ae10.jpg" width="137" height="180"></td>
	</tr>
	<tr>
		<td colspan="2" >
		<pre><b>Figure 44</b></pre></td>
	</tr>
</table>
<p>It appears from <a href="#Figure_44">Figure 44</a> that 
we met our objective of getting better red pass band coverage around the 
perimeter of the wave number response than was the case for the filter shown in 
<a href="#Figure_41">Figure 41</a>.&nbsp; It remains to be seen if this will result in an improvement in 
edge detection performance.</p>
<p><font color="#FF0000"><b>Apply the filter to the Stick Man</b></font></p>
<p><a name="Figure_45">Figure 45</a> shows the result of applying this filter <i>(Filter12.txt)</i> to 
the same enlarged Stick Man image <i>(stickman2b.gif)</i> and multiplying all of 
the color values in the output by a factor of 5.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ae11.jpg" width="218" height="554"><br></pre>
			<pre><b>Figure 45</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>I will let you be the judge as to whether or not <a href="#Figure_45">Figure 45</a> is an improvement 
over <a href="#Figure_42">Figure 42</a>, but it looks to me like the contrast is a little better 
in <a href="#Figure_45">Figure 45</a>.</p>
<p><font color="#FF0000"><b>Apply the filter to a photographic image</b></font></p>
<p>Real photographic images aren't 
normally made up of surfaces that contain rectangular towers or even pyramids 
for that matter.&nbsp; Rather, the changes in slope in the surface that 
represents the image are usually less pronounced than is the case with the Stick 
Man image.&nbsp; By comparing the output for the triangular pulses to the output 
for the rectangular pulse in <a href="#Figure_37">Figure 37</a>, we can predict that the results for real 
photographic images won't be as good as for the Stick Man image.</p>
<p><font color="#FF0000"><b>A little bit of black art</b></font></p>
<p>Also, because of the limited dynamic range of the values used to represent color 
values in images, and the requirement to transform all convolution output values back into the 
range from 0 through 255 inclusive, scaling in the image convolution process is 
something of a black art.&nbsp; If I simply apply the filter whose coefficient 
values are shown in <a href="#Figure_43">Figure 43</a> to the starfish image shown in the top panel of 
<a href="#Figure_34">Figure 34</a>, the results are not usable.&nbsp; There are no scale factors that I can 
apply to the output from the convolution process using the interactive control panel shown in 
<a href="#Figure_4">Figure 4</a> that will bring out 
the edges.</p>
<p><font color="#FF0000"><b>A new filter with larger coefficient values</b></font></p>
<p>However, if I create a new filter <i>(Filter13.txt)</i> in which I simply 
multiply all of the coefficient values from <a href="#Figure_40">Figure 40</a> by a factor of 80, producing the filter 
coefficient values shown in <a name="Figure_46">Figure 46</a>, the results of the convolution are close to what we are 
looking for.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><b>-10.0 -10.0 -10.0
-10.0  80.0 -10.0
-10.0 -10.0 -10.0</b><br></pre>
			<pre><b>Figure 46</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<blockquote>
	<p><i>(Note that multiplying every coefficient in a convolution filter does 
	not change the basic shape of the wave number response.&nbsp; It simply 
	scales the values in the wave number domain by the same multiplicative 
	factor.&nbsp; Therefore, there is no point in showing you another picture of 
	the wave number response for the new filter.&nbsp; It looks just like the wave number response 
	in <a href="#Figure_44">Figure 44</a>.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Apply the filter to the starfish image</b></font></p>
<p><a name="Figure_47">Figure 47</a> shows the result of applying this filter <i>(Filter13.txt)</i> to 
the starfish image <i>(background02.gif)</i> and multiplying all of the color 
values by a factor of 1.3 following the convolution process.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ae12.jpg" width="310" height="476"><br></pre>
			<pre><b>Figure 47</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>Many, but not all of the edges in the original photograph show up in the processed image.&nbsp; 
Note however that because we used a symmetrical convolution filter, the image in 
<a href="#Figure_47">Figure 47</a> doesn't exhibit the 3D-like quality that is apparent in  
<a href="#Figure_34">Figure 34</a>.</p>
<blockquote>
	<p><i>(Later, in <a href="#Figure_59">Figure 59</a>, I will show you another 
	result that was produced by applying the same filter to the same image but 
	using a different normalization scheme to convert the convolution output 
	values back into the required eight-bit unsigned format.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Two different kinds of filters</b></font></p>
<p>The embossing filter used for  
<a href="#Figure_34">Figure 34</a> and the edge detection filter used 
for <a href="#Figure_47">Figure 47</a> are fundamentally two different kinds of filters.</p>
<p>The embossing filter 
used to produce  
<a href="#Figure_34">Figure 34</a> generates an output that is roughly proportional the slope of the 
surface that describes the image.&nbsp; Positive slopes produce positive values 
and negative slopes produce negative values.&nbsp; On the other hand, the edge detection filter used to 
produce <a href="#Figure_47">Figure 47</a> generates an output that is roughly proportional to the 
magnitude of <i>changes</i> in the slope of 
the surface rather than being proportional to the slope itself.</p>
<p>The embossing filter estimates the first derivative of the surface.</p>
<p>The 
edge detection filter estimates the second derivative of the surface.</p>
<blockquote>
	<p><i>(The smoothing filter from an earlier section, by the way, 
estimates the integral of the surface.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Improvements to the edge detection filter</b></font></p>
<p>There are probably other things that can be done to improve the edge 
detection results, such as applying some sort of a threshold, for example.&nbsp; 
I encourage you to experiment and see if you can find a way to do a better job 
of edge detection.</p>
<h4 align="center"><a name="Sharpening_filters">Sharpening filters</a></h4>
<p>Sharpening filters are used to process a photographic image to make it 
more crisp.&nbsp; Let me begin by quoting
<a href="http://users.wfu.edu/bennettk/sharp.html">Ken Bennett, Wake Forest 
University Photographer</a>.</p>
<blockquote>
	<p><i>&quot;All digital images need to be sharpened. This is not related to the 
	'sharpness' of film images -- I'm assuming that you used a sharp lens, 
	focused properly, and avoided camera and subject movement. Rather, we're 
	talking about the apparent softness of raw digital images, either from scans 
	or from digital images. We fix this by increasing edge contrast, making the 
	image appear sharper.&quot;</i></p>
</blockquote>
<p>I will assume that Mr. Bennett is correct in his assessment.&nbsp; My 
objective here is to help you to understand how to sharpen, and not why to 
sharpen.</p>
<p>You will find a very good example of using convolution to sharpen a photographic image of an 
automobile at
<a href="http://www.gamedev.net/reference/programming/features/imageproc/page2.asp">gamedev.net</a>.</p>
<p><font color="#FF0000"><b>Different sharpening techniques are available</b></font></p>
<p>Although there are different techniques used for sharpening digital 
photographs, from what I read, most of them involve enhancing the higher wave 
number components relative to the lower wave number components in the image.&nbsp; 
To do that with a convolution filter, we need a high-pass filter.&nbsp; Many of 
the sharpening filters that I have read about seem to use bipolar 2D convolution 
filters where all of the coefficients add up to a value of 1.0.</p>
<blockquote>
	<p><i>(This means that the wave number response of the filter is 1.0 at a 
	wave number of zero.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Important constraints</b></font></p>
<p>Unlike with the embossing filter and the edge detection filter, we 
are faced with some important constraints.&nbsp; Perhaps the most important 
constraint is that we usually don't want to change the color of the image 
in any significant way.</p>
<blockquote>
	<p><i>(This means that we must control the mean and the standard deviation 
	of the color values in the output image relative to the input image.&nbsp; 
	See the earlier lesson entitled
	<a href="http://www.developer.com/java/other/article.php/3441391">Processing 
	Image Pixels Using Java: Controlling Contrast and Brightness</a> for a 
	discussion of the impact of changing the distribution of color values in an 
	image. )</i></p>
</blockquote>
<p>If we are going to use a high-pass 
filter, it should probably be almost flat with only a hint of emphasis at the 
high end of the wave number spectrum.&nbsp; Otherwise, it will act like an edge 
detection filter or a 3D embossing filter.</p>
<p><font color="#FF0000"><b>How do I design such as filter?</b></font></p>
<p>Once again, let's take a trial-and-error approach using the
<a href="http://sepwww.stanford.edu/oldsep/hale/FftLab.html">FFT Laboratory</a> 
page.&nbsp; Go to that page and check the box labeled <i>Origin Centered</i>.&nbsp; Then go to the 
upper-left box and drag the two black dots on each side of the center down about 
to about one-fifth of their maximum.&nbsp; Make sure that you drag both dots 
down the same distance.&nbsp; <i>(The curve in the bottom right box should be 
flat at zero after you do that.)</i></p>
<p><font color="#FF0000"><b>Note the shape of the response</b></font></p>
<p>Note the shape of the curve in the bottom left box, keeping in mind that the 
empty circle represents a frequency of zero.&nbsp; At this point, the magnitude 
of the response 
at a frequency of zero is large.&nbsp; The sign of the response at zero 
frequency is negative.&nbsp; The response at the Nyquist 
folding frequency is high also, and is positive.&nbsp; The curve is nowhere near being flat.</p>
<p><font color="#FF0000"><b>Adjust the response at a frequency of zero</b></font></p>
<p>Now grab the empty circle in the upper-left box and start pulling it up toward 
the top of the screen.&nbsp; Move it a little at a time and turn it loose 
between moves.&nbsp; Observe what happens to the curve in the bottom-left box as 
you do that.&nbsp; You should see the value at zero frequency in the bottom-left 
box moving upward.</p>
<p>Continue this process until the curve in the 
bottom-left box is almost flat, but with the value at zero frequency being a 
little lower than the value at the folding frequency.&nbsp; You can use this 
trial-and-error technique to design a symmetrical three-point high-pass filter 
having the degree of flatness that you desire.&nbsp; Then estimate the relative 
sizes of the three weights in the top-left box.&nbsp; Those three weights are the 
coefficient values for your sharpening filter.</p>
<p><font color="#FF0000"><b>A one-dimensional example</b></font></p>
<p>Let's see what we get using a three-point filter having the following values:</p>
<p><font face="Arial Narrow"><b>-0.333333 1.666666 -0.333333</b></font></p>
<blockquote>
	<p><i>(Note that the sum of the coefficients for this filter is 1.0.&nbsp; That 
means that the filter has a response of 1.0 at a frequency of zero.)</i></p>
</blockquote>
<p>The frequency response of this filter is shown in the fifth graph in 
<a href="#Figure_48">Figure 
48</a>.&nbsp; The third graph in <a href="#Figure_48">Figure 
48</a> shows the result of applying this filter to our 
standard signal, which is shown in the first graph in <a href="#Figure_48">Figure 
48</a>.&nbsp; The filter itself is shown in the second graph in 
<a name="Figure_48">Figure 48</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412af01.jpg" width="409" height="602"><br></pre>
			<pre><b>Figure 48</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p><font color="#FF0000"><b>Approximate the filter interactively</b></font></p>
<p>If you approximate this filter on the
<a href="http://sepwww.stanford.edu/oldsep/hale/FftLab.html">FFT Laboratory</a> 
page, you will see what the frequency response of this filter looks like on a linear scale,
<i>(as opposed 
to the decibel scale shown in the fifth graph in <a href="#Figure_48">Figure 
48</a>)</i>.</p>
<p><font color="#FF0000"><b>A high-pass filter</b></font></p>
<p>This is a relatively soft high-pass filter, which produces a little blip in 
the output each time the slope of the signal changes. The size of the blip is 
roughly proportional to the rate of change of the slope of the signal.</p>
<p>If we think of the signal values in <a href="#Figure_48">Figure 
48</a> as representing the color 
values in a single row of pixels in a color plane in an image, we see 
that this filter should do a reasonably good job of preserving the color values.</p>
<blockquote>
	<p><i>(However, we do see that the distance between the baseline and the 
	flat portion of the rectangular pulse in the output is less than it is in 
	the input.&nbsp; We also see that the general background is higher in the 
	output than it is in the input.&nbsp; These characteristics suggest that there is some 
	compression of the color distribution, and that the general background in the 
	output will be brighter than the input.)</i></p>
</blockquote>
<p>As mentioned above, a little blip will be produced in the output color 
values each time the slope of the surface that describes the color plane 
changes.&nbsp; We would think that these little blips might cause the changes in 
slope to be highlighted and to cause the image to become a little more crisp.</p>
<p><font color="#FF0000"><b>A 2D sharpening filter</b></font></p>
<p>Unfortunately, none of the 2D sharpening filters that I have found on various 
web sites and in various books seem to work properly when applied using the 
normalization algorithm in the class named <b>ImgMod32</b>.&nbsp; For example, I am going to show you 
the results of applying the 2D convolution filter shown in <a name="Figure_49">Figure 49</a>.&nbsp; This 
is one of the sharpening filters recommended at
<a href="http://www.gamedev.net/reference/programming/features/imageproc/page2.asp">gamedev.net</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><b>-1.0 -1.0 -1.0
-1.0  9.0 -1.0
-1.0 -1.0 -1.0</b><br></pre>
			<pre><b>Figure 49</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p><font color="#FF0000"><b>Apply the filter to a photograph</b></font></p>
<p><a name="Figure_50">Figure 50</a> shows the result of applying the filter <i>(Filter14.txt)</i> shown in 
<a href="#Figure_49">Figure 49</a> to the starfish image 
<i>(background02.gif)</i>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412af02.jpg" width="310" height="476"><br></pre>
			<pre><b>Figure 50</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p><font color="#FF0000"><b>What happened to the color?</b></font></p>
<p>The results shown in <a href="#Figure_50">Figure 50</a> certainly don't look anything like the results 
shown for the image of the automobile at
<a href="http://www.gamedev.net/reference/programming/features/imageproc/page2.asp">gamedev.net</a>.&nbsp; The big question is, why not?</p>
<p>I strongly suspect that the problem has something to do with the way the 
class named <b>ImgMod32</b> treats the bipolar convolution results at the point where it is 
necessary to convert those results back into eight-bit unsigned color values in 
the range from 0 to 255 inclusive.</p>
<p><font color="#FF0000"><b><a name="The_normalization_scheme_for_ImgMod32">The 
normalization scheme for ImgMod32</a></b></font></p>
<p>The normalization scheme in the class named <b>ImgMod32</b> causes the mean value of the output to match 
the mean value of the input.&nbsp; So far, so good.&nbsp; Then if there are any negative values 
remaining, all of the values are biased upward so as to cause the minimum value to be 
zero.&nbsp; In effect, this causes all of the colors to become brighter when it 
occurs.</p>
<p>After that, if there are any values greater than 255, all of the 
values are scaled down to force the maximum value to be 255.&nbsp; While this 
approach seems logical, it may not be the best approach.&nbsp; This last step 
may compress the color distribution.&nbsp; For example, a 
single large positive or negative value would cause all of the color values to 
be compressed into a narrower distribution.&nbsp; This, in turn, would cause the 
colors to appear to be somewhat washed out.</p>
<blockquote>
	<p><i>(By the way, I haven't found any hints in any books or on any websites 
indicating how others perform this normalization, so I'm flying blind in this 
	area.)</i></p>
</blockquote>
<p><font color="#FF0000"><b>The color distribution</b></font></p>
<p>The results shown in <a href="#Figure_50">Figure 50</a> strongly suggest that the normalization 
process is reducing the width of the distribution of the color values.&nbsp; 
Recall that you learned in the earlier lesson entitled
<a href="http://www.developer.com/java/other/article.php/3441391">Processing 
Image Pixels Using Java: Controlling Contrast and Brightness</a>:</p>
<blockquote>
	<p><i>&quot;The contrast of an image is determined by the width of the 
	distribution of the color values belonging to the image.&nbsp; If all color 
	values are grouped together in a narrow distribution ... the details in the 
	image will tend to be washed out.&nbsp; In addition, the overall appearance of 
	the image may tend toward some shade of gray.&nbsp; The shade of gray will depend 
	on the location of the grouping between the extremes of 0 and 255.&quot;</i>
	</p>
</blockquote>
<p>That appears to be what is happening in <a href="#Figure_50">Figure 50</a>.&nbsp; The output image has 
lost contrast relative to the input image.&nbsp; Also, the output image is 
tending toward a shade of gray.</p>
<h3 align="center"><a name="An_alternative_normalization_scheme">An alternative 
normalization scheme</a></h3>
<p>At this point, I am going to switch from the use of the classes named <b>ImgMod33</b> 
and <b>ImgMod32</b> to the classes named <b>ImgMod33a</b> and <b>ImgMod32a</b>.</p>
<p>The normalization scheme used in <b>ImgMod32a</b> is significantly different 
from the normalization scheme used in <b>ImgMod32</b>.</p>
<p>The class named <b>ImgMod33a</b> is the same as the class named <b>ImgMod33</b> 
except that it uses <b>ImgMod32a</b> for convolution instead of using <b>ImgMod32</b>.</p>
<p><font color="#FF0000"><b><a name="Normalization_in_ImgMod32a">Normalization in ImgMod32a</a></b></font></p>
<p>As before, this normalization process guarantees that the final color values 
on all three color planes have values between 0 and 255 inclusive.&nbsp; As 
before, this scheme causes the mean value of the convolution output to match the 
mean value of the input on each color plane.&nbsp; However, this scheme also 
causes the <a href="http://en.wikipedia.org/wiki/Root_mean_square">root mean square</a>
<i>(RMS)</i> value of the color values in the output 
to match the RMS values of the input on each color plane.&nbsp; </p>
<blockquote>
	<p><i>(The RMS value is 
a measure of the width of the color distribution.)</i></p>
</blockquote>
<p>Thus, the scheme 
attempts to cause the width of the output color distribution to match the width 
of the input color distribution on each color plane.&nbsp; As you learned in the 
earlier lesson entitled
<a href="http://www.developer.com/java/other/article.php/3441391">Processing 
Image Pixels Using Java: Controlling Contrast and Brightness</a> this should go 
a long way toward preventing the colors from becoming <i>washed out</i> as in 
<a href="#Figure_50">Figure 50</a>.</p>
<h4 align="center"><a name="Back_to_the_sharpening_filter">Back to the 
sharpening filter</a></h4>
<p><a href="#Figure_51">Figure 51</a> shows the result of applying the sharpening filter <i>(Filter14.txt)</i> shown 
in <a href="#Figure_48">Figure 
48</a> to the starfish image <i>(background02.gif)</i>.&nbsp; This is the 
same process that was used to produce <a href="#Figure_50">Figure 50</a>, except that the normalization 
scheme used in <b>ImgMod32a</b> was used to produce <a name="Figure_51">Figure 
51</a>.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ag01.jpg" width="310" height="476"><br></pre>
			<pre><b>Figure 51</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>For the record, <a href="#Figure_51">Figure 51</a> was produced by executing the following command at 
the command prompt and specifying the filter file named Filter14.txt at the 
interactive control panel <i>(see <a href="#Figure_4">Figure 4</a>)</i>:</p>
<p><font face="Arial Narrow"><b>java ImgMod02a ImgMod33a background02.gif</b></font></p>
<p>No scaling was applied to the output at the interactive control panel.</p>
<p><font color="#FF0000"><b>Now, that's more like it</b></font></p>
<p>If you compare <a href="#Figure_51">Figure 51</a> with <a href="#Figure_50">Figure 50</a>, you will probably agree that 
<a href="#Figure_51">Figure 51</a> is closer to what we would like to see in a sharpening filter.&nbsp; Thus, 
the normalization scheme used in <b>ImgMod32a</b> may be more appropriate than the 
normalization scheme used in <b>ImgMod32</b> for sharpening photographic images.</p>
<p>The sharpening filter definitely brought out the detail in the bottom image 
of <a href="#Figure_51">Figure 51</a> as compared to the top image in 
<a href="#Figure_51">Figure 51</a>.&nbsp; For example, note 
the nearly horizontal lines in the large fish's tail and the detail showing in 
the seaweed at the bottom of the image in the bottom panel.&nbsp; The lines in 
the fish's tail can barely be seen in the original image at the top.&nbsp; The 
seaweed is much more blurred in the original image at the top.</p>
<p>From an aesthetic viewpoint, this particular sharpening filter may have brought out a little too 
much detail.&nbsp; It seems also to have brought out some noise in the 
background and the image seems to be a little harsh.&nbsp; We'll see the results 
produced by a somewhat softer sharpening filter shortly.</p>
<p><font color="#FF0000"><b>The mean and RMS values</b></font></p>
<p>Just in case you are interested, the input and output mean and RMS values 
for <a href="#Figure_51">Figure 51</a> are shown in <a name="Figure_52">Figure 52</a>.</p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><b>Input red mean: 73.35973143759874
Input green mean: 106.97551342812007
Input blue mean: 104.57263823064771
Input red RMS: 45.37941846420423
Input green RMS: 29.99973250165733
Input blue RMS: 27.389329517109754
Output red RMS: 45.37941846420752
Output green RMS: 29.999732501659715
Output blue RMS: 27.38932951711031
Output red mean: 73.35973143760023
Output green mean: 106.97551342812181
Output blue mean: 104.57263823065891</b><br></pre>
			<pre><b>Figure 52</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p><font color="#FF0000"><b>A softer sharpening filter</b></font></p>
<p>Now let's take a look at the results produced by a 2D convolution filter <i>(Filter15.txt)</i> 
having the coefficient values shown in <a name="Figure_53">Figure 53</a>.</p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><b>-0.25 -0.25 -0.25
-0.25   3.0 -0.25
-0.25 -0.25 -0.25</b><br></pre>
			<pre><b>Figure 53</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>Note that as before, the sum of the filter coefficients adds up to 1.0.&nbsp; 
However, each of the eight negative values in this filter is only 8.3-percent of 
the central value of 3.0 whereas each of the negative values in 
<a href="#Figure_48">Figure 
48</a> is 
11.1-percent of the central value of 9.0.&nbsp; As a result, the 2D filter 
surface represented by <a href="#Figure_53">Figure 53</a> is flatter than the filter surface represented 
by <a href="#Figure_48">Figure 
48</a>.</p>
<p><font color="#FF0000"><b>Apply to the starfish image</b></font></p>
<p><a name="Figure_54">Figure 54</a> shows the result of applying the sharpening filter 
<i>(Filter15.txt)</i> to the starfish image 
<i>(background02.gif)</i> without 
performing any scaling on the output of the convolution process.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ag02.jpg" width="310" height="475"><br></pre>
			<pre><b>Figure 54</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>As you can see, the bottom image in <a href="#Figure_54">Figure 54</a> is sharper and crisper than the 
top image, with the bottom image showing more detail.&nbsp; Once again, compare 
the nearly horizontal lines in the large fish's tail and the seaweed between the two 
images.&nbsp; However, the bottom image in <a href="#Figure_54">Figure 54</a> is softer than the bottom 
image in <a href="#Figure_51">Figure 51</a>.</p>
<p><font color="#FF0000"><b>Continue the softening process</b></font></p>
<p>We could continue this softening process by reducing the magnitude of the 
ratio of the negative values to the central positive value in
<a href="#Figure_54">Figure 54</a> <i>(being careful to ensure that the sum of the coefficient values is always 1.0)</i> 
until we reached the point where the negative values are reduced to zero.&nbsp; 
At that point, the convolution filter will have degenerated into a simple copy 
filter having only one non-zero coefficient.</p>
<p>I will leave further 
experimentation with sharpening filters as an exercise for you to carry out on 
your own.</p>
<p><font color="#FF0000"><b>Go back and reprocess earlier images</b></font></p>
<p>Now that we have a normalization scheme that seems to do a pretty good job 
when used with sharpening filters on photographic images, let's go back and apply the same scheme 
to the other kinds of filters:</p>
<ul>
	<li>Smoothing or softening filters</li>
	<li>Bipolar filters
	<ul>
		<li>Embossing filters that produce a 3D-like effect</li>
		<li>Edge detection filters</li>
	</ul></li>
</ul>
<p>I will apply some of the same filters to the same images as before using the 
new normalization scheme so that we 
can compare the results of the two normalization schemes.</p>
<h4 align="center"><a name="Smoothing_or_softening_filters">Smoothing or 
softening filters</a></h4>
<p><a name="Figure_55">Figure 55</a> shows the result of applying the 4x4 smoothing filter from the file 
named Filter05.txt to the same image of the starfish.&nbsp; This is the same filter 
that was applied to the starfish image in 
<a href="#Figure_18">Figure 18</a> using the earlier 
normalization scheme.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ah01.jpg" width="310" height="476"><br></pre>
			<pre><b>Figure 55</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>There is very little difference between <a href="#Figure_55">Figure 55</a> and 
<a href="#Figure_18">Figure 18</a>, so the 
normalization scheme didn't seem to matter much for the smoothing operation.&nbsp; 
However, although it may be my imagination, it does appear to me that the color fidelity between input and output 
may be a little better in <a href="#Figure_55">Figure 55</a>.&nbsp; That should probably be 
expected given that the output in <a href="#Figure_55">Figure 55</a> has the same mean and 
the same RMS value as the 
input.</p>
<p><font color="#FF0000"><b>A rather severe smoothing filter</b></font></p>
<p><a href="#Figure_56">Figure 56</a> should be compared with <a href="#Figure_19">Figure 19</a>.&nbsp; Both of these figures show 
the result of applying the 10x10 smoothing filter from the file named Filter03 
to the image of the starfish.&nbsp; <a href="#Figure_19">Figure 19</a> was produced with the earlier 
normalization scheme.&nbsp; <a name="Figure_56">Figure 56</a> was produced with 
the later normalization scheme.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ah02.jpg" width="310" height="476"><br></pre>
			<pre><b>Figure 56</b></pre></td>
		</tr>
	</tbody>
</table>
<p>This time, I'm certain that it is not my imagination.&nbsp; The color 
fidelity from input to output is definitely better in <a href="#Figure_56">Figure 56</a> than in <a href="#Figure_19">Figure 19</a>.&nbsp; <i>(The starfish is too red in <a href="#Figure_19">Figure 19</a>.)</i>&nbsp; Recall that I mentioned 
the possibility of an undesirable <a href="#A_color_shift">color shift</a> when 
discussing <a href="#Figure_19">Figure 19</a> earlier.</p>
<h4 align="center"><a name="3D_embossing_filters">3D embossing filters</a></h4>
<p><a name="Figure_57">Figure 57</a> should be compared with  
<a href="#Figure_34">Figure 34</a>.&nbsp; 
The two figures show the 
result of applying the 3D embossing filter <i>(Filter02.txt)</i> to the starfish 
image using the two different normalization schemes.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ah03.jpg" width="310" height="476"><br></pre>
			<pre><b>Figure 57</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>The results in <a href="#Figure_57">Figure 57</a> are dramatically different 
from the results in  
<a href="#Figure_34">Figure 34</a>.&nbsp; In this case, the normalization scheme 
that maintained the width of the color distribution seems to have produced a 
more pronounced 3D effect.&nbsp; Many features, such as the small fish and the 
seaweed, that were faded out in  
<a href="#Figure_34">Figure 34</a> are clearly visible in <a href="#Figure_57">Figure 57</a>.</p>
<p><font color="#FF0000"><b>Moving the light source</b></font></p>
<p>While we are at this point, I want to show you something that I haven't shown you 
before.</p>
<p><a name="Figure_58">Figure 58</a> is the same as <a href="#Figure_57">Figure 57</a> with one major exception.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ah04.jpg" width="310" height="476"><br></pre>
			<pre><b>Figure 58</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>In <a href="#Figure_57">Figure 57</a>, the filter <i>(Filter02.txt)</i> was designed to produce a 3D 
optical illusion making it appear that the light source is above and to the left 
of the starfish.&nbsp; The filter <i>(Filter09.txt)</i> in <a href="#Figure_58">Figure 58</a> was 
designed to make it appear that the light source is above and to the right of 
the starfish.&nbsp; Both designs produce a very realistic embossed 3D optical 
illusion when used with the normalization scheme that maintains the width of the 
color distribution from input to output.</p>
<h4 align="center"><a name="Edge_detection_filter">Edge detection filter</a></h4>
<p><a name="Figure_59">Figure 59</a> should be compared with 
<a href="#Figure_47">Figure 47</a>.&nbsp; Both figures show the 
result of applying the edge detection filter <i>(Filter13.txt)</i> to the 
starfish image.</p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ah05.jpg" width="310" height="476"><br></pre>
			<pre><b>Figure 59</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p>The edge detection output shown in <a href="#Figure_59">Figure 59</a> is clearly superior 
to the output shown in <a href="#Figure_47">Figure 47</a>.&nbsp; Many edges, such as some of the small fish that 
are lost in <a href="#Figure_47">Figure 47</a> are identifiable in 
<a href="#Figure_59">Figure 59</a>. </p>
<p><font color="#FF0000"><b>And the verdict is...</b></font></p>
<p>For every case <i>(from <a href="#Figure_51">Figure 51</a> through 
<a href="#Figure_59">Figure 59</a>) </i>but one, where the 
filter was applied to the photographic image of the starfish, the normalization
<a href="#Normalization_in_ImgMod32a">scheme</a> implemented in the class named
<b>ImgMod32a</b> seems to be superior to the normalization
<a href="#The_normalization_scheme_for_ImgMod32">scheme</a> implemented in the class named
<b>ImgMod32</b>.&nbsp; The one exception was the case of a smoothing filter 
where the comparison was something of a toss up with the <b>ImgMod32a</b> scheme beating out 
the other scheme by a whisker.</p>
<p><font color="#FF0000"><b>On the other hand</b></font></p>
<p>However, had we evaluated the two schemes against a different image, we may 
have reached a different conclusion.&nbsp; For example, if you compare 
<a name="Figure_60">Figure 60</a> 
with <a href="#Figure_20">Figure 20</a>, you may conclude that the normalization scheme used for <a href="#Figure_20">Figure 20</a> 
was more successful in producing the 3D optical illusion in this case.</p>
<p></p>
<table border="1" cols="1" bgcolor="#ccffff">
	<tbody>
		<tr>
			<td>
			<pre><img border="0" src="java412ah06.jpg" width="113" height="116"><br></pre>
			<pre><b>Figure 60</b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<blockquote>
	<p><i>(<a href="#Figure_20">Figure 20</a> was produced using the normalization 
	<a href="#The_normalization_scheme_for_ImgMod32">scheme</a> in the class named
	<b>ImgMod32</b> and 
<a href="#Figure_60">Figure 60</a> was produced using the 
normalization <a href="#Normalization_in_ImgMod32a">scheme</a> in the class named
	<b>ImgMod32a.</b>)</i></p>
</blockquote>
<p><font color="#FF0000"><b>Why bother with two normalization schemes?</b></font></p>
<p>By now you may be wondering why I took the time and the effort to walk you 
through two different normalization schemes if I already knew that one was 
probably superior to the other.&nbsp; Mainly I wanted to impress on you that 
digital signal processing <i>(DSP)</i> involves much more than simply doing a 
lot of arithmetic.&nbsp; If all signals of interest were represented as 64-bit 
floating-point values, DSP may be reduced to that, but that is not how things 
usually turn out in the real world.&nbsp; DSP usually requires the user to make decisions based 
on knowledge of the context of the problem.</p>
<p><font color="#FF0000"><b>Historical footnote</b></font></p>
<p>During my DSP career <i>(which admittedly ended several years ago when I 
retired from the real world and became a college professor)</i>, I never had the 
luxury of working with 64-bit floating-point signal data.&nbsp; Virtually all of 
the real-world data that I worked with was quantized to many fewer than 64 bits.&nbsp; 
Typically the signals were quantized as integer values, usually in twelve to 
sixteen bits.&nbsp; For example, here is a
<a href="http://www.ee.washington.edu/conselec/CE/kuhn/cdaudio2/95x7.htm">quotation</a> describing the sampled data format on an audio CD:</p>
<blockquote>
	<p><i>&quot;The original musical signal is a waveform in time. A sample of this 
	waveform in time is taken and &quot;digitized&quot; into two 16-bit words, one for the 
	left channel and one for the right channel.&quot;</i></p>
</blockquote>
<p><font color="#FF0000"><b>Integer arithmetic</b></font></p>
<p>In addition, many of the DSP arithmetic units that I was privileged to use 
were integer arithmetic units, making the possibility of arithmetic overflow a 
real possibility.&nbsp; Even when the arithmetic unit was a floating-point unit, 
it was almost always necessary to normalize the final results back into an 
integer format, as is the case with the color data values in this lesson.</p>
<p><font color="#FF0000"><b>A <i>safe</i> normalization scheme</b></font></p>
<p>I have described two normalization schemes in this lesson.&nbsp; The first 
<a href="#The_normalization_scheme_for_ImgMod32">scheme</a>, as implemented in the class named <b>ImgMod32</b>, 
is a <i>safe</i> 
scheme in that all of the information in the convolution output is re-quantized 
into the required eight-bit unsigned format.&nbsp; None of the data is 
discarded.&nbsp; The results are clearly more granular, but they are all 
there.</p>
<p>Unfortunately, this <i>safe</i> scheme doesn't always produce pleasing images 
when applied to photographs, because 
it can compress the width of the color distribution of the image, causing the 
image to have a &quot;washed out&quot; appearance.</p>
<p><font color="#FF0000"><b>An unsafe but aesthetically pleasing normalization 
scheme</b></font></p>
<p>The second <a href="#Normalization_in_ImgMod32a">scheme</a>, as implemented in the class named <b>ImgMod32a</b>, 
often produces more aesthetically pleasing results for the photographic data, but 
it is 
not a <i>safe</i> scheme.&nbsp; In particular, the process of clipping the final 
values at 0 and 255 is an <i>unsafe</i> nonlinear process.&nbsp; It is entirely 
possible that valuable information may be discarded in the clipping process.</p>
<p><font color="#FF0000"><b>No single &quot;right&quot; answer</b></font></p>
<p>As I indicated earlier, there is no single <i>right</i> answer to the 
questions regarding the normalization of the results.&nbsp; Normalization and 
re-quantization of data always involves tradeoffs among different alternatives 
within the context of the overall problem.</p>
<p>In the final analysis, the person responsible for the work must understand 
the technical ramifications of those alternatives and must make an informed decision as to 
which scheme or schemes among different alternative schemes will be used.</p>
<p><font color="#FF0000"><b>Conversion to a production program</b></font></p>
<p>If I were converting these classes to production software, I would probably 
give the user three additional options at the interactive control panel:</p>
<ul>
	<li>Accept the safe normalization discussed above as the default.</li>
	<li>Select the unsafe normalization discussed above.</li>
	<li>Perform normalization similar to the unsafe normalization discussed 
	above, but allow the user to specify the mean value and the RMS value of the 
	final output.</li>
</ul>
<h2 align="center"><a name="Program_Code">Program Code</a></h2>
<p>The code in the classes used to produce the experimental results shown above 
will be explained in Part 2 of this lesson.</p>
<p>For the benefit of those of you who might want to start working with that 
code now, you will find the source code for the classes in the section entitled
<a href="#Complete_Program_Listings">Complete Program Listings</a>.</p>
<h2 align="center"><a name="Summary">Summary</a></h2>
<p>This is Part 1 of a two-part lesson on image convolution.&nbsp; In this 
lesson, I have walked you through several experiments intended to help you understand why 
and how image convolution does what it does.&nbsp; I also showed you how to 
design and implement the following types of convolution filters:</p>
<ul>
	<li><a href="#A_simple_copy_filter">A simple copy filter</a></li>
	<li><a href="#A_smoothing_or_softening_filter">A smoothing or softening filter</a></li>
	<li><a href="#Bipolar_filters">Bipolar filters</a></li>
<ul>
      <li><a href="#Embossing_Filters_that_produce_a_3D-like_effect">Embossing filters that produce a 3D-like effect</a></li>
	  <li><a href="#Edge_detection_filters">Edge detection filters</a></li>
	  <li><a href="#Sharpening_filters">Sharpening filters</a></li>
</ul>
    </ul>
<h2 align="center"><a name="Whats Next">What's Next?</a></h2>
<p>In Part 2 of this lesson, I will explain the code in the classes used to perform 
the convolution experiments that were explained in this first part of the 
lesson.</p>
<h2 align="center"><a name="References">References</a></h2>
<p>In preparation for understanding the material in this lesson, I recommend 
that you study the material in the following previously-published lessons: </p>
<ul>
	<li><a href="http://www.dickbaldwin.com/dsp/Dsp00100.htm">100</a>&nbsp;&nbsp; Periodic 
Motion and Sinusoids</li>
	<li><a href="http://www.dickbaldwin.com/dsp/Dsp00104.htm">104</a>&nbsp;&nbsp; Sampled Time 
Series</li>
	<li><a href="http://www.dickbaldwin.com/dsp/Dsp00108.htm">108</a>&nbsp;&nbsp; Averaging 
Time Series</li>
	<li><a href="http://www.developer.com/java/other/article.php/3374611">1478</a> 
Fun with Java, How and Why Spectral Analysis Works</li>
	<li><a href="http://www.developer.com/java/other/article.php/3380031">1482</a> 
Spectrum Analysis using Java, Sampling Frequency, Folding Frequency, and the FFT 
Algorithm</li>
	<li><a href="http://www.developer.com/java/other/article.php/3392871">1483</a> 
Spectrum Analysis using Java, Frequency Resolution versus Data Length</li>
	<li><a href="http://www.developer.com/java/other/article.php/3411041">1484</a> 
Spectrum Analysis using Java, Complex Spectrum and Phase Angle</li>
	<li><a href="http://www.developer.com/java/other/article.php/3436341">1485</a> 
Spectrum Analysis using Java, Forward and Inverse Transforms, Filtering in the 
Frequency Domain</li>
	<li><a href="http://www.developer.com/java/other/article.php/3484591">1487</a> 
Convolution and Frequency Filtering in Java</li>
	<li><a href="http://www.developer.com/java/other/article.php/3487996">1488</a> 
Convolution and Matched Filtering in Java</li>
	<li><a href="http://www.developer.com/java/other/article.php/3508706">1489</a> 
Plotting 3D Surfaces using Java </li>
	<li><a href="http://www.developer.com/java/other/article.php/3519441">1490</a> 
2D Fourier Transforms using Java </li>
	<li><a href="http://www.developer.com/java/other/article.php/3526241">1491</a> 
2D Fourier Transforms using Java, Part 2 </li>
	<li><a href="http://www.developer.com/java/data/article.php/3529186">1492</a> 
Plotting Large Quantities of Data using Java</li>
	<li><a href="http://www.developer.com/java/other/article.php/3403921">400</a> 
Processing Image Pixels using Java, Getting Started</li>
	<li><a href="http://www.developer.com/java/other/article.php/3423661">402</a> 
Processing Image Pixels using Java, Creating a Spotlight</li>
	<li><a href="http://www.developer.com/java/other/article.php/3441391">404</a> 
Processing Image Pixels Using Java: Controlling Contrast and Brightness</li>
	<li><a href="http://www.developer.com/java/other/article.php/3512456">406</a> 
Processing Image Pixels, Color Intensity, Color Filtering, and Color Inversion</li>
	<li><a href="http://www.developer.com/java/other/article.php/3522711">408</a> 
Processing Image Pixels, Performing Convolution on Images</li>
	<li><a href="http://www.developer.com/java/other/article.php/3579206">410</a> Processing Image Pixels, Understanding Image Convolution in Java</li></li>
</ul>
<h2 align="center"><a name="Complete_Program_Listings">Complete Program Listings</a></h2>
<p>Complete listings of the programs discussed in this lesson are provided in this section.</p>
<p><font color="#FF0000"><b>A disclaimer</b></font></p>
<p>The programs that I am providing and explaining in this series of lessons are 
not intended to be used for high-volume production work.&nbsp; Numerous 
integrated image-processing programs are available for that purpose.&nbsp; In 
addition, the Java Advanced Imaging <i>(JAI)</i> API has a number of built-in special effects if you prefer to write 
your own production image-processing programs using Java.</p>
<p>The programs that I am providing in this series of lessons are intended to 
make it easier for you to develop and experiment with image-processing algorithms and 
to gain a better understanding of how they work, and why they do what they do.</p>
<table border="1" cols="1" width="482" bgcolor="#ffff00">
	<tbody>
		<tr>
			<td>
			<pre>/* File Graph08.java
Copyright 2005, R.G.Baldwin

This is an updated version of Graph03 to allow the user to
plot up to eight functions instead of only 5.

GraphIntfc08 is a corresponding update to the earlier
interface named GraphIntfc01.

Graph03 and GraphIntfc01 were explained in lesson 1488
entitled Convolution and Matched Filtering in Java.

This program is very similar to Graph01 except that it has
been modified to allow the user to manually resize and
replot the frame.

Note:&nbsp; This program requires access to the interface named
GraphIntfc08.

This is a plotting program.&nbsp; It is designed to access a
class file, which implements GraphIntfc08, and to plot up
to eight functions defined in that class file. The plotting
surface is divided into the required number of equally
sized plotting areas, and one function is plotted on
Cartesian coordinates in each area.

The methods corresponding to the functions are named f1,
f2, f3, f4, f5, f6, f7, and f8.

The class containing the functions must also define a
method named getNmbr(), which takes no parameters and
returns the number of functions to be plotted.&nbsp; If this
method returns a value greater than 8, a
NoSuchMethodException will be thrown.

Note that the constructor for the class that implements
GraphIntfc08 must not require any parameters due to the
use of the newInstance method of the Class class to
instantiate an object of that class.

If the number of functions is less than 8, then the absent
method names must begin with f8 and work down toward f1.&nbsp;
For example, if the number of functions is 3, then the
program will expect to call methods named f1, f2, and f3.
It is OK for the absent methods to be defined in the class.
They simply won't be invoked.&nbsp; In fact, because they are
declared in the interface, they must be defined as dummy
methods in the class that implements the interface.

The plotting areas have alternating white and gray
backgrounds to make them easy to separate visually.

All curves are plotted in black.&nbsp; A Cartesian coordinate
system with axes, tic marks, and labels is drawn in red
in each plotting area.

The Cartesian coordinate system in each plotting area has
the same horizontal and vertical scale, as well as the
same tic marks and labels on the axes.

The labels displayed on the axes, correspond to the values
of the extreme edges of the plotting area.

The program also compiles a sample class named junk, which
contains eight methods and the method named getNmbr.&nbsp; This
makes it easy to compile and test this program in a
stand-alone mode.

At runtime, the name of the class that implements the
GraphIntfc08 interface must be provided as a command-line
parameter.&nbsp; If this parameter is missing, the program
instantiates an object from the internal class named junk
and plots the data provided by that class.&nbsp; Thus, you can
test the program by running it with no command-line
parameter.

This program provides the following text fields for user
input, along with a button labeled Graph.&nbsp; This allows the
user to adjust the parameters and replot the graph as many
times with as many plotting scales as needed:

xMin = minimum x-axis value
xMax = maximum x-axis value
yMin = minimum y-axis value
yMax = maximum y-axis value
xTicInt = tic interval on x-axis
yTicInt = tic interval on y-axis
xCalcInc = calculation interval

The user can modify any of these parameters and then click
the Graph button to cause the eight functions to be
re-plotted according to the new parameters.

Whenever the Graph button is clicked, the event handler
instantiates a new object of the class that implements
the GraphIntfc08 interface.&nbsp; Depending on the nature of
that class, this may be redundant in some cases.&nbsp; However,
it is useful in those cases where it is necessary to
refresh the values of instance variables defined in the
class (such as a counter, for example).

This program uses constants that were first defined in the
Color class of v1.4.0.&nbsp; Therefore, the program requires
v1.4.0 or later to compile and run correctly.

Tested using J2SE 5.0 under WinXP.
**********************************************************/

import java.awt.*;
import java.awt.event.*;
import java.awt.geom.*;
import javax.swing.*;
import javax.swing.border.*;

class Graph08{
&nbsp; public static void main(String[] args)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; throws NoSuchMethodException,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ClassNotFoundException,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; InstantiationException,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; IllegalAccessException{
&nbsp;&nbsp;&nbsp; if(args.length == 1){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //pass command-line paramater
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; new GUI(args[0]);
&nbsp;&nbsp;&nbsp; }else{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //no command-line parameter given
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; new GUI(null);
&nbsp;&nbsp;&nbsp; }//end else
&nbsp; }// end main
}//end class Graph08 definition
//=======================================================//

class GUI extends JFrame implements ActionListener{

&nbsp; //Define plotting parameters and their default values.
&nbsp; double xMin = 0.0;
&nbsp; double xMax = 400.0;
&nbsp; double yMin = -100.0;
&nbsp; double yMax = 100.0;

&nbsp; //Tic mark intervals
&nbsp; double xTicInt = 20.0;
&nbsp; double yTicInt = 20.0;

&nbsp; //Tic mark lengths.&nbsp; If too small on x-axis, a default
&nbsp; // value is used later.
&nbsp; double xTicLen = (yMax-yMin)/50;
&nbsp; double yTicLen = (xMax-xMin)/50;

&nbsp; //Calculation interval along x-axis
&nbsp; double xCalcInc = 1.0;

&nbsp; //Text fields for plotting parameters
&nbsp; JTextField xMinTxt = new JTextField("" + xMin);
&nbsp; JTextField xMaxTxt = new JTextField("" + xMax);
&nbsp; JTextField yMinTxt = new JTextField("" + yMin);
&nbsp; JTextField yMaxTxt = new JTextField("" + yMax);
&nbsp; JTextField xTicIntTxt = new JTextField("" + xTicInt);
&nbsp; JTextField yTicIntTxt = new JTextField("" + yTicInt);
&nbsp; JTextField xCalcIncTxt = new JTextField("" + xCalcInc);

&nbsp; //Panels to contain a label and a text field
&nbsp; JPanel pan0 = new JPanel();
&nbsp; JPanel pan1 = new JPanel();
&nbsp; JPanel pan2 = new JPanel();
&nbsp; JPanel pan3 = new JPanel();
&nbsp; JPanel pan4 = new JPanel();
&nbsp; JPanel pan5 = new JPanel();
&nbsp; JPanel pan6 = new JPanel();

&nbsp; //Misc instance variables
&nbsp; int frmWidth = 408;
&nbsp; int frmHeight = 430;
&nbsp; int width;
&nbsp; int height;
&nbsp; int number;
&nbsp; GraphIntfc08 data;
&nbsp; String args = null;

&nbsp; //Plots are drawn on the canvases in this array.
&nbsp; Canvas[] canvases;

&nbsp; //Constructor
&nbsp; GUI(String args)throws NoSuchMethodException,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ClassNotFoundException,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; InstantiationException,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; IllegalAccessException{

&nbsp;&nbsp;&nbsp; if(args != null){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Save for use later in the ActionEvent handler
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; this.args = args;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Instantiate an object of the target class using the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // String name of the class.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; data = (GraphIntfc08)Class.forName(args).
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; newInstance();
&nbsp;&nbsp;&nbsp; }else{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Instantiate an object of the test class named junk.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; data = new junk();
&nbsp;&nbsp;&nbsp; }//end else

&nbsp;&nbsp;&nbsp; //Create array to hold correct number of Canvas
&nbsp;&nbsp;&nbsp; // objects.
&nbsp;&nbsp;&nbsp; canvases = new Canvas[data.getNmbr()];

&nbsp;&nbsp;&nbsp; //Throw exception if number of functions is greater
&nbsp;&nbsp;&nbsp; // than 8.
&nbsp;&nbsp;&nbsp; number = data.getNmbr();
&nbsp;&nbsp;&nbsp; if(number &gt; 8){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; throw new NoSuchMethodException(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Too many functions.&nbsp; "
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; + "Only 8 allowed.");
&nbsp;&nbsp;&nbsp; }//end if

&nbsp;&nbsp;&nbsp; //Create the control panel and give it a border for
&nbsp;&nbsp;&nbsp; // cosmetics.
&nbsp;&nbsp;&nbsp; JPanel ctlPnl = new JPanel();
&nbsp;&nbsp;&nbsp; ctlPnl.setLayout(new GridLayout(0,4));//?rows x 4 cols
&nbsp;&nbsp;&nbsp; ctlPnl.setBorder(new EtchedBorder());

&nbsp;&nbsp;&nbsp; //Button for replotting the graph
&nbsp;&nbsp;&nbsp; JButton graphBtn =new JButton("Graph");
&nbsp;&nbsp;&nbsp; graphBtn.addActionListener(this);

&nbsp;&nbsp;&nbsp; //Populate each panel with a label and a text field.
&nbsp;&nbsp;&nbsp; // Will place these panels in a grid on the control
&nbsp;&nbsp;&nbsp; // panel later.
&nbsp;&nbsp;&nbsp; pan0.add(new JLabel("xMin"));
&nbsp;&nbsp;&nbsp; pan0.add(xMinTxt);

&nbsp;&nbsp;&nbsp; pan1.add(new JLabel("xMax"));
&nbsp;&nbsp;&nbsp; pan1.add(xMaxTxt);

&nbsp;&nbsp;&nbsp; pan2.add(new JLabel("yMin"));
&nbsp;&nbsp;&nbsp; pan2.add(yMinTxt);

&nbsp;&nbsp;&nbsp; pan3.add(new JLabel("yMax"));
&nbsp;&nbsp;&nbsp; pan3.add(yMaxTxt);

&nbsp;&nbsp;&nbsp; pan4.add(new JLabel("xTicInt"));
&nbsp;&nbsp;&nbsp; pan4.add(xTicIntTxt);

&nbsp;&nbsp;&nbsp; pan5.add(new JLabel("yTicInt"));
&nbsp;&nbsp;&nbsp; pan5.add(yTicIntTxt);

&nbsp;&nbsp;&nbsp; pan6.add(new JLabel("xCalcInc"));
&nbsp;&nbsp;&nbsp; pan6.add(xCalcIncTxt);

&nbsp;&nbsp;&nbsp; //Add the populated panels and the button to the
&nbsp;&nbsp;&nbsp; // control panel with a grid layout.
&nbsp;&nbsp;&nbsp; ctlPnl.add(pan0);
&nbsp;&nbsp;&nbsp; ctlPnl.add(pan1);
&nbsp;&nbsp;&nbsp; ctlPnl.add(pan2);
&nbsp;&nbsp;&nbsp; ctlPnl.add(pan3);
&nbsp;&nbsp;&nbsp; ctlPnl.add(pan4);
&nbsp;&nbsp;&nbsp; ctlPnl.add(pan5);
&nbsp;&nbsp;&nbsp; ctlPnl.add(pan6);
&nbsp;&nbsp;&nbsp; ctlPnl.add(graphBtn);

&nbsp;&nbsp;&nbsp; //Create a panel to contain the Canvas objects.&nbsp; They
&nbsp;&nbsp;&nbsp; // will be displayed in a one-column grid.
&nbsp;&nbsp;&nbsp; JPanel canvasPanel = new JPanel();
&nbsp;&nbsp;&nbsp; canvasPanel.setLayout(new GridLayout(0,1));//?rows 1col

&nbsp;&nbsp;&nbsp; //Create a custom Canvas object for each function to
&nbsp;&nbsp;&nbsp; // be plotted and add them to the one-column grid.
&nbsp;&nbsp;&nbsp; // Make background colors alternate between white and
&nbsp;&nbsp;&nbsp; // gray.
&nbsp;&nbsp;&nbsp; for(int cnt = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cnt &lt; number; cnt++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; switch(cnt){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 0 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; canvases[cnt] = new MyCanvas(cnt);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; canvases[cnt].setBackground(Color.WHITE);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 1 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; canvases[cnt] = new MyCanvas(cnt);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; canvases[cnt].setBackground(Color.LIGHT_GRAY);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 2 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; canvases[cnt] = new MyCanvas(cnt);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; canvases[cnt].setBackground(Color.WHITE);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 3 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; canvases[cnt] = new MyCanvas(cnt);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; canvases[cnt].setBackground(Color.LIGHT_GRAY);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 4 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; canvases[cnt] = new MyCanvas(cnt);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; canvases[cnt]. setBackground(Color.WHITE);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 5 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; canvases[cnt] = new MyCanvas(cnt);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; canvases[cnt].setBackground(Color.LIGHT_GRAY);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 6 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; canvases[cnt] = new MyCanvas(cnt);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; canvases[cnt]. setBackground(Color.WHITE);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 7 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; canvases[cnt] = new MyCanvas(cnt);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; canvases[cnt].setBackground(Color.LIGHT_GRAY);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end switch
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Add the object to the grid.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; canvasPanel.add(canvases[cnt]);
&nbsp;&nbsp;&nbsp; }//end for loop

&nbsp;&nbsp;&nbsp; //Add the sub-assemblies to the frame.&nbsp; Set its
&nbsp;&nbsp;&nbsp; // location, size, and title, and make it visible.
&nbsp;&nbsp;&nbsp; getContentPane(). add(ctlPnl,"South");
&nbsp;&nbsp;&nbsp; getContentPane(). add(canvasPanel,"Center");

&nbsp;&nbsp;&nbsp; setBounds(0,0,frmWidth,frmHeight);

&nbsp;&nbsp;&nbsp; if(args == null){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; setTitle("Graph08, Copyright 2005, " +
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Richard G. Baldwin");
&nbsp;&nbsp;&nbsp; }else{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; setTitle("Graph08/" + args + " Copyright 2005, " +
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "R. G. Baldwin");
&nbsp;&nbsp;&nbsp; }//end else

&nbsp;&nbsp;&nbsp; setVisible(true);

&nbsp;&nbsp;&nbsp; //Set to exit on X-button click
&nbsp;&nbsp;&nbsp; setDefaultCloseOperation(EXIT_ON_CLOSE);

&nbsp;&nbsp;&nbsp; //Guarantee a repaint on startup.
&nbsp;&nbsp;&nbsp; for(int cnt = 0;cnt &lt; number; cnt++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; canvases[cnt].repaint();
&nbsp;&nbsp;&nbsp; }//end for loop

&nbsp; }//end constructor
&nbsp; //-----------------------------------------------------//

&nbsp; //This event handler is registered on the JButton to
&nbsp; // cause the functions to be replotted.
&nbsp; public void actionPerformed(ActionEvent evt){
&nbsp;&nbsp;&nbsp; //Re-instantiate the object that provides the data
&nbsp;&nbsp;&nbsp; try{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(args != null){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; data = (GraphIntfc08)Class.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; forName(args).newInstance();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }else{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; data = new junk();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end else
&nbsp;&nbsp;&nbsp; }catch(Exception e){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Known to be safe at this point. Otherwise would
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // have aborted earlier.
&nbsp;&nbsp;&nbsp; }//end catch

&nbsp;&nbsp;&nbsp; //Set plotting parameters using data from the text
&nbsp;&nbsp;&nbsp; // fields.
&nbsp;&nbsp;&nbsp; xMin = Double.parseDouble(xMinTxt.getText());
&nbsp;&nbsp;&nbsp; xMax = Double.parseDouble(xMaxTxt.getText());
&nbsp;&nbsp;&nbsp; yMin = Double.parseDouble(yMinTxt.getText());
&nbsp;&nbsp;&nbsp; yMax = Double.parseDouble(yMaxTxt.getText());
&nbsp;&nbsp;&nbsp; xTicInt = Double.parseDouble(xTicIntTxt.getText());
&nbsp;&nbsp;&nbsp; yTicInt = Double.parseDouble(yTicIntTxt.getText());
&nbsp;&nbsp;&nbsp; xCalcInc = Double.parseDouble(xCalcIncTxt.getText());

&nbsp;&nbsp;&nbsp; //Calculate new values for the length of the tic marks
&nbsp;&nbsp;&nbsp; // on the axes.&nbsp; If too small on x-axis, a default
&nbsp;&nbsp;&nbsp; // value is used later.
&nbsp;&nbsp;&nbsp; xTicLen = (yMax-yMin)/50;
&nbsp;&nbsp;&nbsp; yTicLen = (xMax-xMin)/50;

&nbsp;&nbsp;&nbsp; //Repaint the plotting areas
&nbsp;&nbsp;&nbsp; for(int cnt = 0;cnt &lt; number; cnt++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; canvases[cnt].repaint();
&nbsp;&nbsp;&nbsp; }//end for loop

&nbsp; }//end actionPerformed
&nbsp; //-----------------------------------------------------//


//This is an inner class, which is used to override the
// paint method on the plotting surface.
class MyCanvas extends Canvas{
&nbsp; int cnt;//object number
&nbsp; //Factors to convert from double values to integer pixel
&nbsp; // locations.
&nbsp; double xScale;
&nbsp; double yScale;

&nbsp; MyCanvas(int cnt){//save obj number
&nbsp;&nbsp;&nbsp; this.cnt = cnt;
&nbsp; }//end constructor

&nbsp; //Override the paint method
&nbsp; public void paint(Graphics g){

&nbsp;&nbsp;&nbsp; //Get and save the size of the plotting surface
&nbsp;&nbsp;&nbsp; width = canvases[0].getWidth();
&nbsp;&nbsp;&nbsp; height = canvases[0].getHeight();

&nbsp;&nbsp;&nbsp; //Calculate the scale factors
&nbsp;&nbsp;&nbsp; xScale = width/(xMax-xMin);
&nbsp;&nbsp;&nbsp; yScale = height/(yMax-yMin);

&nbsp;&nbsp;&nbsp; //Set the origin based on the minimum values in x and y
&nbsp;&nbsp;&nbsp; g.translate((int)((0-xMin)*xScale),
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (int)((0-yMin)*yScale));
&nbsp;&nbsp;&nbsp; drawAxes(g);//Draw the axes
&nbsp;&nbsp;&nbsp; g.setColor(Color.BLACK);

&nbsp;&nbsp;&nbsp; //Get initial data values
&nbsp;&nbsp;&nbsp; double xVal = xMin;
&nbsp;&nbsp;&nbsp; int oldX = getTheX(xVal);
&nbsp;&nbsp;&nbsp; int oldY = 0;
&nbsp;&nbsp;&nbsp; //Use the Canvas obj number to determine which method
&nbsp;&nbsp;&nbsp; // to invoke to get the value for y.
&nbsp;&nbsp;&nbsp; switch(cnt){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 0 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; oldY = getTheY(data.f1(xVal));
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 1 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; oldY = getTheY(data.f2(xVal));
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 2 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; oldY = getTheY(data.f3(xVal));
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 3 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; oldY = getTheY(data.f4(xVal));
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 4 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; oldY = getTheY(data.f5(xVal));
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 5 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; oldY = getTheY(data.f6(xVal));
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 6 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; oldY = getTheY(data.f7(xVal));
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 7 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; oldY = getTheY(data.f8(xVal));
&nbsp;&nbsp;&nbsp; }//end switch

&nbsp;&nbsp;&nbsp; //Now loop and plot the points
&nbsp;&nbsp;&nbsp; while(xVal &lt; xMax){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int yVal = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Get next data value.&nbsp; Use the Canvas obj number to
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // determine which method to invoke to get the value
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // for y.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; switch(cnt){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 0 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; yVal = getTheY(data.f1(xVal));
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 1 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; yVal = getTheY(data.f2(xVal));
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 2 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; yVal = getTheY(data.f3(xVal));
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 3 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; yVal = getTheY(data.f4(xVal));
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 4 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; yVal = getTheY(data.f5(xVal));
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 5 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; yVal = getTheY(data.f6(xVal));
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 6 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; yVal = getTheY(data.f7(xVal));
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 7 :
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; yVal =getTheY(data.f8(xVal));
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end switch1

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Convert the x-value to an int and draw the next
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // line segment
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int x = getTheX(xVal);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; g.drawLine(oldX,oldY,x,yVal);

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Increment along the x-axis
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; xVal += xCalcInc;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Save end point to use as start point for next line
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // segment.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; oldX = x;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; oldY = yVal;
&nbsp;&nbsp;&nbsp; }//end while loop

&nbsp; }//end overridden paint method
&nbsp; //-----------------------------------------------------//

&nbsp; //Method to draw axes with tic marks and labels in the
&nbsp; // color RED
&nbsp; void drawAxes(Graphics g){
&nbsp;&nbsp;&nbsp; g.setColor(Color.RED);

&nbsp;&nbsp;&nbsp; //Lable left x-axis and bottom y-axis.&nbsp; These are the
&nbsp;&nbsp;&nbsp; // easy ones.&nbsp; Separate the labels from the ends of the
&nbsp;&nbsp;&nbsp; // tic marks by two pixels.
&nbsp;&nbsp;&nbsp; g.drawString("" + (int)xMin,getTheX(xMin),
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; getTheY(xTicLen/2)-2);
&nbsp;&nbsp;&nbsp; g.drawString("" + (int)yMin,getTheX(yTicLen/2)+2,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; getTheY(yMin));

&nbsp;&nbsp;&nbsp; //Label the right x-axis and the top y-axis.&nbsp; These are
&nbsp;&nbsp;&nbsp; // the hard ones because the position must be adjusted
&nbsp;&nbsp;&nbsp; // by the font size and the number of characters.
&nbsp;&nbsp;&nbsp; //Get the width of the string for right end of x-axis
&nbsp;&nbsp;&nbsp; // and the height of the string for top of y-axis
&nbsp;&nbsp;&nbsp; //Create a string that is an integer representation of
&nbsp;&nbsp;&nbsp; // the label for the right end of the x-axis.&nbsp; Then get
&nbsp;&nbsp;&nbsp; // a character array that represents the string.
&nbsp;&nbsp;&nbsp; int xMaxInt = (int)xMax;
&nbsp;&nbsp;&nbsp; String xMaxStr = "" + xMaxInt;
&nbsp;&nbsp;&nbsp; char[] array = xMaxStr.toCharArray();

&nbsp;&nbsp;&nbsp; //Get a FontMetrics object that can be used to get the
&nbsp;&nbsp;&nbsp; // size of the string in pixels.
&nbsp;&nbsp;&nbsp; FontMetrics fontMetrics = g.getFontMetrics();
&nbsp;&nbsp;&nbsp; //Get a bounding rectangle for the string
&nbsp;&nbsp;&nbsp; Rectangle2D r2d = fontMetrics.getStringBounds(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; array,0,array.length,g);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Get the width and the height of the bounding
&nbsp;&nbsp;&nbsp; // rectangle.&nbsp; The width is the width of the label at
&nbsp;&nbsp;&nbsp; // the right end of the x-axis.&nbsp; The height applies to
&nbsp;&nbsp;&nbsp; // all the labels, but is needed specifically for the
&nbsp;&nbsp;&nbsp; // label at the top end of the y-axis.
&nbsp;&nbsp;&nbsp; int labWidth = (int)(r2d.getWidth());
&nbsp;&nbsp;&nbsp; int labHeight = (int)(r2d.getHeight());

&nbsp;&nbsp;&nbsp; //Label the positive x-axis and the positive y-axis
&nbsp;&nbsp;&nbsp; // using the width and height from above to position
&nbsp;&nbsp;&nbsp; // the labels.&nbsp; These labels apply to the very ends of
&nbsp;&nbsp;&nbsp; // the axes at the edge of the plotting surface.
&nbsp;&nbsp;&nbsp; g.drawString("" + (int)xMax,getTheX(xMax)-labWidth,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; getTheY(xTicLen/2)-2);
&nbsp;&nbsp;&nbsp; g.drawString("" + (int)yMax,getTheX(yTicLen/2)+2,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; getTheY(yMax)+labHeight);

&nbsp;&nbsp;&nbsp; //Draw the axes
&nbsp;&nbsp;&nbsp; g.drawLine(getTheX(xMin),getTheY(0.0),getTheX(xMax),
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; getTheY(0.0));

&nbsp;&nbsp;&nbsp; g.drawLine(getTheX(0.0),getTheY(yMin),getTheX(0.0),
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; getTheY(yMax));

&nbsp;&nbsp;&nbsp; //Draw the tic marks on axes
&nbsp;&nbsp;&nbsp; xTics(g);
&nbsp;&nbsp;&nbsp; yTics(g);
&nbsp; }//end drawAxes

&nbsp; //-----------------------------------------------------//

&nbsp; //Method to draw tic marks on x-axis
&nbsp; void xTics(Graphics g){
&nbsp;&nbsp;&nbsp; double xDoub = 0;
&nbsp;&nbsp;&nbsp; int x = 0;

&nbsp;&nbsp;&nbsp; //Get the ends of the tic marks.
&nbsp;&nbsp;&nbsp; int topEnd = getTheY(xTicLen/2);
&nbsp;&nbsp;&nbsp; int bottomEnd =getTheY(-xTicLen/2);

&nbsp;&nbsp;&nbsp; //If the vertical size of the plotting area is small,
&nbsp;&nbsp;&nbsp; // the calculated tic size may be too small.&nbsp; In that
&nbsp;&nbsp;&nbsp; // case, set it to 10 pixels.
&nbsp;&nbsp;&nbsp; if(topEnd &lt; 5){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; topEnd = 5;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; bottomEnd = -5;
&nbsp;&nbsp;&nbsp; }//end if

&nbsp;&nbsp;&nbsp; //Loop and draw a series of short lines to serve as
&nbsp;&nbsp;&nbsp; // tic marks. Begin with the positive x-axis moving to
&nbsp;&nbsp;&nbsp; // the right from zero.
&nbsp;&nbsp;&nbsp; while(xDoub &lt; xMax){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; x = getTheX(xDoub);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; g.drawLine(x,topEnd,x,bottomEnd);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; xDoub += xTicInt;
&nbsp;&nbsp;&nbsp; }//end while

&nbsp;&nbsp;&nbsp; //Now do the negative x-axis moving to the left from
&nbsp;&nbsp;&nbsp; // zero
&nbsp;&nbsp;&nbsp; xDoub = 0;
&nbsp;&nbsp;&nbsp; while(xDoub &gt; xMin){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; x = getTheX(xDoub);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; g.drawLine(x,topEnd,x,bottomEnd);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; xDoub -= xTicInt;
&nbsp;&nbsp;&nbsp; }//end while

&nbsp; }//end xTics
&nbsp; //-----------------------------------------------------//

&nbsp; //Method to draw tic marks on y-axis
&nbsp; void yTics(Graphics g){
&nbsp;&nbsp;&nbsp; double yDoub = 0;
&nbsp;&nbsp;&nbsp; int y = 0;
&nbsp;&nbsp;&nbsp; int rightEnd = getTheX(yTicLen/2);
&nbsp;&nbsp;&nbsp; int leftEnd = getTheX(-yTicLen/2);

&nbsp;&nbsp;&nbsp; //Loop and draw a series of short lines to serve as tic
&nbsp;&nbsp;&nbsp; // marks. Begin with the positive y-axis moving up from
&nbsp;&nbsp;&nbsp; // zero.
&nbsp;&nbsp;&nbsp; while(yDoub &lt; yMax){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; y = getTheY(yDoub);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; g.drawLine(rightEnd,y,leftEnd,y);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; yDoub += yTicInt;
&nbsp;&nbsp;&nbsp; }//end while

&nbsp;&nbsp;&nbsp; //Now do the negative y-axis moving down from zero.
&nbsp;&nbsp;&nbsp; yDoub = 0;
&nbsp;&nbsp;&nbsp; while(yDoub &gt; yMin){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; y = getTheY(yDoub);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; g.drawLine(rightEnd,y,leftEnd,y);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; yDoub -= yTicInt;
&nbsp;&nbsp;&nbsp; }//end while

&nbsp; }//end yTics
&nbsp; //-----------------------------------------------------//

&nbsp; //This method translates and scales a double y value to
&nbsp; // plot properly in the integer coordinate system. In
&nbsp; // addition to scaling, it causes the positive direction
&nbsp; // of the y-axis to be from bottom to top.
&nbsp; int getTheY(double y){
&nbsp;&nbsp;&nbsp; double yDoub = (yMax+yMin)-y;
&nbsp;&nbsp;&nbsp; int yInt = (int)(yDoub*yScale);
&nbsp;&nbsp;&nbsp; return yInt;
&nbsp; }//end getTheY
&nbsp; //-----------------------------------------------------//

&nbsp; //This method scales a double x value to plot properly
&nbsp; // in the integer coordinate system.
&nbsp; int getTheX(double x){
&nbsp;&nbsp;&nbsp; return (int)(x*xScale);
&nbsp; }//end getTheX
&nbsp; //-----------------------------------------------------//

}//end inner class MyCanvas
//=======================================================//

}//end class GUI
//=======================================================//

//Sample test class.&nbsp; Required for compilation and
// stand-alone testing.
class junk implements GraphIntfc08{
&nbsp; public int getNmbr(){
&nbsp;&nbsp;&nbsp; //Return number of functions to process.&nbsp; Must not
&nbsp;&nbsp;&nbsp; // exceed 8.
&nbsp;&nbsp;&nbsp; return 8;
&nbsp; }//end getNmbr

&nbsp; public double f1(double x){
&nbsp;&nbsp;&nbsp; return (x*x*x)/200.0;
&nbsp; }//end f1

&nbsp; public double f2(double x){
&nbsp;&nbsp;&nbsp; return -(x*x*x)/200.0;
&nbsp; }//end f2

&nbsp; public double f3(double x){
&nbsp;&nbsp;&nbsp; return (x*x)/200.0;
&nbsp; }//end f3

&nbsp; public double f4(double x){
&nbsp;&nbsp;&nbsp; return 50*Math.cos(x/10.0);
&nbsp; }//end f4

&nbsp; public double f5(double x){
&nbsp;&nbsp;&nbsp; return 100*Math.sin(x/20.0);
&nbsp; }//end f5

&nbsp; public double f6(double x){
&nbsp;&nbsp;&nbsp; return 100*Math.sin(x/30.0);
&nbsp; }//end f6
&nbsp;
&nbsp; public double f7(double x){
&nbsp;&nbsp;&nbsp; return 100*Math.sin(x/5.0);
&nbsp; }//end f7

&nbsp; public double f8(double x){
&nbsp;&nbsp;&nbsp; return 100*Math.sin(x/2.5);
&nbsp; }//end f8
}//end sample class junk<br><br><b><font face="Courier New,Courier">Listing 1</font></b></pre>
			</td>
		</tr>
	</tbody>
</table>
<p>&nbsp;</p>
<table border="1" cols="1" width="482" bgcolor="#ffff00">
	<tbody>
		<tr>
			<td>
			<pre>/* File GraphIntfc08.java
Copyright 2005, R.G.Baldwin

This interface must be implemented by classes whose objects
produce data to be plotted by the program named Graph08.

This is an upgrade from GraphIntfc01, designed to handle
eight graphs instead of only five.

Tested using J2SE 5.0 WinXP.
**********************************************************/

public interface GraphIntfc08{
&nbsp; public int getNmbr();
&nbsp; public double f1(double x);
&nbsp; public double f2(double x);
&nbsp; public double f3(double x);
&nbsp; public double f4(double x);
&nbsp; public double f5(double x);
&nbsp; public double f6(double x);
&nbsp; public double f7(double x);
&nbsp; public double f8(double x);
}//end GraphIntfc08<br><br><b><font face="Courier New,Courier">Listing 2</font></b></pre>
			</td>
		</tr>
	</tbody>
</table>
<p></p>
<p>&nbsp;</p>
<table border="1" cols="1" width="482" bgcolor="#ffff00">
	<tbody>
		<tr>
			<td>
			<pre>/* File Dsp041.java
Copyright 2005, R.G.Baldwin

This class is loosely based on the class named Dsp040a. The
class named Dsp040a was explained in detail in Lesson 1488
entitled Convolution and Matched Filtering in Java.

The purpose of this class is to make it easy to experiment
with different time series and different convolution
filters.

This class must be run under control of the class named
Graph08. Thus, it requires access to the class named
Graph08 and the interface named GraphIntfc08.&nbsp;

Graph08 and GraphIntfc08 are updates to Graph03 and
GraphIntfc01.&nbsp; The updates allow the user to plot a maximum
of eight graphs instead of a maximum of five graphs as is
the case with Graph03.

Graph03 and GraphIntfc01 were explained in lesson 1488
entitled Convolution and Matched Filtering in Java.

To run this program, enter the following command at the
command line:

java Graph08 Dsp041

Access to the following classes, plus some inner classes
defined in these classes is required to compile and
run this class under control of the class named Graph08:

Dsp041.class
Graph08.class
GraphIntfc08.class
GUI.class

The source code for all of the above classes is provided
either in this file or in lesson 412 entitled Processing
Image Pixels, Applying Image Convolution in Java.

This program illustrates the application of a convolution
filter to signals having a known waveform.&nbsp; In its current
state, five different convolution filters are coded into
the class.&nbsp; Since the class can only apply one convolution
filter at a time, it is necessary to enable and disable the
filters using comments and then recompile the class to
switch from one convolution filter to the other.&nbsp; The five
convolution filters are:

1. A single impulse filter that simply copies the input to
&nbsp;&nbsp; the output.
2. A high-pass filter with an output that is proportional
&nbsp;&nbsp; to the slope of the signal.&nbsp; In essence, the output
&nbsp;&nbsp; approximates the first derivative of the signal.
3. A high-pass filter with an output that is proportional
&nbsp;&nbsp; to the rate of change of the slope of the signal. This
&nbsp;&nbsp; output approximates the second derivative of the signal.
4. A relatively soft high-pass filter, which produces a
&nbsp;&nbsp; little blip in its output each time the slope of the
&nbsp;&nbsp; signal changes.&nbsp; The size of the blip is roughly
&nbsp;&nbsp; proportional to the rate of change of the slope of the
&nbsp;&nbsp; signal.
5. A low-pass smoothing filter.&nbsp; The output approximates a
&nbsp;&nbsp; four-point running average or integration of the signal.

These convolution filters are applied to signal waveforms
having varying slopes.&nbsp; Several interesting results are
displayed.&nbsp; (The filters and the signal waveforms can be
easily modified by modifying that part of the program and
recompiling the program.)

The display contains six graphs and shows the following:
1. The signal waveform as a time series.
2. The convolution filter waveform as a time series.
3. The result of applying the convolution filter to the
&nbsp;&nbsp; signal, including the impulse response of the filter.
4. The amplitude spectrum of the signal expressed in db.
5. The amplitude frequency response of the convolution
&nbsp;&nbsp; filter expressed in db.
6. The amplitude spectrum of the output produced by
&nbsp;&nbsp; applying the convolution filter to the signal.

The convolution algorithm emulates a one-dimensional
version of the 2D image convolution algorithm used in the
class named ImgMod032 with respect to output normalization
and scaling.&nbsp; See an explanation of just what this means in
the comments at the beginning of the convolve method.

In addition to computing and plotting the output from the
convolution process, the class computes and plots several
spectral graphs.

Tested using J2SE 5.0 under WinXP.
**********************************************************/

class Dsp041 implements GraphIntfc08{
&nbsp; //Establish length for various arrays
&nbsp; int filterLen = 200;
&nbsp; int signalLen = 400;
&nbsp; int outputLen = signalLen - filterLen;
&nbsp; //Ignore right half of signal, which is all zeros, when
&nbsp; // computing the spectrum.
&nbsp; int signalSpectrumPts = signalLen/2;
&nbsp; int filterSpectrumPts = outputLen;
&nbsp; int outputSpectrumPts = outputLen;
&nbsp;

&nbsp; //Create arrays to store different types of data.
&nbsp; double[] signal = new double[signalLen];
&nbsp; double[] filter = new double[filterLen];
&nbsp; double[] output = new double[outputLen];
&nbsp; double[] spectrumA = new double[signalSpectrumPts];
&nbsp; double[] spectrumB = new double[filterSpectrumPts];
&nbsp; double[] spectrumC = new double[outputSpectrumPts];

&nbsp; public Dsp041(){//constructor

&nbsp;&nbsp;&nbsp; //Create and save a filter.&nbsp; Change the locations of
&nbsp;&nbsp;&nbsp; // the following comment indicators to enable and/or
&nbsp;&nbsp;&nbsp; // disable a particular filter.&nbsp; Then recompile the
&nbsp;&nbsp;&nbsp; // class and rerun the program to see the effect of
&nbsp;&nbsp;&nbsp; // the newly enabled filter on the signal.
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //This is a single impulse filter that simply copies
&nbsp;&nbsp;&nbsp; // the input to the output.
&nbsp;&nbsp;&nbsp; filter[0] = 1;

/*
&nbsp;&nbsp;&nbsp; //This is a high-pass filter with an output that is
&nbsp;&nbsp;&nbsp; // proportional to the slope of the signal.&nbsp; In
&nbsp;&nbsp;&nbsp; // essence,the output approximates the first derivative
&nbsp;&nbsp;&nbsp; // of the signal.
&nbsp;&nbsp;&nbsp; filter[0] = -1.0;
&nbsp;&nbsp;&nbsp; filter[1] = 1.0;

&nbsp;&nbsp;&nbsp; //This is a high-pass filter with an output that is
&nbsp;&nbsp;&nbsp; // proportional to the rate of change of the slope of
&nbsp;&nbsp;&nbsp; // the signal. In essence, the output approximates the
&nbsp;&nbsp;&nbsp; // second derivative of the signal.
&nbsp;&nbsp;&nbsp; filter[0] = -0.5;
&nbsp;&nbsp;&nbsp; filter[1] = 1.0;
&nbsp;&nbsp;&nbsp; filter[2] = -0.5;

&nbsp;&nbsp;&nbsp; //This is a relatively soft high-pass filter, which
&nbsp;&nbsp;&nbsp; // produces a little blip in the output each time the
&nbsp;&nbsp;&nbsp; // slope of the signal changes.&nbsp; The size of the blip
&nbsp;&nbsp;&nbsp; // is roughly proportional to the rate of change of the
&nbsp;&nbsp;&nbsp; // slope of the signal.
&nbsp;&nbsp;&nbsp; filter[0] = -0.2;
&nbsp;&nbsp;&nbsp; filter[1] = 1.0;
&nbsp;&nbsp;&nbsp; filter[2] = -0.2;

&nbsp;&nbsp;&nbsp; //This is a low-pass smoothing filter.&nbsp; It approximates
&nbsp;&nbsp;&nbsp; // a four-point running average or integration of the
&nbsp;&nbsp;&nbsp; // signal.
&nbsp;&nbsp;&nbsp; filter[0] = 0.250;
&nbsp;&nbsp;&nbsp; filter[1] = 0.250;
&nbsp;&nbsp;&nbsp; filter[2] = 0.250;
&nbsp;&nbsp;&nbsp; filter[3] = 0.250;
*/
&nbsp;
&nbsp;&nbsp;&nbsp; //Create a signal time series containing four distinct
&nbsp;&nbsp;&nbsp; // waveforms:
&nbsp;&nbsp;&nbsp; //&nbsp; An impulse.
&nbsp;&nbsp;&nbsp; //&nbsp; A rectangular pulse.
&nbsp;&nbsp;&nbsp; //&nbsp; A triangular pulse with a large slope.
&nbsp;&nbsp;&nbsp; //&nbsp; A triangular pulse with a smaller slope.
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //First create a baseline in the signal time series.
&nbsp;&nbsp;&nbsp; //Modify the following value and recompile the class
&nbsp;&nbsp;&nbsp; // to change the baseline.
&nbsp;&nbsp;&nbsp; double baseline = 10.0;
&nbsp;&nbsp;&nbsp; for(int cnt = 0;cnt &lt; signalLen;cnt++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; signal[cnt] = baseline;
&nbsp;&nbsp;&nbsp; }//end for loop
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Now add the pulses to the signal time series.
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //First add an impulse.
&nbsp;&nbsp;&nbsp; signal[20] = 75;
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Add a rectangular pulse.
&nbsp;&nbsp;&nbsp; signal[30] = 75;
&nbsp;&nbsp;&nbsp; signal[31] = 75;
&nbsp;&nbsp;&nbsp; signal[32] = 75;
&nbsp;&nbsp;&nbsp; signal[33] = 75;
&nbsp;&nbsp;&nbsp; signal[34] = 75;
&nbsp;&nbsp;&nbsp; signal[35] = 75;
&nbsp;&nbsp;&nbsp; signal[36] = 75;
&nbsp;&nbsp;&nbsp; signal[37] = 75;
&nbsp;&nbsp;&nbsp; signal[38] = 75;
&nbsp;&nbsp;&nbsp; signal[39] = 75;
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Add a triangular pulse with a large slope.
&nbsp;&nbsp;&nbsp; signal[50] = 10;
&nbsp;&nbsp;&nbsp; signal[51] = 30;
&nbsp;&nbsp;&nbsp; signal[52] = 50;
&nbsp;&nbsp;&nbsp; signal[53] = 70;
&nbsp;&nbsp;&nbsp; signal[54] = 90;
&nbsp;&nbsp;&nbsp; signal[55] = 70;
&nbsp;&nbsp;&nbsp; signal[56] = 50;
&nbsp;&nbsp;&nbsp; signal[57] = 30;
&nbsp;&nbsp;&nbsp; signal[58] = 10;
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Add a triangular pulse with a smaller slope.
&nbsp;&nbsp;&nbsp; signal[70] = 10;
&nbsp;&nbsp;&nbsp; signal[71] = 20;
&nbsp;&nbsp;&nbsp; signal[72] = 30;
&nbsp;&nbsp;&nbsp; signal[73] = 40;
&nbsp;&nbsp;&nbsp; signal[74] = 50;
&nbsp;&nbsp;&nbsp; signal[75] = 60;
&nbsp;&nbsp;&nbsp; signal[76] = 70;
&nbsp;&nbsp;&nbsp; signal[77] = 80;
&nbsp;&nbsp;&nbsp; signal[78] = 90;
&nbsp;&nbsp;&nbsp; signal[79] = 80;
&nbsp;&nbsp;&nbsp; signal[80] = 70;
&nbsp;&nbsp;&nbsp; signal[81] = 60;
&nbsp;&nbsp;&nbsp; signal[82] = 50;
&nbsp;&nbsp;&nbsp; signal[83] = 40;
&nbsp;&nbsp;&nbsp; signal[84] = 30;
&nbsp;&nbsp;&nbsp; signal[85] = 20;
&nbsp;&nbsp;&nbsp; signal[86] = 10;

&nbsp;&nbsp;&nbsp; //Convolve the signal with the convolution filter.
&nbsp;&nbsp;&nbsp; // Note, this convolution algorithm emulates a
&nbsp;&nbsp;&nbsp; // one-dimensional version of the 2D image
&nbsp;&nbsp;&nbsp; // convolution algorithm used in ImgMod032 with respect
&nbsp;&nbsp;&nbsp; // to normalization and scaling.
&nbsp;&nbsp;&nbsp; convolve(signal,filter,output);
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Compute and save the DFT of the signal, expressed in
&nbsp;&nbsp;&nbsp; // db.
&nbsp;&nbsp;&nbsp; //Ignore right half of signal which is all zeros.
&nbsp;&nbsp;&nbsp; dft(signal,signalSpectrumPts,spectrumA);
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Compute and save the DFT of the convolution filter
&nbsp;&nbsp;&nbsp; // expressed in db.
&nbsp;&nbsp;&nbsp; //Note that the convolution filter is added to a long
&nbsp;&nbsp;&nbsp; // time series having zero values.&nbsp; This causes the
&nbsp;&nbsp;&nbsp; // output of the DFT to be finely sampled and produces
&nbsp;&nbsp;&nbsp; // a smooth curve for the frequency response of the
&nbsp;&nbsp;&nbsp; // convolution filter.
&nbsp;&nbsp;&nbsp; dft(filter,filterSpectrumPts,spectrumB);

&nbsp;&nbsp;&nbsp; //Compute and save the DFT of the output expressed in
&nbsp;&nbsp;&nbsp; // decibels.
&nbsp;&nbsp;&nbsp; dft(output,outputSpectrumPts,spectrumC);
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //All of the time series have now been produced and
&nbsp;&nbsp;&nbsp; // saved.&nbsp; They may be retrieved and plotted by
&nbsp;&nbsp;&nbsp; // invoking the methods named f1 through f6 below.

&nbsp; }//end constructor

&nbsp; //-----------------------------------------------------//
&nbsp; //The following nine methods are required by the
&nbsp; // interface named GraphIntfc08.&nbsp; They are invoked by the
&nbsp; // plotting class named Graph08.
&nbsp; public int getNmbr(){
&nbsp;&nbsp;&nbsp; //Return number of functions to process. Must not
&nbsp;&nbsp;&nbsp; // exceed 6.
&nbsp;&nbsp;&nbsp; return 6;
&nbsp; }//end getNmbr
&nbsp; //-----------------------------------------------------//
&nbsp; public double f1(double x){
&nbsp;&nbsp;&nbsp; int index = (int)Math.round(x);
&nbsp;&nbsp;&nbsp; //This version of this method returns the signal.
&nbsp;&nbsp;&nbsp; if(index &lt; 0 || index &gt; signal.length-1){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return 0;
&nbsp;&nbsp;&nbsp; }else{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Scale for display and return.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return signal[index] * 1.0;
&nbsp;&nbsp;&nbsp; }//end else
&nbsp; }//end f1
&nbsp; //-----------------------------------------------------//
&nbsp; public double f2(double x){
&nbsp;&nbsp;&nbsp; //Return the convolution filter.
&nbsp;&nbsp;&nbsp; int index = (int)Math.round(x);
&nbsp;&nbsp;&nbsp; if(index &lt; 0 || index &gt; filter.length-1){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return 0;
&nbsp;&nbsp;&nbsp; }else{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Scale for display and return.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return filter[index] * 50.0;
&nbsp;&nbsp;&nbsp; }//end else
&nbsp; }//end f2
&nbsp; //-----------------------------------------------------//
&nbsp; public double f3(double x){
&nbsp;&nbsp;&nbsp; //Return convolution output.
&nbsp;&nbsp;&nbsp; int index = (int)Math.round(x);
&nbsp;&nbsp;&nbsp; if(index &lt; 0 || index &gt; output.length-1){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return 0;
&nbsp;&nbsp;&nbsp; }else{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Scale for display and return.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return output[index] * 1.0;
&nbsp;&nbsp;&nbsp; }//end else
&nbsp; }//end f3
&nbsp; //-----------------------------------------------------//
&nbsp; public double f4(double x){
&nbsp;&nbsp;&nbsp; //Return frequency spectrum of the signal.
&nbsp;&nbsp;&nbsp; int index = (int)Math.round(x);
&nbsp;&nbsp;&nbsp; if(index &lt; 0 || index &gt; spectrumA.length-1){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return 0;
&nbsp;&nbsp;&nbsp; }else{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Adjust peak amplitude for display and return.&nbsp; With
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // this scaling, 100 vertical units in the plot
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // produced by Graph08 represents 25 decibels.&nbsp; In
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // addition, the db values are adjusted to cause the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // maximum value to be plotted at 100 units above
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // the horizontal axis.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return spectrumA[index] * 4.0 + 100;
&nbsp;&nbsp;&nbsp; }//end else
&nbsp; }//end f4
&nbsp; //-----------------------------------------------------//
&nbsp; public double f5(double x){
&nbsp;&nbsp;&nbsp; //Return frequency response of convolution filter.
&nbsp;&nbsp;&nbsp; int index = (int)Math.round(x);
&nbsp;&nbsp;&nbsp; if(index &lt; 0 || index &gt; spectrumB.length-1){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return 0;
&nbsp;&nbsp;&nbsp; }else{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Adjust peak amplitude for display and return. See
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // comments in f4.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return spectrumB[index] * 4.0 + 100;
&nbsp;&nbsp;&nbsp; }//end else
&nbsp; }//end f5
&nbsp; //-----------------------------------------------------//
&nbsp; public double f6(double x){
&nbsp;&nbsp;&nbsp; //Return frequency spectrum of the output.
&nbsp;&nbsp;&nbsp; int index = (int)Math.round(x);
&nbsp;&nbsp;&nbsp; if(index &lt; 0 || index &gt; spectrumC.length-1){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return 0;
&nbsp;&nbsp;&nbsp; }else{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Adjust peak amplitude for display and return. See
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // comments in f4.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return spectrumC[index] * 4.0 + 100;
&nbsp;&nbsp;&nbsp; }//end else
&nbsp; }//end f6
&nbsp; //-----------------------------------------------------//
&nbsp; public double f7(double x){
&nbsp;&nbsp;&nbsp; //This method is not used but must be defined.
&nbsp;&nbsp;&nbsp; return 0.0;
&nbsp; }//end f7
&nbsp; //-----------------------------------------------------//
&nbsp; public double f8(double x){
&nbsp;&nbsp;&nbsp; //This method is not used but must be defined.
&nbsp;&nbsp;&nbsp; return 0.0;
&nbsp; }//end f8
&nbsp; //-----------------------------------------------------//

&nbsp; //This method computes and returns the amplitude spectrum
&nbsp; // of an incoming time series.&nbsp; The amplitude spectrum is
&nbsp; // computed as the square root of the sum of the squares
&nbsp; // of the real and imaginary parts.&nbsp; It is converted to
&nbsp; // decibels and the amplitude spectrum in db is returned.
&nbsp; //Returns a number of points in the frequency domain
&nbsp; // equal to the number of samples in the incoming time
&nbsp; // series. This is for convenience only and is not a
&nbsp; // requirement of a DFT.
&nbsp; //Deposits the frequency data in an array whose
&nbsp; // reference is received as an incoming parameter.
&nbsp; public void dft(double[] data,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int dataLen,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[] spectrum){
&nbsp;&nbsp;&nbsp; double twoPI = 2*Math.PI;

&nbsp;&nbsp;&nbsp; //Set the frequency increment to the reciprocal of the
&nbsp;&nbsp;&nbsp; // data length.&nbsp; This is a convenience only, and is not
&nbsp;&nbsp;&nbsp; // a requirement of the DFT algorithm.
&nbsp;&nbsp;&nbsp; double delF = 1.0/dataLen;
&nbsp;&nbsp;&nbsp; //Outer loop interates on frequency values.
&nbsp;&nbsp;&nbsp; for(int i = 0; i &lt; dataLen;i++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double freq = i*delF;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double real = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double imag = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Inner loop iterates on time- series points.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int j=0; j &lt; dataLen; j++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; real += data[j]*Math.cos(twoPI*freq*j);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; imag += data[j]*Math.sin(twoPI*freq*j);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; spectrum[i] = Math.sqrt(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; real*real + imag*imag);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp; }//end outer loop
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Convert the amplitude spectrum to decibels.
&nbsp;&nbsp;&nbsp; for(int cnt = 0;cnt &lt; dataLen;cnt++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Set zero and negative values to -Double.MAX_VALUE
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // before converting to log values. Shouldn't be any
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // negative values. May be some zero values. An
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // amplitude value of 0 should result in negative
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // infinity decibels.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(spectrum[cnt] &lt;= 0){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; spectrum[cnt] = -Double.MAX_VALUE;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end if
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(spectrum[cnt] &gt; 0){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Ignore zero and negative values. Convert positive
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // values to log base 10.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; spectrum[cnt] = 20*Math.log10(spectrum[cnt]);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end if
&nbsp;&nbsp;&nbsp; }//end for loop
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //The amplitude spectrum has now been converted to db.
&nbsp;&nbsp;&nbsp; // Normalize the peak to zero db.
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Get the max value.
&nbsp;&nbsp;&nbsp; double max = -Double.MAX_VALUE;
&nbsp;&nbsp;&nbsp; for(int cnt = 0;cnt &lt; dataLen;cnt++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(spectrum[cnt] &gt; max)max = spectrum[cnt];
&nbsp;&nbsp;&nbsp; }//end for loop
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Subtract the max from every value
&nbsp;&nbsp;&nbsp; for(int cnt = 0;cnt &lt; dataLen;cnt++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; spectrum[cnt] -= max;
&nbsp;&nbsp;&nbsp; //System.out.print(spectrum[cnt] + " ");
&nbsp;&nbsp;&nbsp; }//end for loop
&nbsp; }//end dft
&nbsp; //-----------------------------------------------------//
&nbsp; //This method applies an incoming convolution filter
&nbsp; // to an incoming set of data and deposits the filtered
&nbsp; // data in an output array whose reference is received as
&nbsp; // an incoming parameter.
&nbsp; //This convolution algorithm emulates a one-dimensional
&nbsp; // version of the 2D image convolution algorithm used in
&nbsp; // the class named ImgMod032 with respect to
&nbsp; // normalization and scaling.
&nbsp; //There are two major differences between this algorithm
&nbsp; // and the 2D algorithm.&nbsp; First, this algorithm flips the
&nbsp; // convolution filter end-for-end whereas the 2D
&nbsp; // algorithm does not flip the convolution filter.
&nbsp; // Thus, the 2D algorithm requires that the convolution
&nbsp; // operator be flipped before it is passed to the method.
&nbsp; // Second, whereas the 2D algorithm normalizes the output
&nbsp; // data so as to guarantee that the output values range
&nbsp; // from 0 to 255 inclusive, this algorithm normalizes the
&nbsp; // output data so as to guarantee that the output values
&nbsp; // range from 0 to 100 inclusive.&nbsp; This difference is of
&nbsp; // no practical significance other than to cause the
&nbsp; // output values to be plotted on a scale that is
&nbsp; // somewhat easier to interpret.
&nbsp; //Both algorithms assume that the incoming data consists
&nbsp; // of all positive values (as is the case with color
&nbsp; // values) with regard to the normalization rationale.
&nbsp; // However, that is not a technical requirement.
&nbsp; //The algorithm begins by computing and saving the mean
&nbsp; // value of the incoming data.&nbsp; Then it makes a copy of
&nbsp; // the incoming data, removing the mean in the process.
&nbsp; // (The copy is made simply to avoid modifying the
&nbsp; // original data.)&nbsp; Then the method applies the
&nbsp; // convolution filter to the copy of the incoming data
&nbsp; // producing an output time series with a zero mean
&nbsp; // value.
&nbsp; //Then the method adds the&nbsp; original mean value to the
&nbsp; // output values causing the mean value of the output
&nbsp; // to be the same as the mean value of the input.
&nbsp; //Following this, the method computes the minimum value
&nbsp; // of the output and checks to see if it is negative.&nbsp; If
&nbsp; // so, the minimum value is subtracted from all output
&nbsp; // values, causing the minimum value of the output to be
&nbsp; // zero.&nbsp; Otherwise, no adjustment is made on the basis
&nbsp; // of the minimum value.
&nbsp; //Then the method computes the maximum value and checks
&nbsp; // to see if the maximum value is greater than 100.&nbsp; If
&nbsp; // so, all output values are scaled so as to cause the
&nbsp; // maximum output value to be 100.&nbsp; Otherwise, no
&nbsp; // adjustment is made on the basis of the maximum value.
&nbsp; public&nbsp; void convolve(double[] data,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[] operator,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[] output){
&nbsp;&nbsp;&nbsp; int dataLen = data.length;
&nbsp;&nbsp;&nbsp; double[] temp = new double[dataLen];
&nbsp;&nbsp;&nbsp;

&nbsp;&nbsp;&nbsp; //Get, save, and remove the mean value.
&nbsp;&nbsp;&nbsp; //Copy the data into a temporary array, removing the
&nbsp;&nbsp;&nbsp; // mean value in the process.
&nbsp;&nbsp;&nbsp; double sum = 0;
&nbsp;&nbsp;&nbsp; for(int cnt = 0;cnt &lt; dataLen;cnt++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sum += data[cnt];
&nbsp;&nbsp;&nbsp; }//end for loop
&nbsp;&nbsp;&nbsp; double mean = sum/dataLen;
&nbsp;&nbsp;&nbsp; for(int cnt = 0;cnt &lt; dataLen;cnt++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; temp[cnt] = data[cnt] - mean;
&nbsp;&nbsp;&nbsp; }//end for loop

&nbsp;&nbsp;&nbsp; //Apply the convolution filter to the copy of the
&nbsp;&nbsp;&nbsp; // data, dealing with the index reversal required
&nbsp;&nbsp;&nbsp; // to flip the operator end-for-end.
&nbsp;&nbsp;&nbsp; int operatorLen = operator.length;
&nbsp;&nbsp;&nbsp; for(int i = 0;i &lt; dataLen-operatorLen;i++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output[i] = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int j = operatorLen-1;j &gt;= 0;j--){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output[i] += temp[i+j]*operator[j];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp; }//end outer loop
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Restore the original mean value to the output.
&nbsp;&nbsp;&nbsp; for(int cnt = 0;cnt &lt; dataLen-operatorLen;cnt++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output[cnt] += mean;
&nbsp;&nbsp;&nbsp; }//end for loop
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Find the minimum value in the output.
&nbsp;&nbsp;&nbsp; double min = Double.MAX_VALUE;
&nbsp;&nbsp;&nbsp; for(int cnt = 0;cnt &lt; dataLen-operatorLen;cnt++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(output[cnt] &lt; min){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; min = output[cnt];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end if
&nbsp;&nbsp;&nbsp; }//end for loop
&nbsp;&nbsp;&nbsp; System.out.println("Output min: " + min);

&nbsp;&nbsp;&nbsp; //If the minimum value is negative, subtract it from
&nbsp;&nbsp;&nbsp; // all of the output values to ensure that the output
&nbsp;&nbsp;&nbsp; // minimum is zero.
&nbsp;&nbsp;&nbsp; if(min &lt; 0.0){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int cnt = 0;cnt &lt; dataLen-operatorLen;cnt++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output[cnt] -= min;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end for loop
&nbsp;&nbsp;&nbsp; }//end if
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Find the maximum value in the output.
&nbsp;&nbsp;&nbsp; double max = -Double.MAX_VALUE;
&nbsp;&nbsp;&nbsp; for(int cnt = 0;cnt &lt; dataLen-operatorLen;cnt++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(output[cnt] &gt; max){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; max = output[cnt];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end if
&nbsp;&nbsp;&nbsp; }//end for loop
&nbsp;&nbsp;&nbsp; System.out.println("Output max: " + max);

&nbsp;&nbsp;&nbsp; //If the maximum value is greater than 100, scale all
&nbsp;&nbsp;&nbsp; // of the output values to ensure that the output
&nbsp;&nbsp;&nbsp; // maximum is 100.
&nbsp;&nbsp;&nbsp; if(max &gt; 100.0){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int cnt = 0;cnt &lt; dataLen-operatorLen;cnt++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output[cnt] *= 100.0/max;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end for loop
&nbsp;&nbsp;&nbsp; }//end if

&nbsp; }//end convolve method
}//end class Dsp041
//=======================================================//
<br><br><b><font face="Courier New,Courier">Listing 3</font></b></pre></td>
		</tr>
	</tbody>
</table>
<p></p>
<p></p>
<p>&nbsp;</p>
<table border="1" cols="1" width="482" bgcolor="#ffff00">
	<tbody>
		<tr>
			<td>
			<pre>/*File ImgMod33.java
Copyright 2005, R.G.Baldwin

This class provides a general purpose 2D image convolution
and color filtering capability in Java. The class is
designed to be driven by the class named ImgMod02a.&nbsp;

The image file is specified on the command line. The name
of a file containing the 2D convolution filter is provided
via a TextField after the program starts running.
Multiplicative factors, which are applied to the individual
color planes are also provided through three TextFields
after the program starts running.

Enter the following at the command line to run this
program:

java ImgMod02a ImgMod33 ImageFileName

where ImageFileName is the name of a .gif or .jpg file,
including the extension.

Then enter the name of a file containing a 2D convolution
filter in the TextField that appears on the screen.&nbsp; Click
the Replot button on the Frame that displays the image
to cause the convolution filter to be applied to the image.
You can modify the multiplicative factors in the three
TextFields labeled Red, Green, and Blue before clicking the
Replot button to cause the color values to be scaled by
the respective multiplicative factors.&nbsp; The default
multiplicative factor for each color plane is 1.0.

When you click the Replot button, the image in the top of
the Frame will be convolved with the filter, the color
values in the color planes will be scaled by the
multiplicative factors, and the filtered image will appear
in the bottom of the Frame.

Each time you click the Replot button, two additional
graphs are produced that show the following information
in a color contour map fomat:
1.&nbsp; The convolution filter.
2.&nbsp; The wave number response of the convolution filter.

Because the GUI that contains the TextField for entry of
the convolution filter file name also contains three
additional TextFields that allow for the entry of
multiplicative factors that are applied to the three color
planes, it is possible to implement color filtering in
addition to convolution filtering.&nbsp; To apply color
filtering, enter new multiplicative scale factors into
the TextFields for Red, Green, and Blue and click the
Replot button.

Once the program is running, different convolution filters
and different color filters can be successively applied to
the same image, either separately or in combination, by
entering the name of each new filter file into the
TextField and/or entering new color multiplicative factors
into the respective color TextFields and then clicking the
Replot button

See comments at the beginning of the method named getFilter
for a description and an example of the required format for
the file containing the 2D convolution filter.

This program requires access to the following class files
plus some inner classes that are defined inside the
following classes:

ImgIntfc02.class
ImgMod02a.class
ImgMod29.class
ImgMod30.class
ImgMod32.class
ImgMod33.class

Tested using J2SE 5.0 and WinXP
**********************************************************/
import java.awt.*;
import java.io.*;

class ImgMod33 extends Frame implements ImgIntfc02{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp; TextField fileNameField = new TextField("");
&nbsp; Panel rgbPanel = new Panel();
&nbsp; TextField redField = new TextField("1.0");
&nbsp; TextField greenField = new TextField("1.0");
&nbsp; TextField blueField = new TextField("1.0");
&nbsp; Label instructions = new Label(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Enter Filter File Name and scale factors for " +
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Red, Green, and Blue and click Replot");
&nbsp; //-----------------------------------------------------//

&nbsp; ImgMod33(){//constructor
&nbsp;&nbsp;&nbsp; setLayout(new GridLayout(4,1));
&nbsp;&nbsp;&nbsp; add(new Label("Filter File Name"));
&nbsp;&nbsp;&nbsp; add(fileNameField);
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Populate the rgbPanel
&nbsp;&nbsp;&nbsp; rgbPanel.add(new Label("Red"));
&nbsp;&nbsp;&nbsp; rgbPanel.add(redField);
&nbsp;&nbsp;&nbsp; rgbPanel.add(new Label("Green"));
&nbsp;&nbsp;&nbsp; rgbPanel.add(greenField);
&nbsp;&nbsp;&nbsp; rgbPanel.add(new Label("Blue"));
&nbsp;&nbsp;&nbsp; rgbPanel.add(blueField);

&nbsp;&nbsp;&nbsp; add(rgbPanel);
&nbsp;&nbsp;&nbsp; add(instructions);
&nbsp;&nbsp;&nbsp; setTitle("Copyright 2005, R.G.Baldwin");
&nbsp;&nbsp;&nbsp; setBounds(400,0,460,125);
&nbsp;&nbsp;&nbsp; setVisible(true);
&nbsp; }//end constructor
&nbsp; //-----------------------------------------------------//

&nbsp; //This method is required by ImgIntfc02.&nbsp; It is called at
&nbsp; // the beginning of the run and each time thereafter that
&nbsp; // the user clicks the Replot button on the Frame
&nbsp; // containing the images.
&nbsp; //The method gets a 2D convolution filter from a text
&nbsp; // file, applies it to the incoming 3D array of pixel
&nbsp; // data and returns a filtered 3D array of pixel data.&nbsp;
&nbsp; public int[][][] processImg(int[][][] threeDPix,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int imgRows,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int imgCols){

&nbsp;&nbsp;&nbsp; //Create an empty output array of the same size as the
&nbsp;&nbsp;&nbsp; // incoming array.
&nbsp;&nbsp;&nbsp; int[][][] output = new int[imgRows][imgCols][4];

&nbsp;&nbsp;&nbsp; //Make a working copy of the 3D pixel array to avoid
&nbsp;&nbsp;&nbsp; // making permanent changes to the original image data.
&nbsp;&nbsp;&nbsp; int[][][] working3D = new int[imgRows][imgCols][4];
&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; imgRows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; imgCols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; working3D[row][col][0] = threeDPix[row][col][0];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; working3D[row][col][1] = threeDPix[row][col][1];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; working3D[row][col][2] = threeDPix[row][col][2];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; working3D[row][col][3] = threeDPix[row][col][3];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Copy alpha values directly to the output. They
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // are not processed when the image is filtered
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // by the convolution filter.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output[row][col][0] = threeDPix[row][col][0];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp; }//end outer loop

&nbsp;&nbsp;&nbsp; //Get the file name containing the filter from the
&nbsp;&nbsp;&nbsp; // textfield.
&nbsp;&nbsp;&nbsp; String fileName = fileNameField.getText();
&nbsp;&nbsp;&nbsp; if(fileName.equals("")){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //The file name is an empty string. Skip the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // convolution process and pass the input image
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // directly to the output.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output = working3D;
&nbsp;&nbsp;&nbsp; }else{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Get a 2D array that is populated with the contents
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // of the file containing the 2D filter.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[][] filter = getFilter(fileName);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Plot the impulse response and the wave-number
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // response of the convolution filter.&nbsp; These items
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // are not computed and plotted when the program
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // starts running.&nbsp; Rather, they are computed and
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // plotted each time the user clicks the Replot
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // button after entering the name of a file
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // containing a convolution filter into the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // TextField.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Begin by placing the impulse response in the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // center of a large flat surface with an elevation
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // of zero.This is done to improve the resolution of
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // the Fourier Transform, which will be computed
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // later.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int numFilterRows = filter.length;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int numFilterCols = filter[0].length;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int rows = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int cols = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Make the size of the surface ten pixels larger than
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // the convolution filter with a minimum size of
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // 32x32 pixels.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(numFilterRows &lt; 22){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; rows = 32;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }else{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; rows = numFilterRows + 10;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end else
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(numFilterCols &lt; 22){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cols = 32;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }else{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cols = numFilterCols + 10;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end else
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Create the surface, which will be initialized to
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // all zero values.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[][] filterSurface = new double[rows][cols];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Place the convolution filter in the center of the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // surface.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; numFilterRows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; numFilterCols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; filterSurface[row + (rows - numFilterRows)/2]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [col + (cols - numFilterCols)/2] =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; filter[row][col];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end outer loop
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Display the filter and the surface on which it
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // resides as a 3D plot in a color contour format.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; new ImgMod29(filterSurface,4,true,1);
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Get and display the 2D Fourier Transform of the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // convolution filter.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Prepare arrays to receive the results of the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // Fourier transform.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[][] real = new double[rows][cols];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[][] imag = new double[rows][cols];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[][] amp = new double[rows][cols];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Perform the 2D Fourier transform.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ImgMod30.xform2D(filterSurface,real,imag,amp);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Ignore the real and imaginary results.&nbsp; Prepare the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // amplitude spectrum for more-effective plotting by
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // shifting the origin to the center in wave-number
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // space.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[][] shiftedAmplitudeSpect =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ImgMod30.shiftOrigin(amp);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Get and display the minimum and maximum wave number
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // values.&nbsp; This is useful because the way that the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // wave number plots are normalized. it is not
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // possible to infer the flatness or lack thereof of
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // the wave number surface simply by viewing the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // plot.&nbsp; The colors that describe the elevations
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // always range from black at the minimum to white at
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // the maximum, with different colors in between
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // regardless of the difference between the minimum
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // and the maximum.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double maxValue = -Double.MAX_VALUE;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double minValue = Double.MAX_VALUE;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; rows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; cols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(amp[row][col] &gt; maxValue){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; maxValue = amp[row][col];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end if
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(amp[row][col] &lt; minValue){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; minValue = amp[row][col];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end if
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end outer loop
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; System.out.println("minValue: " + minValue);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; System.out.println("maxValue: " + maxValue);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; System.out.println("ratio: " + maxValue/minValue);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Generate and display the wave-number response
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // graph by plotting the 3D surface on the computer
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // screen.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; new ImgMod29(shiftedAmplitudeSpect,4,true,1);

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Perform the convolution.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output = ImgMod32.convolve(working3D,filter);
&nbsp;&nbsp;&nbsp; }//end else
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Scale output color planes.&nbsp; Color planes will be
&nbsp;&nbsp;&nbsp; // scaled only if the corresponding scale factor in the
&nbsp;&nbsp;&nbsp; // TextField has a value other than 1.0.&nbsp; Otherwise,
&nbsp;&nbsp;&nbsp; // there is no point in consuming computer time to do
&nbsp;&nbsp;&nbsp; // the scaling.
&nbsp;&nbsp;&nbsp; if(!redField.getText().equals(1.0)){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double scale = Double.parseDouble(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; redField.getText());
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; scaleColorPlane(output,1,scale);
&nbsp;&nbsp;&nbsp; }//end if on redField
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; if(!greenField.getText().equals(1.0)){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double scale = Double.parseDouble(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; greenField.getText());
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; scaleColorPlane(output,2,scale);
&nbsp;&nbsp;&nbsp; }//end if on greenField
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; if(!blueField.getText().equals(1.0)){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double scale = Double.parseDouble(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; blueField.getText());
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; scaleColorPlane(output,3,scale);
&nbsp;&nbsp;&nbsp; }//end if on blueField
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Return a reference to the array containing the image,
&nbsp;&nbsp;&nbsp; // which has undergone both convolution filtering and
&nbsp;&nbsp;&nbsp; // color filtering.
&nbsp;&nbsp;&nbsp; return output;

&nbsp; }//end processImg method
&nbsp; //-----------------------------------------------------//
&nbsp;
&nbsp;
&nbsp; //The purpose of this method is to scale every color
&nbsp; // value in a specified color plane in the int version
&nbsp; // of an image pixel array by a specified scale factor.
&nbsp; // The scaled values are clipped at 255 and 0.
&nbsp; static void scaleColorPlane(int[][][] inputImageArray,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int plane,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double scale){
&nbsp;&nbsp;&nbsp; int numImgRows = inputImageArray.length;
&nbsp;&nbsp;&nbsp; int numImgCols = inputImageArray[0].length;
&nbsp;&nbsp;&nbsp; //Scale each color value
&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; numImgRows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; numImgCols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double result =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; inputImageArray[row][col][plane] * scale;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(result &gt; 255){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; result = 255;//clip large numbers
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end if
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(result &lt; 0){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; result = 0;//clip negative numbers
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end if
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Cast the result to int and put back into the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // color plane.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; inputImageArray[row][col][plane] = (int)result;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp; }//end outer loop
&nbsp; }//end scaleColorPlane
&nbsp; //-----------------------------------------------------//
&nbsp; /*
&nbsp; The purpose of this method is to read the contents of a
&nbsp;&nbsp; text file and to use those contents to create a 2D
&nbsp;&nbsp;&nbsp; convolution filter by populating a 2D array with the
&nbsp;&nbsp;&nbsp; contents of the text file.

&nbsp; The text file consists of a series of lines with each
&nbsp;&nbsp; line containing a single string of characters.
&nbsp;
&nbsp; Whitespace is allowed before and after the strings on a
&nbsp;&nbsp; line.
&nbsp;
&nbsp; Lines containing empty strings are ignored.
&nbsp;
&nbsp; The file is allowed to contain comments, which must begin
&nbsp; with //
&nbsp;
&nbsp; Comments are displayed on the standard output device.
&nbsp;
&nbsp; Comments in the text file are ignored and do not factor
&nbsp;&nbsp; into the programming comments that follow.
&nbsp;
&nbsp; The first two strings must be convertible to type int and
&nbsp;&nbsp; every other string must be convertible to type double.
&nbsp;
&nbsp; The first string specifies the number of rows in the 2D
&nbsp; filter as type int.
&nbsp;
&nbsp; The second string specifies the number of columns in the
&nbsp; 2D filter as type int.
&nbsp;
&nbsp; The remaining strings specify the filter coefficients as
&nbsp; type double in row-column order.

&nbsp; The total number of strings must be (2 + rows*cols).
&nbsp; Otherwise, the program will throw an exception and abort.

&nbsp; Here are the results for a test file named Filter01.txt.
&nbsp; The file contents are shown below. Note that the comment
&nbsp; indicators are comment indicators in the file and are
&nbsp; not comment indicators in this program.

&nbsp; //File Filter01.txt
&nbsp; //This is a test file, and this is a comment.
&nbsp; //This is a high-pass filter in the wave-number domain.
&nbsp; 3
&nbsp; 3

&nbsp; -1
&nbsp; -1
&nbsp; -1

&nbsp; -1
&nbsp;&nbsp; 8
&nbsp; -1

&nbsp; -1
&nbsp; //This is another comment put here for test purposes.
&nbsp; //There is whitespace following the next item.
&nbsp; -1
&nbsp; -1

&nbsp; The text output produced by the method for this input
&nbsp; file is shown below.

&nbsp; //File Filter01.txt
&nbsp; //This is a test file, and this is a comment.
&nbsp; //This is a high-pass filter in the wave-number domain.
&nbsp; //This is another comment put here for test purposes.
&nbsp; //There is whitespace following the next item.
&nbsp; -1.0 -1.0 -1.0
&nbsp; -1.0 8.0 -1.0
&nbsp; -1.0 -1.0 -1.0
&nbsp; */
&nbsp; double[][] getFilter(String fileName){
&nbsp;&nbsp;&nbsp; double[][] filter = new double[0][0];
&nbsp;&nbsp;&nbsp; try{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; BufferedReader inData =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; new BufferedReader(new FileReader(fileName));

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; String data;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int count = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int rows = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int cols = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int row = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int col = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; while((data = inData.readLine()) != null){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(data.startsWith("//")){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Display and ignore comments.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; System.out.println(data);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }else{//Not a comment
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(!data.equals("")){//ignore empty strings
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; count++;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(count == 1){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Get row dimension value. Trim whitespace in
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // the process.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; rows = Integer.parseInt(data.trim());
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }else if(count == 2){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Get column dimension value. Trim whitespace
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // in the process.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cols = Integer.parseInt(data.trim());
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Create a new array object to be populated
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // with the remaining contents of the file.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; filter = new double[rows][cols];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }else{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Populate the filter array with the contents
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // of the file. Trim whitespace in the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // process.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; row = (count-3)/cols;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; col = (count-3)%cols;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; filter[row][col] =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Double.parseDouble(data.trim());
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end else
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end if on empty strings
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end else, not a comment
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end while data != null
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; inData.close();//Close the input stream.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Display the filter coefficient values in a
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // rectangular array format.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int outCnt = 0;outCnt &lt; rows;outCnt++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int inCnt = 0;inCnt &lt; cols;inCnt++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; System.out.print(filter[outCnt][inCnt] + " ");
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end for loop
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; System.out.println();//new line
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end for loop
&nbsp;&nbsp;&nbsp; }catch(IOException e){}

&nbsp;&nbsp;&nbsp; return filter;//Return the filter.
&nbsp; }//end getFilter
&nbsp; //-----------------------------------------------------//
}//end class ImgMod33<br><br><b><font face="Courier New,Courier">Listing 4</font></b></pre>
			</td>
		</tr>
	</tbody>
</table>
<p></p>
<p>&nbsp;</p>
<table border="1" cols="1" width="482" bgcolor="#ffff00">
	<tbody>
		<tr>
			<td>
			<pre>/*File ImgMod33a.java
Copyright 2005, R.G.Baldwin

This class is identical to ImgMod33 except that it calls
ImgMod32a instead of ImgMod32.

This class provides a general purpose 2D image convolution
and color filtering capability in Java. The class is
designed to be driven by the class named ImgMod02a.&nbsp;

The image file is specified on the command line. The name
of a file containing the 2D convolution filter is provided
via a TextField after the program starts running.
Multiplicative factors, which are applied to the individual
color planes are also provided through three TextFields
after the program starts running.

Enter the following at the command line to run this
program:

java ImgMod02a ImgMod33a ImageFileName

where ImageFileName is the name of a .gif or .jpg file,
including the extension.

Then enter the name of a file containing a 2D convolution
filter in the TextField that appears on the screen.&nbsp; Click
the Replot button on the Frame that displays the image
to cause the convolution filter to be applied to the image.
You can modify the multiplicative factors in the three
TextFields labeled Red, Green, and Blue before clicking the
Replot button to cause the color values to be scaled by
the respective multiplicative factors.&nbsp; The default
multiplicative factor for each color plane is 1.0.

When you click the Replot button, the image in the top of
the Frame will be convolved with the filter, the color
values in the color planes will be scaled by the
multiplicative factors, and the filtered image will appear
in the bottom of the Frame.

Each time you click the Replot button, two additional
graphs are produced that show the following information
in a color contour map fomat:
1.&nbsp; The convolution filter.
2.&nbsp; The wave number response of the convolution filter.

Because the GUI that contains the TextField for entry of
the convolution filter file name also contains three
additional TextFields that allow for the entry of
multiplicative factors that are applied to the three color
planes, it is possible to implement color filtering in
addition to convolution filtering.&nbsp; To apply color
filtering, enter new multiplicative scale factors into
the TextFields for Red, Green, and Blue and click the
Replot button.

Once the program is running, different convolution filters
and different color filters can be successively applied to
the same image, either separately or in combination, by
entering the name of each new filter file into the
TextField and/or entering new color multiplicative factors
into the respective color TextFields and then clicking the
Replot button

See comments at the beginning of the method named getFilter
for a description and an example of the required format for
the file containing the 2D convolution filter.

This program requires access to the following class files
plus some inner classes that are defined inside the
following classes:

ImgIntfc02.class
ImgMod02a.class
ImgMod29.class
ImgMod30.class
ImgMod32a.class
ImgMod33a.class

Tested using J2SE 5.0 and WinXP
**********************************************************/
import java.awt.*;
import java.io.*;

class ImgMod33a extends Frame implements ImgIntfc02{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp; TextField fileNameField = new TextField("");
&nbsp; Panel rgbPanel = new Panel();
&nbsp; TextField redField = new TextField("1.0");
&nbsp; TextField greenField = new TextField("1.0");
&nbsp; TextField blueField = new TextField("1.0");
&nbsp; Label instructions = new Label(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Enter Filter File Name and scale factors for " +
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Red, Green, and Blue and click Replot");
&nbsp; //-----------------------------------------------------//

&nbsp; ImgMod33a(){//constructor
&nbsp;&nbsp;&nbsp; setLayout(new GridLayout(4,1));
&nbsp;&nbsp;&nbsp; add(new Label("Filter File Name"));
&nbsp;&nbsp;&nbsp; add(fileNameField);
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Populate the rgbPanel
&nbsp;&nbsp;&nbsp; rgbPanel.add(new Label("Red"));
&nbsp;&nbsp;&nbsp; rgbPanel.add(redField);
&nbsp;&nbsp;&nbsp; rgbPanel.add(new Label("Green"));
&nbsp;&nbsp;&nbsp; rgbPanel.add(greenField);
&nbsp;&nbsp;&nbsp; rgbPanel.add(new Label("Blue"));
&nbsp;&nbsp;&nbsp; rgbPanel.add(blueField);

&nbsp;&nbsp;&nbsp; add(rgbPanel);
&nbsp;&nbsp;&nbsp; add(instructions);
&nbsp;&nbsp;&nbsp; setTitle("Copyright 2005, R.G.Baldwin");
&nbsp;&nbsp;&nbsp; setBounds(400,0,460,125);
&nbsp;&nbsp;&nbsp; setVisible(true);
&nbsp; }//end constructor
&nbsp; //-----------------------------------------------------//

&nbsp; //This method is required by ImgIntfc02.&nbsp; It is called at
&nbsp; // the beginning of the run and each time thereafter that
&nbsp; // the user clicks the Replot button on the Frame
&nbsp; // containing the images.
&nbsp; //The method gets a 2D convolution filter from a text
&nbsp; // file, applies it to the incoming 3D array of pixel
&nbsp; // data and returns a filtered 3D array of pixel data.&nbsp;
&nbsp; public int[][][] processImg(int[][][] threeDPix,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int imgRows,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int imgCols){

&nbsp;&nbsp;&nbsp; //Create an empty output array of the same size as the
&nbsp;&nbsp;&nbsp; // incoming array.
&nbsp;&nbsp;&nbsp; int[][][] output = new int[imgRows][imgCols][4];

&nbsp;&nbsp;&nbsp; //Make a working copy of the 3D pixel array to avoid
&nbsp;&nbsp;&nbsp; // making permanent changes to the original image data.
&nbsp;&nbsp;&nbsp; int[][][] working3D = new int[imgRows][imgCols][4];
&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; imgRows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; imgCols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; working3D[row][col][0] = threeDPix[row][col][0];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; working3D[row][col][1] = threeDPix[row][col][1];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; working3D[row][col][2] = threeDPix[row][col][2];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; working3D[row][col][3] = threeDPix[row][col][3];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Copy alpha values directly to the output. They
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // are not processed when the image is filtered
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // by the convolution filter.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output[row][col][0] = threeDPix[row][col][0];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp; }//end outer loop

&nbsp;&nbsp;&nbsp; //Get the file name containing the filter from the
&nbsp;&nbsp;&nbsp; // textfield.
&nbsp;&nbsp;&nbsp; String fileName = fileNameField.getText();
&nbsp;&nbsp;&nbsp; if(fileName.equals("")){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //The file name is an empty string. Skip the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // convolution process and pass the input image
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // directly to the output.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output = working3D;
&nbsp;&nbsp;&nbsp; }else{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Get a 2D array that is populated with the contents
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // of the file containing the 2D filter.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[][] filter = getFilter(fileName);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Plot the impulse response and the wave-number
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // response of the convolution filter.&nbsp; These items
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // are not computed and plotted when the program
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // starts running.&nbsp; Rather, they are computed and
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // plotted each time the user clicks the Replot
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // button after entering the name of a file
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // containing a convolution filter into the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // TextField.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Begin by placing the impulse response in the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // center of a large flat surface with an elevation
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // of zero.This is done to improve the resolution of
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // the Fourier Transform, which will be computed
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // later.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int numFilterRows = filter.length;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int numFilterCols = filter[0].length;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int rows = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int cols = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Make the size of the surface ten pixels larger than
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // the convolution filter with a minimum size of
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // 32x32 pixels.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(numFilterRows &lt; 22){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; rows = 32;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }else{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; rows = numFilterRows + 10;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end else
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(numFilterCols &lt; 22){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cols = 32;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }else{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cols = numFilterCols + 10;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end else
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Create the surface, which will be initialized to
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // all zero values.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[][] filterSurface = new double[rows][cols];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Place the convolution filter in the center of the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // surface.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; numFilterRows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; numFilterCols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; filterSurface[row + (rows - numFilterRows)/2]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [col + (cols - numFilterCols)/2] =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; filter[row][col];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end outer loop
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Display the filter and the surface on which it
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // resides as a 3D plot in a color contour format.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; new ImgMod29(filterSurface,4,true,1);
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Get and display the 2D Fourier Transform of the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // convolution filter.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Prepare arrays to receive the results of the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // Fourier transform.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[][] real = new double[rows][cols];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[][] imag = new double[rows][cols];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[][] amp = new double[rows][cols];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Perform the 2D Fourier transform.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ImgMod30.xform2D(filterSurface,real,imag,amp);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Ignore the real and imaginary results.&nbsp; Prepare the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // amplitude spectrum for more-effective plotting by
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // shifting the origin to the center in wave-number
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // space.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[][] shiftedAmplitudeSpect =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ImgMod30.shiftOrigin(amp);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Get and display the minimum and maximum wave number
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // values.&nbsp; This is useful because the way that the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // wave number plots are normalized. it is not
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // possible to infer the flatness or lack thereof of
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // the wave number surface simply by viewing the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // plot.&nbsp; The colors that describe the elevations
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // always range from black at the minimum to white at
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // the maximum, with different colors in between
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // regardless of the difference between the minimum
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // and the maximum.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double maxValue = -Double.MAX_VALUE;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double minValue = Double.MAX_VALUE;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; rows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; cols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(amp[row][col] &gt; maxValue){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; maxValue = amp[row][col];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end if
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(amp[row][col] &lt; minValue){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; minValue = amp[row][col];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end if
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end outer loop
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; System.out.println("minValue: " + minValue);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; System.out.println("maxValue: " + maxValue);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; System.out.println("ratio: " + maxValue/minValue);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Generate and display the wave-number response
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // graph by plotting the 3D surface on the computer
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // screen.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; new ImgMod29(shiftedAmplitudeSpect,4,true,1);

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Perform the convolution.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output = ImgMod32a.convolve(working3D,filter);
&nbsp;&nbsp;&nbsp; }//end else
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Scale output color planes.&nbsp; Color planes will be
&nbsp;&nbsp;&nbsp; // scaled only if the corresponding scale factor in the
&nbsp;&nbsp;&nbsp; // TextField has a value other than 1.0.&nbsp; Otherwise,
&nbsp;&nbsp;&nbsp; // there is no point in consuming computer time to do
&nbsp;&nbsp;&nbsp; // the scaling.
&nbsp;&nbsp;&nbsp; if(!redField.getText().equals(1.0)){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double scale = Double.parseDouble(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; redField.getText());
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; scaleColorPlane(output,1,scale);
&nbsp;&nbsp;&nbsp; }//end if on redField
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; if(!greenField.getText().equals(1.0)){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double scale = Double.parseDouble(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; greenField.getText());
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; scaleColorPlane(output,2,scale);
&nbsp;&nbsp;&nbsp; }//end if on greenField
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; if(!blueField.getText().equals(1.0)){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double scale = Double.parseDouble(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; blueField.getText());
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; scaleColorPlane(output,3,scale);
&nbsp;&nbsp;&nbsp; }//end if on blueField
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Return a reference to the array containing the image,
&nbsp;&nbsp;&nbsp; // which has undergone both convolution filtering and
&nbsp;&nbsp;&nbsp; // color filtering.
&nbsp;&nbsp;&nbsp; return output;

&nbsp; }//end processImg method
&nbsp; //-----------------------------------------------------//
&nbsp;
&nbsp;
&nbsp; //The purpose of this method is to scale every color
&nbsp; // value in a specified color plane in the int version
&nbsp; // of an image pixel array by a specified scale factor.
&nbsp; // The scaled values are clipped at 255 and 0.
&nbsp; static void scaleColorPlane(int[][][] inputImageArray,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int plane,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double scale){
&nbsp;&nbsp;&nbsp; int numImgRows = inputImageArray.length;
&nbsp;&nbsp;&nbsp; int numImgCols = inputImageArray[0].length;
&nbsp;&nbsp;&nbsp; //Scale each color value
&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; numImgRows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; numImgCols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double result =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; inputImageArray[row][col][plane] * scale;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(result &gt; 255){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; result = 255;//clip large numbers
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end if
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(result &lt; 0){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; result = 0;//clip negative numbers
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end if
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Cast the result to int and put back into the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // color plane.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; inputImageArray[row][col][plane] = (int)result;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp; }//end outer loop
&nbsp; }//end scaleColorPlane
&nbsp; //-----------------------------------------------------//
&nbsp; /*
&nbsp; The purpose of this method is to read the contents of a
&nbsp;&nbsp; text file and to use those contents to create a 2D
&nbsp;&nbsp;&nbsp; convolution filter by populating a 2D array with the
&nbsp;&nbsp;&nbsp; contents of the text file.

&nbsp; The text file consists of a series of lines with each
&nbsp;&nbsp; line containing a single string of characters.
&nbsp;
&nbsp; Whitespace is allowed before and after the strings on a
&nbsp;&nbsp; line.
&nbsp;
&nbsp; Lines containing empty strings are ignored.
&nbsp;
&nbsp; The file is allowed to contain comments, which must begin
&nbsp; with //
&nbsp;
&nbsp; Comments are displayed on the standard output device.
&nbsp;
&nbsp; Comments in the text file are ignored and do not factor
&nbsp;&nbsp; into the programming comments that follow.
&nbsp;
&nbsp; The first two strings must be convertible to type int and
&nbsp;&nbsp; every other string must be convertible to type double.
&nbsp;
&nbsp; The first string specifies the number of rows in the 2D
&nbsp; filter as type int.
&nbsp;
&nbsp; The second string specifies the number of columns in the
&nbsp; 2D filter as type int.
&nbsp;
&nbsp; The remaining strings specify the filter coefficients as
&nbsp; type double in row-column order.

&nbsp; The total number of strings must be (2 + rows*cols).
&nbsp; Otherwise, the program will throw an exception and abort.

&nbsp; Here are the results for a test file named Filter01.txt.
&nbsp; The file contents are shown below. Note that the comment
&nbsp; indicators are comment indicators in the file and are
&nbsp; not comment indicators in this program.

&nbsp; //File Filter01.txt
&nbsp; //This is a test file, and this is a comment.
&nbsp; //This is a high-pass filter in the wave-number domain.
&nbsp; 3
&nbsp; 3

&nbsp; -1
&nbsp; -1
&nbsp; -1

&nbsp; -1
&nbsp;&nbsp; 8
&nbsp; -1

&nbsp; -1
&nbsp; //This is another comment put here for test purposes.
&nbsp; //There is whitespace following the next item.
&nbsp; -1
&nbsp; -1

&nbsp; The text output produced by the method for this input
&nbsp; file is shown below.

&nbsp; //File Filter01.txt
&nbsp; //This is a test file, and this is a comment.
&nbsp; //This is a high-pass filter in the wave-number domain.
&nbsp; //This is another comment put here for test purposes.
&nbsp; //There is whitespace following the next item.
&nbsp; -1.0 -1.0 -1.0
&nbsp; -1.0 8.0 -1.0
&nbsp; -1.0 -1.0 -1.0
&nbsp; */
&nbsp; double[][] getFilter(String fileName){
&nbsp;&nbsp;&nbsp; double[][] filter = new double[0][0];
&nbsp;&nbsp;&nbsp; try{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; BufferedReader inData =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; new BufferedReader(new FileReader(fileName));

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; String data;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int count = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int rows = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int cols = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int row = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int col = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; while((data = inData.readLine()) != null){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(data.startsWith("//")){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Display and ignore comments.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; System.out.println(data);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }else{//Not a comment
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(!data.equals("")){//ignore empty strings
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; count++;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(count == 1){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Get row dimension value. Trim whitespace in
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // the process.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; rows = Integer.parseInt(data.trim());
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }else if(count == 2){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Get column dimension value. Trim whitespace
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // in the process.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cols = Integer.parseInt(data.trim());
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Create a new array object to be populated
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // with the remaining contents of the file.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; filter = new double[rows][cols];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }else{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Populate the filter array with the contents
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // of the file. Trim whitespace in the
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // process.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; row = (count-3)/cols;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; col = (count-3)%cols;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; filter[row][col] =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Double.parseDouble(data.trim());
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end else
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end if on empty strings
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end else, not a comment
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end while data != null
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; inData.close();//Close the input stream.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //Display the filter coefficient values in a
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // rectangular array format.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int outCnt = 0;outCnt &lt; rows;outCnt++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int inCnt = 0;inCnt &lt; cols;inCnt++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; System.out.print(filter[outCnt][inCnt] + " ");
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end for loop
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; System.out.println();//new line
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end for loop
&nbsp;&nbsp;&nbsp; }catch(IOException e){}

&nbsp;&nbsp;&nbsp; return filter;//Return the filter.
&nbsp; }//end getFilter
&nbsp; //-----------------------------------------------------//
}//end class ImgMod33a<br><br><b><font face="Courier New,Courier">Listing 5</font></b></pre>
			</td>
		</tr>
	</tbody>
</table>
<p></p>
<p>&nbsp;</p>
<table border="1" cols="1" width="482" bgcolor="#ffff00">
	<tbody>
		<tr>
			<td>
			<pre>/*File ImgMod32a.java
Copyright 2005, R.G.Baldwin

This class is similar to ImgMod32 except that it uses a
different normalization scheme when converting convolution
results back to eight-bit unsigned values.&nbsp; The
normalization scheme causes the mean and the RMS of the
output to match the mean and the RMS of the input.&nbsp; Then it
sets negative values to 0 and sets values greater than 255
to 255.

This class provides a general purpose 2D image convolution
capability in the form of a static method named convolve.

The convolve method that is defined in this class receives
an incoming 3D array of image pixel data of type int
containing four planes. The format of this image data is
consistent with the format for image data used in the
program named ImgMod02a.

The planes are identified as follows:
0 - alpha or transparency data
1 - red color data
2 - green color data
3 - blue color data

The convolve method also receives an incoming 2D array of
type double containing the weights that make up a 2D
convolution filter.

The pixel values on each color plane are convolved
separately with the same convolution filter.&nbsp;

The results are normalized so as to cause the filtered
output to fall within the range from 0 to 255.

The values on the alpha plane are not modified.

The method returns a filtered 3D pixel array in the same
format as the incoming pixel array.&nbsp; The returned array
contains filtered values for each of the three color
planes.

The method does not modify the contents of the incoming
array of pixel data.

An unfiltered dead zone equal to half the filter length is
left around the perimeter of the filtered image to avoid
any attempt to perform convolution using data outside the
bounds of the image.

Although this class is intended to be used to implement 2D
convolution in other programs, a main method is provided so
that the class can be tested in a stand-alone mode.&nbsp; In
addition, the main method ilustrates the relationship
between convolution in the image domain and the
wave-number spectrum of the raw and filtered image.

When run as a stand-alone program, this class displays raw
surfaces, filtered surfaces, and the Fourier Transform of
both raw and filtered surfaces.&nbsp; See the details in the
comments in the main method.&nbsp; The program also displays
some text on the command-line screen.

Execution of the main method in this class requires access
to the following classes, plus some inner classed defined
within these classes:

ImgMod29.class - Displays 3D surfaces
ImgMod30.class - Provides 2D Fourier Transform
ImgMod32a.class - This class

Tested using J2SE 5.0 and WinXP
**********************************************************/

class ImgMod32a{
&nbsp; //The primary purpose of this main method is to test the
&nbsp; // class in a stand-alone mode.&nbsp; A secondary purpose is
&nbsp; // to illustrate the relationship between convolution
&nbsp; // filtering in the image domain and the spectrum of the
&nbsp; // raw and filtered images in the wave-number domain.
&nbsp;
&nbsp; //The code in this method creates a nine-point
&nbsp; // convolution filter and applies it to three&nbsp; different
&nbsp; // surfaces.&nbsp; The convolution filter has a dc response of
&nbsp; // zero with a high response at the folding wave numbers.
&nbsp; // Hence, it tends to have the characteristic of a
&nbsp; // sharpening or edge-detection filter.&nbsp;

&nbsp; //The three surfaces consist of:
&nbsp; // 1. A single impulse
&nbsp; // 2. A 3x3 square
&nbsp; // 3. A 5x5 square
&nbsp;
&nbsp; //The three surfaces are constructed on what ordinarily
&nbsp; // is considered to be the color planes in an image.
&nbsp; // However, in this case, the surfaces have nothing in
&nbsp; // particular to do with color.&nbsp; They simply&nbsp; represent
&nbsp; // three surfaces on which it is convenient to
&nbsp; // synthetically construct 3D shapes that are useful for
&nbsp; // testing and illustrating the image convolution
&nbsp; // concepts.&nbsp; But, in order to be consistent with the
&nbsp; // concept of color planes, the comments in the main
&nbsp; // method frequently refer to the values as color values.
&nbsp;
&nbsp; //In addition to the display of some text material on the
&nbsp; // command-line screen, the program displays twelve
&nbsp; // different graphs.&nbsp; They are described as follows:
&nbsp;
&nbsp; //The following surfaces are displayed:
&nbsp; // 1. The impulse
&nbsp; // 2. The raw 3x3 square
&nbsp; // 3. The raw 5x5 square
&nbsp; // 4. The filtered impulse
&nbsp; // 5. The filtered 3x3 square
&nbsp; // 6. The filtered 5x5 square
&nbsp;
&nbsp; // In addition, a 2D Fourier Transform is computed and
&nbsp; // the results are displayed for the following surfaces:
&nbsp; // 1. The impulse
&nbsp; // 2. The 3x3 square input
&nbsp; // 3. The 5x5 square input
&nbsp; // 4. The filtered impulse
&nbsp; // 5. The filtered 3x3 square
&nbsp; // 6. The filtered 5x5 square
&nbsp; public static void main(String[] args){
&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Create a 2D convolution filter having nine weights in
&nbsp;&nbsp;&nbsp; // a square.
&nbsp;&nbsp;&nbsp; double[][] filter = {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {-1,-1,-1},
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {-1, 8,-1},
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {-1,-1,-1}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; };

&nbsp;&nbsp;&nbsp; //Create synthetic image pixel data.&nbsp; Use a surface
&nbsp;&nbsp;&nbsp; // that is sufficiently large to produce good
&nbsp;&nbsp;&nbsp; // resolution in the 2D Fourier Transform.&nbsp; Zero-fill
&nbsp;&nbsp;&nbsp; // those portions of the surface that don't describe
&nbsp;&nbsp;&nbsp; // the shapes of interest.
&nbsp;&nbsp;&nbsp; int rowLim = 31;
&nbsp;&nbsp;&nbsp; int colLim = 31;
&nbsp;&nbsp;&nbsp; int[][][] threeDPix = new int[rowLim][colLim][4];

&nbsp;&nbsp;&nbsp; //Place a single impulse in the red plane 1
&nbsp;&nbsp;&nbsp; threeDPix[3][3][1] = 255;
&nbsp;
&nbsp;&nbsp;&nbsp; //Place a 3x3 square in the green plane 2
&nbsp;&nbsp;&nbsp; threeDPix[2][2][2] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[2][3][2] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[2][4][2] = 255;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; threeDPix[3][2][2] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[3][3][2] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[3][4][2] = 255;
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; threeDPix[4][2][2] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[4][3][2] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[4][4][2] = 255;&nbsp;&nbsp;

&nbsp;&nbsp;&nbsp; //Place a 5x5 square in the blue plane 3
&nbsp;&nbsp;&nbsp; threeDPix[2][2][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[2][3][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[2][4][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[2][5][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[2][6][3] = 255;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; threeDPix[3][2][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[3][3][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[3][4][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[3][5][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[3][6][3] = 255;
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; threeDPix[4][2][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[4][3][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[4][4][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[4][5][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[4][6][3] = 255;
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; threeDPix[5][2][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[5][3][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[5][4][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[5][5][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[5][6][3] = 255;
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; threeDPix[6][2][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[6][3][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[6][4][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[6][5][3] = 255;
&nbsp;&nbsp;&nbsp; threeDPix[6][6][3] = 255;
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Perform the convolution.
&nbsp;&nbsp;&nbsp; int[][][] output = convolve(threeDPix,filter);
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //All of the remaining code in the main method is used
&nbsp;&nbsp;&nbsp; // to display material that is used to test and to
&nbsp;&nbsp;&nbsp; // illustrate the convolution process.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Remove the mean values from the filtered color planes
&nbsp;&nbsp;&nbsp; // before plotting and computing spectra.

&nbsp;&nbsp;&nbsp; //First convert the color values from int to double.
&nbsp;&nbsp;&nbsp; double[][][] outputDouble = intToDouble(output);
&nbsp;&nbsp;&nbsp; //Now remove the mean color value from each plane.
&nbsp;&nbsp;&nbsp; removeMean(outputDouble,1);
&nbsp;&nbsp;&nbsp; removeMean(outputDouble,2);
&nbsp;&nbsp;&nbsp; removeMean(outputDouble,3);

&nbsp;&nbsp;&nbsp; //Convert the raw image data from int to double
&nbsp;&nbsp;&nbsp; double[][][] rawDouble = intToDouble(threeDPix);

&nbsp;&nbsp;&nbsp; //Get and plot the raw red plane 1.&nbsp; This is an input
&nbsp;&nbsp;&nbsp; // to the filter process.
&nbsp;&nbsp;&nbsp; //Get the plane of interest.
&nbsp;&nbsp;&nbsp; double[][] temp = getPlane(rawDouble,1);
&nbsp;&nbsp;&nbsp; //Generate and display the graph by plotting the 3D
&nbsp;&nbsp;&nbsp; // surface on the computer screen.
&nbsp;&nbsp;&nbsp; new ImgMod29(temp,4,true,1);

&nbsp;&nbsp;&nbsp; //Get and display the 2D Fourier Transform of plane 1.
&nbsp;&nbsp;&nbsp; //Get the plane of interest.
&nbsp;&nbsp;&nbsp; temp = getPlane(rawDouble,1);
&nbsp;&nbsp;&nbsp; //Prepare arrays to receive the results of the Fourier
&nbsp;&nbsp;&nbsp; // transform.
&nbsp;&nbsp;&nbsp; double[][] real = new double[rowLim][colLim];
&nbsp;&nbsp;&nbsp; double[][] imag = new double[rowLim][colLim];
&nbsp;&nbsp;&nbsp; double[][] amp = new double[rowLim][colLim];
&nbsp;&nbsp;&nbsp; //Perform the 2D Fourier transform.
&nbsp;&nbsp;&nbsp; ImgMod30.xform2D(temp,real,imag,amp);
&nbsp;&nbsp;&nbsp; //Ignore the real and imaginary results.&nbsp; Prepare the
&nbsp;&nbsp;&nbsp; // amplitude spectrum for more-effective plotting by
&nbsp;&nbsp;&nbsp; // shifting the origin to the center in wave-number
&nbsp;&nbsp;&nbsp; // space.
&nbsp;&nbsp;&nbsp; double[][] shiftedAmplitudeSpect =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ImgMod30.shiftOrigin(amp);
&nbsp;&nbsp;&nbsp; //Generate and display the graph by plotting the 3D
&nbsp;&nbsp;&nbsp; // surface on the computer screen.
&nbsp;&nbsp;&nbsp; new ImgMod29(shiftedAmplitudeSpect,4,true,1);
&nbsp;&nbsp;&nbsp;

&nbsp;&nbsp;&nbsp; //Get and plot the filtered plane 1.&nbsp; This is the
&nbsp;&nbsp;&nbsp; // impulse response of the convolution filter.
&nbsp;&nbsp;&nbsp; temp = getPlane(outputDouble,1);
&nbsp;&nbsp;&nbsp; new ImgMod29(temp,4,true,1);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Get and display the transform of filtered plane 1.
&nbsp;&nbsp;&nbsp; // This is the transform of the impulse response of
&nbsp;&nbsp;&nbsp; // the convolution filter.
&nbsp;&nbsp;&nbsp; temp = getPlane(outputDouble,1);
&nbsp;&nbsp;&nbsp; real = new double[rowLim][colLim];
&nbsp;&nbsp;&nbsp; imag = new double[rowLim][colLim];
&nbsp;&nbsp;&nbsp; amp = new double[rowLim][colLim];
&nbsp;&nbsp;&nbsp; ImgMod30.xform2D(temp,real,imag,amp);
&nbsp;&nbsp;&nbsp; shiftedAmplitudeSpect = ImgMod30.shiftOrigin(amp);
&nbsp;&nbsp;&nbsp; new ImgMod29(shiftedAmplitudeSpect,4,true,1);


&nbsp;&nbsp;&nbsp; //Get and plot the raw green plane 2.&nbsp; This is another
&nbsp;&nbsp;&nbsp; // input to the filter process.
&nbsp;&nbsp;&nbsp; temp = getPlane(rawDouble,2);
&nbsp;&nbsp;&nbsp; new ImgMod29(temp,4,true,1);

&nbsp;&nbsp;&nbsp; //Get and display the transform of plane 2.
&nbsp;&nbsp;&nbsp; temp = getPlane(rawDouble,2);
&nbsp;&nbsp;&nbsp; real = new double[rowLim][colLim];
&nbsp;&nbsp;&nbsp; imag = new double[rowLim][colLim];
&nbsp;&nbsp;&nbsp; amp = new double[rowLim][colLim];
&nbsp;&nbsp;&nbsp; ImgMod30.xform2D(temp,real,imag,amp);
&nbsp;&nbsp;&nbsp; shiftedAmplitudeSpect = ImgMod30.shiftOrigin(amp);
&nbsp;&nbsp;&nbsp; new ImgMod29(shiftedAmplitudeSpect,4,true,1);
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Get and plot the filtered plane 2.
&nbsp;&nbsp;&nbsp; temp = getPlane(outputDouble,2);
&nbsp;&nbsp;&nbsp; new ImgMod29(temp,4,true,1);
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Get and display the transform of filtered plane 2.
&nbsp;&nbsp;&nbsp; temp = getPlane(outputDouble,2);
&nbsp;&nbsp;&nbsp; real = new double[rowLim][colLim];
&nbsp;&nbsp;&nbsp; imag = new double[rowLim][colLim];
&nbsp;&nbsp;&nbsp; amp = new double[rowLim][colLim];
&nbsp;&nbsp;&nbsp; ImgMod30.xform2D(temp,real,imag,amp);
&nbsp;&nbsp;&nbsp; shiftedAmplitudeSpect = ImgMod30.shiftOrigin(amp);
&nbsp;&nbsp;&nbsp; new ImgMod29(shiftedAmplitudeSpect,4,true,1);


&nbsp;&nbsp;&nbsp; //Get and plot the raw blue plane 3.&nbsp; This is another
&nbsp;&nbsp;&nbsp; // input to the filter process.
&nbsp;&nbsp;&nbsp; temp = getPlane(rawDouble,3);
&nbsp;&nbsp;&nbsp; new ImgMod29(temp,4,true,1);

&nbsp;&nbsp;&nbsp; //Get and display the transform of plane 3.
&nbsp;&nbsp;&nbsp; temp = getPlane(rawDouble,3);
&nbsp;&nbsp;&nbsp; real = new double[rowLim][colLim];
&nbsp;&nbsp;&nbsp; imag = new double[rowLim][colLim];
&nbsp;&nbsp;&nbsp; amp = new double[rowLim][colLim];
&nbsp;&nbsp;&nbsp; ImgMod30.xform2D(temp,real,imag,amp);
&nbsp;&nbsp;&nbsp; shiftedAmplitudeSpect = ImgMod30.shiftOrigin(amp);
&nbsp;&nbsp;&nbsp; new ImgMod29(shiftedAmplitudeSpect,4,true,1);
&nbsp;&nbsp;&nbsp;

&nbsp;&nbsp;&nbsp; //Get and plot the filtered plane 3.
&nbsp;&nbsp;&nbsp; temp = getPlane(outputDouble,3);
&nbsp;&nbsp;&nbsp; new ImgMod29(temp,4,true,1);
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Get and display the transform of filtered plane 3
&nbsp;&nbsp;&nbsp; temp = getPlane(outputDouble,3);
&nbsp;&nbsp;&nbsp; real = new double[rowLim][colLim];
&nbsp;&nbsp;&nbsp; imag = new double[rowLim][colLim];
&nbsp;&nbsp;&nbsp; amp = new double[rowLim][colLim];
&nbsp;&nbsp;&nbsp; ImgMod30.xform2D(temp,real,imag,amp);
&nbsp;&nbsp;&nbsp; shiftedAmplitudeSpect = ImgMod30.shiftOrigin(amp);
&nbsp;&nbsp;&nbsp; new ImgMod29(shiftedAmplitudeSpect,4,true,1);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp; }//end main
&nbsp; //-----------------------------------------------------//
&nbsp;
&nbsp; //The purpose of this method is to extract a color plane
&nbsp; // from the double version of an image and to return it
&nbsp; // as a 2D array of type double.&nbsp; This is useful, for
&nbsp; // example, for performing Fourier transforms on the data
&nbsp; // in a color plane.
&nbsp; //This method is used only in support of the operations
&nbsp; // in the main method.&nbsp; It is not required for performing
&nbsp; // the convolution.
&nbsp;
&nbsp; public static double[][] getPlane(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[][][] threeDPixDouble,int plane){
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; int numImgRows = threeDPixDouble.length;
&nbsp;&nbsp;&nbsp; int numImgCols = threeDPixDouble[0].length;
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Create an empty output array of the same
&nbsp;&nbsp;&nbsp; // size as a single plane in the incoming array of
&nbsp;&nbsp;&nbsp; // pixels.
&nbsp;&nbsp;&nbsp; double[][] output =new double[numImgRows][numImgCols];

&nbsp;&nbsp;&nbsp; //Copy the values from the specified plane to the
&nbsp;&nbsp;&nbsp; // double array converting them to type double in the
&nbsp;&nbsp;&nbsp; // process.
&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; numImgRows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; numImgCols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output[row][col] =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; threeDPixDouble[row][col][plane];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end loop on col
&nbsp;&nbsp;&nbsp; }//end loop on row
&nbsp;&nbsp;&nbsp; return output;
&nbsp; }//end getPlane
&nbsp; //-----------------------------------------------------//

&nbsp; //The purpose of this method is to get and remove the
&nbsp; // mean value from a specified color plane in the double
&nbsp; // version of an image pixel array.&nbsp; The method returns
&nbsp; // the mean value that was removed so that it can be
&nbsp; // saved by the calling method and restored later.
&nbsp; static double removeMean(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[][][] inputImageArray,int plane){
&nbsp;&nbsp;&nbsp; int numImgRows = inputImageArray.length;
&nbsp;&nbsp;&nbsp; int numImgCols = inputImageArray[0].length;
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Compute the mean color value
&nbsp;&nbsp;&nbsp; double sum = 0;
&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; numImgRows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; numImgCols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sum += inputImageArray[row][col][plane];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp; }//end outer loop
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; double mean = sum/(numImgRows*numImgCols);
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Remove the mean value from each pixel value.
&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; numImgRows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; numImgCols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; inputImageArray[row][col][plane] -= mean;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp; }//end outer loop
&nbsp;&nbsp;&nbsp; return mean;
&nbsp; }//end removeMean
&nbsp; //-----------------------------------------------------//
&nbsp;
&nbsp; //The purpose of this method is to get and return the
&nbsp; // mean value from a specified color plane in the double
&nbsp; // version of an image pixel array.
&nbsp; static double getMean(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[][][] inputImageArray,int plane){
&nbsp;&nbsp;&nbsp; int numImgRows = inputImageArray.length;
&nbsp;&nbsp;&nbsp; int numImgCols = inputImageArray[0].length;
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Compute the mean color value
&nbsp;&nbsp;&nbsp; double sum = 0;
&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; numImgRows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; numImgCols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sum += inputImageArray[row][col][plane];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp; }//end outer loop
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; double mean = sum/(numImgRows*numImgCols);
&nbsp;&nbsp;&nbsp; return mean;
&nbsp; }//end getMean
&nbsp; //-----------------------------------------------------//
&nbsp;
&nbsp; //The purpose of this method is to add a constant to
&nbsp; // every color value in a specified color plane in the
&nbsp; // double version of an image pixel array.&nbsp; For example,
&nbsp; // this method can be used to restore the mean value to a
&nbsp; // color plane that was removed earlier.
&nbsp; static void addConstantToColor(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[][][] inputImageArray,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int plane,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double constant){
&nbsp;&nbsp;&nbsp; int numImgRows = inputImageArray.length;
&nbsp;&nbsp;&nbsp; int numImgCols = inputImageArray[0].length;
&nbsp;&nbsp;&nbsp; //Add the constant value to each color value
&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; numImgRows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; numImgCols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; inputImageArray[row][col][plane] =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; inputImageArray[row][col][plane] + constant;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp; }//end outer loop
&nbsp; }//end addConstantToColor
&nbsp; //-----------------------------------------------------//
&nbsp;
&nbsp; //The purpose of this method is to scale every color
&nbsp; // value in a specified color plane in the double version
&nbsp; // of an image pixel array by a specified scale factor.
&nbsp; static void scaleColorPlane(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[][][] inputImageArray,int plane,double scale){
&nbsp;&nbsp;&nbsp; int numImgRows = inputImageArray.length;
&nbsp;&nbsp;&nbsp; int numImgCols = inputImageArray[0].length;
&nbsp;&nbsp;&nbsp; //Scale each color value
&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; numImgRows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; numImgCols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; inputImageArray[row][col][plane] =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; inputImageArray[row][col][plane] * scale;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp; }//end outer loop
&nbsp; }//end scaleColorPlane
&nbsp; //-----------------------------------------------------//
&nbsp;
&nbsp; //The purpose of this method is to convert an image pixel
&nbsp; // array (where the pixel values are represented as type
&nbsp; // int) to an image pixel array where the pixel values
&nbsp; // are reprented as type double.
&nbsp; static double[][][] intToDouble(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int[][][] inputImageArray){
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; int numImgRows = inputImageArray.length;
&nbsp;&nbsp;&nbsp; int numImgCols = inputImageArray[0].length;
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; double[][][] outputImageArray =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; new double[numImgRows][numImgCols][4];
&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; numImgRows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; numImgCols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; outputImageArray[row][col][0] =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; inputImageArray[row][col][0];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; outputImageArray[row][col][1] =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; inputImageArray[row][col][1];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; outputImageArray[row][col][2] =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; inputImageArray[row][col][2];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; outputImageArray[row][col][3] =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; inputImageArray[row][col][3];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp; }//end outer loop
&nbsp;&nbsp;&nbsp; return outputImageArray;
&nbsp; }//end intToDouble
&nbsp; //-----------------------------------------------------//

&nbsp; //The purpose of this method is to convert an image pixel
&nbsp; // array (where the pixel values are represented as type
&nbsp; // double) to an image pixel array where the pixel values
&nbsp; // are reprented as type int.
&nbsp; static int[][][] doubleToInt(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[][][] inputImageArray){
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; int numImgRows = inputImageArray.length;
&nbsp;&nbsp;&nbsp; int numImgCols = inputImageArray[0].length;
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; int[][][] outputImageArray =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; new int[numImgRows][numImgCols][4];
&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; numImgRows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; numImgCols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; outputImageArray[row][col][0] =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (int)inputImageArray[row][col][0];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; outputImageArray[row][col][1] =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (int)inputImageArray[row][col][1];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; outputImageArray[row][col][2] =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (int)inputImageArray[row][col][2];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; outputImageArray[row][col][3] =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (int)inputImageArray[row][col][3];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp; }//end outer loop
&nbsp;&nbsp;&nbsp; return outputImageArray;
&nbsp; }//end doubleToInt
&nbsp; //-----------------------------------------------------//

&nbsp; //The purpose of this method is to clip all negative
&nbsp; // color values in a plane to a value of 0.
&nbsp; static void clipToZero(double[][][] inputImageArray,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int plane){
&nbsp;&nbsp;&nbsp; int numImgRows = inputImageArray.length;
&nbsp;&nbsp;&nbsp; int numImgCols = inputImageArray[0].length;
&nbsp;&nbsp;&nbsp; //Do the clip
&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; numImgRows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; numImgCols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(inputImageArray[row][col][plane] &lt; 0){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; inputImageArray[row][col][plane] = 0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end if
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp; }//end outer loop
&nbsp; }//end clipToZero
&nbsp; //-----------------------------------------------------//
&nbsp; //The purpose of this method is to clip all color values
&nbsp; // in a plane that are greater than 255 to a value
&nbsp; // of 255.
&nbsp; static void clipTo255(double[][][] inputImageArray,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int plane){
&nbsp;&nbsp;&nbsp; int numImgRows = inputImageArray.length;
&nbsp;&nbsp;&nbsp; int numImgCols = inputImageArray[0].length;
&nbsp;&nbsp;&nbsp; //Do the clip
&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; numImgRows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; numImgCols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(inputImageArray[row][col][plane] &gt; 255){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; inputImageArray[row][col][plane] = 255;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end if
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp; }//end outer loop
&nbsp; }//end clipTo255
&nbsp; //-----------------------------------------------------//
&nbsp;
&nbsp; //The purpose of this method is to get and return the
&nbsp; // RMS value from a specified color plane in the double
&nbsp; // version of an image pixel array.
&nbsp; static double getRms(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double[][][] inputImageArray,int plane){
&nbsp;&nbsp;&nbsp; int numImgRows = inputImageArray.length;
&nbsp;&nbsp;&nbsp; int numImgCols = inputImageArray[0].length;
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Compute the RMS color value
&nbsp;&nbsp;&nbsp; double sumSq = 0;
&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; numImgRows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; numImgCols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sumSq += (inputImageArray[row][col][plane]*
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; inputImageArray[row][col][plane]);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp; }//end outer loop
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; double mean = sumSq/(numImgRows*numImgCols);
&nbsp;&nbsp;&nbsp; double rms = Math.sqrt(mean);
&nbsp;&nbsp;&nbsp; return rms;
&nbsp; }//end getRms
&nbsp; //-----------------------------------------------------//
&nbsp;
&nbsp; //This method applies an incoming 2D convolution filter
&nbsp; // to each color plane in an incoming 3D array of pixel
&nbsp; // data and returns a filtered 3D array of pixel data.
&nbsp; //The convolution filter is applied separately to each
&nbsp; // color plane.
&nbsp; //The alpha plane is not modified.
&nbsp; //The output is normalized so as to guarantee that the
&nbsp; // output color values fall within the range from 0
&nbsp; // to 255.&nbsp; This is accomplished by causing the mean and
&nbsp; // the RMS of the color values in each output color plane
&nbsp; // to match the mean and the RMS of the color values in
&nbsp; // the corresponding input color plane.&nbsp; Then, all
&nbsp; // negative color values are set to a value of 0 and all
&nbsp; // color values greater than 255 are set to 255.
&nbsp; //The convolution filter is passed to the method as a 2D
&nbsp; // array of type double.&nbsp; All convolution and
&nbsp; // normalization arithmetic is performed as type double.
&nbsp; //The normalized results are converted to type int before
&nbsp; // returning them to the calling method.
&nbsp; //This method does not modify the contents of the
&nbsp; // incoming array of pixel data.
&nbsp; //An unfiltered dead zone equal to half the filter length
&nbsp; // is left around the perimeter of the filtered image to
&nbsp; // avoid any attempt to perform convolution using data
&nbsp; // outside the bounds of the image.
&nbsp; public static int[][][] convolve(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int[][][] threeDPix,double[][] filter){
&nbsp;&nbsp;&nbsp; //Get the dimensions of the image and filter arrays.
&nbsp;&nbsp;&nbsp; int numImgRows = threeDPix.length;
&nbsp;&nbsp;&nbsp; int numImgCols = threeDPix[0].length;
&nbsp;&nbsp;&nbsp; int numFilRows = filter.length;
&nbsp;&nbsp;&nbsp; int numFilCols = filter[0].length;

&nbsp;&nbsp;&nbsp; //Display the dimensions of the image and filter
&nbsp;&nbsp;&nbsp; // arrays.
&nbsp;&nbsp;&nbsp; System.out.println("numImgRows = " + numImgRows);
&nbsp;&nbsp;&nbsp; System.out.println("numImgCols = " + numImgCols);
&nbsp;&nbsp;&nbsp; System.out.println("numFilRows = " + numFilRows);
&nbsp;&nbsp;&nbsp; System.out.println("numFilCols = " + numFilCols);

&nbsp;&nbsp;&nbsp; //Make a working copy of the incoming 3D pixel array to
&nbsp;&nbsp;&nbsp; // avoid making permanent changes to the original image
&nbsp;&nbsp;&nbsp; // data. Convert the pixel data to type double in the
&nbsp;&nbsp;&nbsp; // process.&nbsp; Will convert back to type int when
&nbsp;&nbsp;&nbsp; // returning from this method.
&nbsp;&nbsp;&nbsp; double[][][] work3D = intToDouble(threeDPix);
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Display the mean value for each color plane.
&nbsp;&nbsp;&nbsp; System.out.println(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Input red mean: " + getMean(work3D,1));
&nbsp;&nbsp;&nbsp; System.out.println(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Input green mean: " + getMean(work3D,2));
&nbsp;&nbsp;&nbsp; System.out.println(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Input blue mean: " + getMean(work3D,3));
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Remove the mean value from each color plane.&nbsp; Save
&nbsp;&nbsp;&nbsp; // the mean values for later restoration.
&nbsp;&nbsp;&nbsp; double redMean = removeMean(work3D,1);
&nbsp;&nbsp;&nbsp; double greenMean = removeMean(work3D,2);
&nbsp;&nbsp;&nbsp; double blueMean = removeMean(work3D,3);
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Get and save the input RMS value for later
&nbsp;&nbsp;&nbsp; // restoration.
&nbsp;&nbsp;&nbsp; double inputRedRms = getRms(work3D,1);
&nbsp;&nbsp;&nbsp; double inputGreenRms = getRms(work3D,2);
&nbsp;&nbsp;&nbsp; double inputBlueRms = getRms(work3D,3);
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Display the input RMS value
&nbsp;&nbsp;&nbsp; System.out.println("Input red RMS: " + inputRedRms);
&nbsp;&nbsp;&nbsp; System.out.println(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Input green RMS: " + inputGreenRms);
&nbsp;&nbsp;&nbsp; System.out.println("Input blue RMS: " + inputBlueRms);

&nbsp;&nbsp;&nbsp; //Create an empty output array of the same size as the
&nbsp;&nbsp;&nbsp; // incoming array of pixels.
&nbsp;&nbsp;&nbsp; double[][][] output =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; new double[numImgRows][numImgCols][4];
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Copy the alpha values directly to the output array.
&nbsp;&nbsp;&nbsp; // They will not be processed during the convolution
&nbsp;&nbsp;&nbsp; // process.
&nbsp;&nbsp;&nbsp; for(int row = 0;row &lt; numImgRows;row++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int col = 0;col &lt; numImgCols;col++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output[row][col][0] = work3D[row][col][0];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//end inner loop
&nbsp;&nbsp;&nbsp; }//end outer loop

//Because of the length of the following statements, and
// the width of this publication format, this format
// sacrifices indentation style for clarity. Otherwise,it
// would be necessary to break the statements into so many
// short lines that it would be very difficult to read
// them.

//Use nested for loops to perform a 2D convolution of each
// color plane with the 2D convolution filter.

for(int yReg = numFilRows-1;yReg &lt; numImgRows;yReg++){
&nbsp; for(int xReg = numFilCols-1;xReg &lt; numImgCols;xReg++){
&nbsp;&nbsp;&nbsp; for(int filRow = 0;filRow &lt; numFilRows;filRow++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for(int filCol = 0;filCol &lt; numFilCols;filCol++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output[yReg-numFilRows/2][xReg-numFilCols/2][1] +=
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; work3D[yReg-filRow][xReg-filCol][1] *
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; filter[filRow][filCol];

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output[yReg-numFilRows/2][xReg-numFilCols/2][2] +=
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; work3D[yReg-filRow][xReg-filCol][2] *
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; filter[filRow][filCol];

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output[yReg-numFilRows/2][xReg-numFilCols/2][3] +=
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; work3D[yReg-filRow][xReg-filCol][3] *
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; filter[filRow][filCol];

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }//End loop on filCol
&nbsp;&nbsp;&nbsp; }//End loop on filRow

&nbsp;&nbsp;&nbsp; //Divide the result at each point in the output by the
&nbsp;&nbsp;&nbsp; // number of filter coefficients.&nbsp; Note that in some
&nbsp;&nbsp;&nbsp; // cases, this is not helpful.&nbsp; For example, it is not
&nbsp;&nbsp;&nbsp; // helpful when a large number of the filter
&nbsp;&nbsp;&nbsp; // coefficients have a value of zero.
&nbsp;&nbsp;&nbsp; output[yReg-numFilRows/2][xReg-numFilCols/2][1] =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output[yReg-numFilRows/2][xReg-numFilCols/2][1]/
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (numFilRows*numFilCols);
&nbsp;&nbsp;&nbsp; output[yReg-numFilRows/2][xReg-numFilCols/2][2] =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output[yReg-numFilRows/2][xReg-numFilCols/2][2]/
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (numFilRows*numFilCols);
&nbsp;&nbsp;&nbsp; output[yReg-numFilRows/2][xReg-numFilCols/2][3] =
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output[yReg-numFilRows/2][xReg-numFilCols/2][3]/
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (numFilRows*numFilCols);

&nbsp; }//End loop on xReg
}//End loop on yReg

&nbsp;&nbsp;&nbsp; //Return to the normal indentation style.

&nbsp;&nbsp;&nbsp; //Remove any mean value resulting from computational
&nbsp;&nbsp;&nbsp; // inaccuracies.&nbsp; Should be very small.
&nbsp;&nbsp;&nbsp; removeMean(output,1);
&nbsp;&nbsp;&nbsp; removeMean(output,2);
&nbsp;&nbsp;&nbsp; removeMean(output,3);

&nbsp;&nbsp;&nbsp; //Get and save the RMS value of the output for each
&nbsp;&nbsp;&nbsp; // color plane.
&nbsp;&nbsp;&nbsp; double outputRedRms = getRms(output,1);
&nbsp;&nbsp;&nbsp; double outputGreenRms = getRms(output,2);
&nbsp;&nbsp;&nbsp; double outputBlueRms = getRms(output,3);
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; //Scale the output to cause the RMS value of the output
&nbsp;&nbsp;&nbsp; // to match the RMS value of the input
&nbsp;&nbsp;&nbsp; scaleColorPlane(output,1,inputRedRms/outputRedRms);
&nbsp;&nbsp;&nbsp; scaleColorPlane(output,2,inputGreenRms/outputGreenRms);
&nbsp;&nbsp;&nbsp; scaleColorPlane(output,3,inputBlueRms/outputBlueRms);

&nbsp;&nbsp;&nbsp; //Display the adjusted RMS values.&nbsp; Should match the
&nbsp;&nbsp;&nbsp; // input RMS values.
&nbsp;&nbsp;&nbsp; System.out.println(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Output red RMS: " + getRms(output,1));
&nbsp;&nbsp;&nbsp; System.out.println(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Output green RMS: " + getRms(output,2));
&nbsp;&nbsp;&nbsp; System.out.println(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Output blue RMS: " + getRms(output,3));

&nbsp;&nbsp;&nbsp; //Restore the original mean value to each color plane.
&nbsp;&nbsp;&nbsp; addConstantToColor(output,1,redMean);
&nbsp;&nbsp;&nbsp; addConstantToColor(output,2,greenMean);
&nbsp;&nbsp;&nbsp; addConstantToColor(output,3,blueMean);

&nbsp;&nbsp;&nbsp; System.out.println(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Output red mean: " + getMean(output,1));
&nbsp;&nbsp;&nbsp; System.out.println(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Output green mean: " + getMean(output,2));
&nbsp;&nbsp;&nbsp; System.out.println(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Output blue mean: " + getMean(output,3));
&nbsp;
&nbsp;&nbsp;&nbsp; //Guarantee that all color values fall within the range
&nbsp;&nbsp;&nbsp; // from 0 to 255.

&nbsp;&nbsp;&nbsp; //Clip all negative color values at zero and all color
&nbsp;&nbsp;&nbsp; // values that are greater than 255 at 255.
&nbsp;&nbsp;&nbsp; clipToZero(output,1);
&nbsp;&nbsp;&nbsp; clipToZero(output,2);
&nbsp;&nbsp;&nbsp; clipToZero(output,3);
&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; clipTo255(output,1);
&nbsp;&nbsp;&nbsp; clipTo255(output,2);
&nbsp;&nbsp;&nbsp; clipTo255(output,3);

&nbsp;&nbsp;&nbsp; //Return a reference to the array containing the
&nbsp;&nbsp;&nbsp; // filtered pixels.&nbsp; Convert the color
&nbsp;&nbsp;&nbsp; // values to type int before returning.
&nbsp;&nbsp;&nbsp; return doubleToInt(output);

&nbsp; }//end convolve method
&nbsp; //-----------------------------------------------------//
}//end class ImgMod32a<br><br><b><font face="Courier New,Courier">Listing 6</font></b></pre>
			</td>
		</tr>
	</tbody>
</table>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p><hr size="3" width="100%" align="center">
<p>Copyright 2006, Richard G. Baldwin.&nbsp; Reproduction in whole or in
part in any form or medium without express written permission from Richard
Baldwin is prohibited. </p>
<h4><a name="About_the_author">About the author</a></h4>
<p><b><a href="mailto:baldwin@dickbaldwin.com">Richard Baldwin</a></b><i>
  is a college professor (at Austin Community College in Austin, TX) and
private  consultant whose primary focus is a combination of Java, C#, and
XML. In addition to the many platform and/or language independent benefits
of Java and C# applications, he believes that a combination of Java, C#,
and XML will become the primary driving force in the delivery of structured
information on the Web.</i> </p>
<p><i>Richard has participated in numerous consulting projects and he frequently 
 provides onsite training at the high-tech companies located in and around 
 Austin, Texas.&nbsp; He is the author of Baldwin's Programming 
<a
 href="http://www.dickbaldwin.com">Tutorials</a>,
  which has gained a worldwide following among experienced and aspiring programmers.
  He has also published articles in JavaPro magazine.</i> </p>
<p><i>In addition to his programming expertise, Richard has many years of 
 practical experience in Digital Signal Processing (DSP).&nbsp; His first
 job after he earned his Bachelor's degree was doing DSP in the Seismic Research 
 Department of Texas Instruments.&nbsp; (TI is still a world leader in DSP.)&nbsp; 
 In the following years, he applied his programming and DSP expertise to other
 interesting areas including sonar and underwater acoustics.</i> </p>
<p><i>Richard holds an MSEE degree from Southern Methodist University and
  has many years of experience in the application of computer technology
to  real-world problems.</i> </p>
<p><i><a href="mailto:baldwin@dickbaldwin.com">Baldwin@DickBaldwin.com</a></i>
</p>
<p><b>Keywords</b><br>Java pixel convolution filter smooth blur image jpg 
gif color linear DSP 3D 
2D</p>
<p>-end- </p></body>
</html>