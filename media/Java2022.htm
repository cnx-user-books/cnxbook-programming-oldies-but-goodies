<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
<html>
<head>
   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
   <meta name="GENERATOR" content="Microsoft FrontPage 5.0">
   <title>... in Java by Richard G Baldwin</title>
</head>
<body link="#DD0000" vlink="#0000FF" alink="#FF0000" lang="EN-US">
<h2>
Java Sound, Creating, Playing, and Saving Synthetic Sounds</h2>
<i>Baldwin shows you how to create, play, and save synthetic sounds, making use 
of the features of the java.nio package to help with the byte manipulations.&nbsp; 
Seven different sample sounds are provided and explained.</i><p><b>Published:</b>&nbsp; 
June 17, 2003<br><b>By <a href="mailto:Baldwin@DickBaldwin.com">Richard G. Baldwin</a></b>
<p>Java Programming Notes # 2022<ul >
<li>
<a href="#Preface">Preface</a></li>
<li>
<a href="#Preview">Preview</a></li>

<li>
<a href="#Discussion and Sample Programs">Discussion and Sample Code</a></li>

<li>
<a href="#Run the program">Run the Program</a></li>

<li>
<a href="#Summary">Summary</a></li>

<li>
<a href="#Complete Program Listings">Complete Program Listing</a></li>
</ul>

<hr size=3 width="100%" align=center>
<center>
<h2>
<a NAME="Preface"></a>Preface</h2></center>
<p>
This  series of lessons is designed to teach you how to use the 
Java Sound API.&nbsp; The first lesson in the series was entitled 
<a href="http://www.developer.com/java/other/article.php/1565671">Java Sound, An 
Introduction</a>.&nbsp; The 
previous lesson was entitled
<a href="http://www.developer.com/java/other/article.php/2205521">Java Sound, 
Writing More Robust Audio Programs</a>.</p>
<p><font color="#FF0000"><b>Two types of audio data</b></font></p>
<p>
Two  different 
types of audio data are supported by the Java Sound API:<ul>
  <li>Sampled audio data</li>
  <li>Musical Instrument Digital Interface (MIDI) data</li>
  </ul>
  <p>The two types of audio data are very different.&nbsp;  I 
  am concentrating on sampled audio data at this point in time.&nbsp; I will defer 
  my discussion of 
      MIDI    until later.<p>
<b><font color="#FF0000">Viewing tip</font></b>
<p>You may find it useful to open another copy of this lesson in a separate
browser window.&nbsp; That will make it easier for you to scroll back and
forth among the different listings and figures while you are reading about
them.
<p><b><font color="#FF0000">Supplementary material</font></b>
<p>I recommend that you also study the other lessons in my extensive collection
of online Java tutorials.&nbsp; You will find those lessons published at
<a href="http://softwaredev.earthweb.com/java">Gamelan.com</a>.&nbsp;
However, as of the date of this writing, Gamelan doesn't maintain a consolidated
index of my Java tutorial lessons, and sometimes they are difficult to
locate there.&nbsp; You will find a consolidated index at <font color="#000000">
<a href="http://www.DickBaldwin.com">www.DickBaldwin.com</a>.</font><p>
<font color="#FF0000"><b>Material in earlier lessons</b></font><p>Earlier lessons in 
this series 
showed you how to:<ul>
  <li>Use methods of the <b>AudioSystem</b> class to write more robust audio 
  programs.</li>
  <li>Play back audio files, including those that you create using a Java 
  program, and those that you acquire from other sources.</li>
  <li>Capture microphone data into audio files types of your own choosing.</li>
  <li>Capture microphone data into a <b>ByteArrayOutputStream</b> object.</li>
  <li>Use the Sound API to play back previously captured audio data.</li>
  <li>Identify the mixers available on your system.</li>
  <li>Specify a 
  particular mixer for use in the acquisition of audio data from a microphone.</li>
  <li>Understand the use of lines and mixers in the Java Sound API.</li>
  </ul>
  <h2 align="center"><font color="#000000"><a name="Preview">Preview</a></font></h2>
  <p><font color="#FF0000"><b>What are synthetic sounds?</b></font><p>
Synthetic sounds, <i>(as opposed to sounds that you record via a microphone),</i> are 
sounds that you create by executing a mathematical algorithm.<p>
<font color="#FF0000"><b>How does this differ from MIDI sounds?</b></font><p>
Generally speaking, <i>(but not entirely),</i> MIDI sounds are designed to 
provide a computer-generated simulation of musical instruments.&nbsp; Even in 
those cases where MIDI sounds may not be intended to simulate real musical 
instruments, MIDI sounds are generally intended to  somehow fit into the domain of 
making music.<p>
Synthetic sounds, as discussed in this lesson, are more comparable to what you 
may consider to be <i>sound effects.</i>&nbsp; For example, synthetic sounds 
might be appropriate for including in a computer game, or for gaining someone's 
attention when they download your web page.<p>
For example, the Windows operating system makes various sounds when the user 
performs certain operations with the mouse or keyboard <i>(Critical Stop, 
Default Beep, Exclamation, etc.).</i>&nbsp; While some of those sounds may have 
been recorded via a microphone, many of those sounds appear to have been 
generated synthetically.<p>
<font color="#FF0000"><b>Why create synthetic sounds?</b></font><p>
I'm publishing this lesson for several reasons.&nbsp; The first reason is simply 
that creating and listening to synthetic sounds can be lots of fun.&nbsp; It is 
fun to write a new algorithm that produces synthetic sounds, and then to listen 
and hear what it sounds like. <p>
<font color="#FF0000"><b>Reason 2:&nbsp; Creating synthetic sounds is easy</b></font><p>
In addition to being fun, creating synthetic sounds can be relatively easy.&nbsp; For 
example, while it is also fun to create and view  animated graphics, 
creating animated graphics requires a lot of work.&nbsp; Once you know how to do 
it, it is much easier to create interesting sounds than it is to create interesting 
animations.<p>
The sample program that I will discuss in this lesson contains 
algorithms for creating seven different sounds.&nbsp; The code for each 
algorithm is very similar to the code for every other algorithm.&nbsp; None of the 
algorithms contain more than one page of code, and they all sound very different<p>
<font color="#FF0000"><b>Reason 3:&nbsp; Will need in the future</b></font><p>
In the near future, I plan to write a tutorial lesson explaining the technical 
aspects of the different encoding schemes used with the different audio formats 
(ALAW, PCM_SIGNED, PCM_UNSIGNED, and ULAW for example).<p>
To explain the different encoding schemes, it will be necessary to have audio 
data that is both deterministic and repeatable.&nbsp; I will apply different 
encoding schemes to the same deterministic audio samples, and will show numbers to 
explain the differences between the encoding schemes.&nbsp; Algorithms similar 
to those explained in this lesson will suffice for providing the audio data.<center>
<h2>
<a NAME="Discussion and Sample Programs"></a><font color="#000000">Discussion
and Sample Code</font></h2></center>
<p>
<font color="#FF0000"><b>The user interface</b></font><p>
The user interface for the sample program that I will discuss in this lesson is shown in Figure 1.<p align="center">
<img border="0" src="java2022a.gif" width="251" height="276"><p align="center">
Figure 1&nbsp; GUI for current version of the program<p>
<font color="#FF0000"><b>Seven different synthetic sounds</b></font><p>
The center panel in the GUI contains radio buttons that allow the user to select 
from seven different synthetic sounds <i>(hopefully you will add many more):</i><ul>
  <li>Tones - This sound consists of a two-second monaural mixture of sinusoids 
  at three frequencies.</li>
  <li>Stereo Panning - This one-second stereo sound begins in the left speaker 
  and pans across to the right speaker with a shift in the frequency from high 
  to low in the process</li>
  <li>Stereo Pingpong - This one-second stereo sound switches rapidly back and forth 
  between the two speakers shifting frequency in the process.</li>
  <li>FM Sweep - This monaural sound starts at 100 Hz and does a linear 
  frequency shift up to 1000 Hz during a two-second period.</li>
  <li>Decay Pulse - This two-second monaural sound is a pulse whose amplitude 
  decays in a linear fashion from a maximum value at the beginning to zero at 
  the end of one-second elapsed time.&nbsp; There is no sound during the second 
  half of the period.</li>
  <li>Echo Pulse - This two-second monaural sound consists a primary pulse <i>
  (based on the Decay Pulse algorithm)</i> and 
  several echoes that decrease in intensity over time.</li>
  <li>WaWa Pulse - This two-second monaural sound is similar to the Echo Pulse 
  described above, except that two of the three echoes were added in with a 
  180-degree phase shift.&nbsp; This produces a decidedly different effect.</li>
  </ul>
  <p>
<font color="#FF0000"><b>Listen or write to file</b></font><p>
The bottom panel in the GUI contains two radio buttons that allow the user to 
specify whether she wants to listen to the sound immediately or to write it into an audio file 
of type AU.&nbsp; A text field is 
provided to allow for specifying a name for the file.&nbsp; <i>(The default file 
name is junk.au.)</i><p>
<font color="#FF0000"><b>Generate and Play or File</b></font><p>
The top panel in the GUI contains two buttons that allow the user to first 
generate a sound as specified by the radio buttons in the center panel, and then 
to either play the sound or write it into an audio file, depending on which 
radio button has been selected in the bottom panel.<p>
Having generated a sound, the user can listen to it repeatedly and then write it 
into a file if desired.<p>
The top panel also contains an elapsed-time meter that shows the length of the 
sound in milliseconds each time it is played.<p>
<font color="#FF0000"><b>Default case</b></font><p>
As you can see from Figure 1, the default case on startup is to generate a <i>
Tones</i> sound and <i>Listen</i> to the sound when the <i>Play/File</i> button 
is clicked.<p>
<font color="#FF0000"><b>Operating instructions</b></font><p>
Here are the operating instructions for the program:<ul>
    <li>Start the program.</li>
    <li>Select a sound from the center panel, or accept the <i>Tones</i> 
    default.</li>
    <li>Select <i>Listen</i> or <i>File</i> in the bottom panel, or accept the
    <i>Listen</i> default.</li>
    <li>Click the <i>Generate</i> button in the top panel to generate the sound 
    and store it in memory.</li>
    <li>Click the <i>Play/File</i> button in the top panel one or more times.&nbsp; 
    If you previously selected <i>Listen</i> in the bottom panel, the file will be played 
    each time you click the button.&nbsp; If you previously selected <i>File</i> in the 
    bottom panel, an audio file of type AU will be written with the name showing 
    in the text field.</li>
    <li>Play back the recorded audio file, if any.&nbsp; You should be able to 
    play back the file using a media player such as the Windows Media Player, or 
    a Java program such as the program named AudioPlayer02 that I discussed in 
    an earlier lesson entitled <b>
    <a href="http://www.developer.com/java/other/article.php/2173111">Java Sound, Playing Back Audio Files using Java</a></b>.</li>
    </ul>
    <p>
<font color="#FF0000"><b>Will discuss the program in fragments</b></font><p>
The sample program that I will discuss in this lesson is named <b>AudioSynth01</b>.&nbsp; 
As usual, I will discuss this program in fragments.&nbsp; A complete listing of 
the program is shown in Listing 49 near the end of the lesson.<p>
<font color="#FF0000"><b>Similar to previous programs</b></font><p>
The program named <b>AudioSynth01</b> contains many elements that are similar to 
other programs that I have discussed in earlier lessons in this series.&nbsp; <i>
(You are strongly encouraged to review those earlier lessons.)</i><p>
Although I will discuss the entire program briefly to establish the context, I 
will concentrate my detailed discussion on those aspects of the new program 
having to do with the creation, playback, and recording of synthetic sound.<p>
<font color="#FF0000"><b>The controlling class named AudioSynth01</b></font><p>
The class definition for the controlling class begins in Listing 1.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>public class <b>AudioSynth01</b> extends JFrame{

  AudioFormat audioFormat;
  AudioInputStream audioInputStream;
  SourceDataLine sourceDataLine;

<b><font face="Courier New,Courier">Listing 1</font></b></pre>
</td>
</tr>
</table>

<p>
The code in Listing 1 includes the declaration of three instance variables used 
to create a <b>SourceDataLine</b> object that feeds data to the speakers on 
playback.&nbsp; I have discussed <b>SourceDataLine</b> objects in several 
previous lessons, so I won't discuss the instance variables further in this 
lesson.<p>
<font color="#FF0000"><b>Audio format parameters</b></font><p>
The instance variables in Listing 2 are audio format parameters with their 
default values.&nbsp; Some of these values are modified later by the code in the 
algorithms that generate the sound.&nbsp; The values for each parameter allowed 
by Java SDK 1.4.1 are shown in comments following the declaration of each 
parameter.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>  float sampleRate = 16000.0F;
  //Allowable 8000,11025,16000,22050,44100
  int sampleSizeInBits = 16;
  //Allowable 8,16
  int channels = 1;
  //Allowable 1,2
  boolean signed = true;
  //Allowable true,false
  boolean bigEndian = true;
  //Allowable true,false

<b><font face="Courier New,Courier">Listing 2</font></b></pre>
</td>
</tr>
</table>

<p>
Although I have used format parameters in several previous lessons, I haven't 
had much to say about them to this point.&nbsp; I will discuss the format 
parameters in the following paragraphs with respect to the impact that they have 
on the generation of synthetic sound.<p>
<font color="#FF0000"><b>Sample rate</b></font><p>
I have discussed the sampling rate in general in my tutorial lesson entitled
<a href="http://www.dickbaldwin.com/dsp/Dsp00104.htm">Digital Signal Processing 
(DSP) in Java, Sampled Time Series</a>.&nbsp; Rather than to repeat that 
discussion, I will simply refer you to that earlier lesson.<blockquote>
  <p>
<i>(By the way, you will find an index to all of my tutorial lessons at
<a href="http://www.DickBaldwin.com">www.DickBaldwin.com</a>)</i></blockquote>
<p>
The higher the sampling rate, the more samples are required for a fixed amount 
of time, the more memory is required, and the more computational demands are 
placed on the computer to be able to handle the audio data in real time.<p>
For this lesson, I chose a sampling rate of 16000 samples per second as a 
reasonable compromise between the minimum allowable rate of 8000 samples per 
second and the highest allowable rate of 44,100 samples per second.<p>
<font color="#FF0000"><b>Sample size in bits</b></font><p>
Java SDK 1.4.1 allows sample sizes of eight bits or 16 bits.&nbsp; Using signed 
PCM encoding, <i>(which I elected to use),</i> an 8-bit sample can record a 
dynamic range of only 127 to 1.&nbsp; In other words, the loudest sound can only 
be 127 times as loud as the quietest sound, assuming that the range of sounds is 
perfectly balanced within the allowable range of the digitizer.<blockquote>
  <p>
<i>(In addition, Java type <b>short</b> is a natural fit for 16-bit signed PCM 
encoding with big-endian byte order.)</i></blockquote>
<p>
I elected to use 16-bit signed samples <i>(based on type <b>short</b>),</i> which provide a dynamic range 
of 32,767 to 1.<p>
<font color="#FF0000"><b>Number of channels</b></font><p>
Java SDK 1.4.1 allows both monaural <i>(one channel)</i> and stereo <i>(two 
channel)</i> sound.&nbsp; I will show you how to use both in this lesson.<p>
<font color="#FF0000"><b>Signed or unsigned data</b></font><p>
Java allows for the use of either signed or unsigned audio data.&nbsp; However, 
because Java does not support unsigned integer types <i>(as does C and C++),</i> extra work is required to create synthetic sound for unsigned data.&nbsp; 
Therefore, I elected to use signed 16-bit data for all of the synthetic sound 
examples that I will discuss in this lesson.<p>
<font color="#FF0000"><b>Big-endian or little-endian</b></font><p>
Java SDK 1.4.1 supports both big-endian and little-endian audio data.&nbsp; 
However, according to <a href="http://mindprod.com/jglossendian.html">Roedy 
Green</a>,<blockquote>

<p>
<i>&quot;Everything in Java binary format files is stored big-endian, MSB(Most 
Significant Byte) first. This is sometimes called network order. This is good 
news. This means if you use only Java, all files are done the same way on all 
platforms Mac, PC, Solaris, etc.&nbsp; You can freely exchange binary data 
electronically over the Internet or on CD/floppy without any concerns about 
endianness. The problem comes when you must exchange data files with some 
program not written in Java that uses little-endian order, most commonly C on 
the PC. Some platforms use big-endian order internally (Mac, IBM 390); some use 
little-endian order (Intel). Java hides that internal endianness from you. &quot;</i></blockquote>

<p>
Because Java inherently creates big-endian data, you must do a lot of extra work 
to create little-endian audio data in Java.&nbsp; Therefore, I elected to create 
all of the synthetic sounds in this lesson in big-endian order.<p>
<font color="#FF0000"><b>PCM, ALAW, or ULAW encoding</b></font><p>
Of  the available encoding schemes, linear PCM is not only the simplest, it 
is also the default for one of the constructors for the <b>AudioFormat</b> 
class.&nbsp; I used that constructor in this sample program.&nbsp; Therefore, I used linear 
PCM encoding for all the synthetic samples in this lesson.<p>
I plan to publish a future lesson that will explain the differences between the 
different audio encoding schemes supported by Java.<p>
<font color="#FF0000"><b>An audio data buffer for synthetic data</b></font><p>
Listing 3 shows the declaration and initialization of a <b>byte</b> array with a
<b>length</b> of 64000 bytes.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>  byte audioData[] = new byte[16000*4];

<b><font face="Courier New,Courier">Listing 3</font></b></pre>
</td>
</tr>
</table>

<p>
Each of the synthetic sound data generators deposits the synthetic sound data in 
this array when it is invoked.<p>
At 16-bits per sample and 16000 samples per second, this array  can contain 
two seconds of monaural <i>(one-channel)</i> data or one second 
of stereo <i>(two-channel)</i> data.<p>
For simplicity, all of the synthetic data generators in this sample program fill 
this array when called upon to generate synthetic sound data.&nbsp; Thus, the 
stereo samples are only half as long as the monaural samples.<blockquote>
  <p>
<i>(You can change the length of the audio data by changing the size of this 
array.&nbsp; However, for reasons that I will mention later, you should make the 
size of the array an even multiple of four.)</i></blockquote>
<p>
<font color="#FF0000"><b>The GUI components</b></font><p>
I'm not going to spend much time discussing the GUI or its components.&nbsp; 
However, I will skim over the GUI code very lightly to establish the context.<p>
The instance variables in Listing 4 hold references to components that appear in 
the top panel in Figure 1.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>  final JButton generateBtn =
                         new JButton("Generate");
  final JButton playOrFileBtn =
                        new JButton("Play/File");
  final JLabel elapsedTimeMeter =
                              new JLabel("0000");

<b><font face="Courier New,Courier">Listing 4</font></b></pre>
</td>
</tr>
</table>

<p>
<font color="#FF0000"><b>Radio buttons in the center of the GUI</b></font><p>
The instance variables in Listing 5 hold references to radio buttons that appear 
in the center of the GUI in Figure 1.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>  final JRadioButton tones =
                  new JRadioButton("Tones",true);
  final JRadioButton stereoPanning =
              new JRadioButton("Stereo Panning");
  final JRadioButton stereoPingpong =
             new JRadioButton("Stereo Pingpong");
  final JRadioButton fmSweep =
                    new JRadioButton("FM Sweep");
  final JRadioButton decayPulse =
                 new JRadioButton("Decay Pulse");
  final JRadioButton echoPulse =
                 new JRadioButton("Echo Pulse");
  final JRadioButton waWaPulse =
                 new JRadioButton("WaWa Pulse");

<b><font face="Courier New,Courier">Listing 5</font></b></pre>
</td>
</tr>
</table>

<p>
If you update the program to add new synthetic sound data generators <i>(which I 
hope that you do),</i> this is where you establish the radio buttons for the new 
generators.<p>
<font color="#FF0000"><b>Components in the bottom panel of the GUI</b></font><p>
The instance variables in Listing 6 hold references to the two radio buttons and 
the text field that appear in the bottom panel of the GUI in Figure 1.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>  final JRadioButton listen =
                 new JRadioButton("Listen",true);
  final JRadioButton file =
                        new JRadioButton("File");
  final JTextField fileName =
                       new JTextField("junk",10);

<b><font face="Courier New,Courier">Listing 6</font></b></pre>
</td>
</tr>
</table>

<p>
<font color="#FF0000"><b>The main method</b></font><p>
The <b>main</b> method is shown in Listing 7.&nbsp; This method simply 
instantiates an object of the controlling class.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>  public static void <b>main</b>(String args[]){
    new AudioSynth01();
  }//end main

<b><font face="Courier New,Courier">Listing 7</font></b></pre>
</td>
</tr>
</table>

<p>
<font color="#FF0000"><b>The constructor</b></font><p>
The constructor begins in Listing 8.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>  public AudioSynth01(){//constructor
    final JPanel controlButtonPanel =
                                    new JPanel();
    controlButtonPanel.setBorder(
             BorderFactory.createEtchedBorder());

<b><font face="Courier New,Courier">Listing 8</font></b></pre>
</td>
</tr>
</table>

<p>
The code in Listing 8 instantiates a <b>JPanel</b> object, which will contain 
the two buttons and the label in the top panel.&nbsp; Note the use of the <b>
setBorder</b> method to create a border on the <b>JPanel</b> object as shown in 
Figure 1.<p>
<font color="#FF0000"><b>The center panel in the GUI</b></font><p>
The code in Listing 9 instantiates a <b>JPanel</b> object that will be used to 
create a physical grouping of the radio buttons in the center of the GUI.&nbsp; 
The code also instantiates a <b>ButtonGroup</b> object that will be used to 
group the radio buttons into a logical, mutually exclusive group.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>    final JPanel synButtonPanel = new JPanel();
    final ButtonGroup synButtonGroup =
                               new ButtonGroup();
    final JPanel centerPanel = new JPanel();

<b><font face="Courier New,Courier">Listing 9</font></b></pre>
</td>
</tr>
</table>

<p>
In addition, the code in Listing 9 instantiates another <b>JPanel</b> object 
that will be used for cosmetic purposes, to cause the radio buttons to be 
centered horizontally in the center of the GUI in Figure 1.<p>
<font color="#FF0000"><b>JPanel and ButtonGroup for the bottom panel of the GUI</b></font><p>
The code in Listing 10 instantiates a <b>JPanel</b> object with an etched border 
to hold the components in the bottom panel of the GUI.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>    final JPanel outputButtonPanel =
                                    new JPanel();
    outputButtonPanel.setBorder(
             BorderFactory.createEtchedBorder());
    final ButtonGroup outputButtonGroup =
                               new ButtonGroup();

<b><font face="Courier New,Courier">Listing 10</font></b></pre>
</td>
</tr>
</table>

<p>
The code in Listing 10 also instantiates a <b>ButtonGroup</b> 
object that will be used to group the two radio buttons in the bottom panel into a logical, 
mutually exclusive group.<p>
<font color="#FF0000"><b>Don't play before generating a synthetic sound</b></font><p>
It would not work for the user to attempt to play a synthetic sound before 
generating such a sound.&nbsp; The code in Listing 11 disables the <b>Play/File</b> 
button <i>(see Figure 1)</i> to prevent this from happening.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>    playOrFileBtn.setEnabled(false);

<b><font face="Courier New,Courier">Listing 11</font></b></pre>
</td>
</tr>
</table>

<p>
As you will see later, this button is enabled after the first synthetic sound is 
generated by the user.<p>
<font color="#FF0000"><b>Register action listener on the Generate button</b></font><p>
The code in listing 12 instantiates an anonymous action listener object and 
registers it for action events on the <b>Generate</b> button.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>    generateBtn.addActionListener(
      new ActionListener(){
        public void actionPerformed(
                                  ActionEvent e){
          //Don't allow Play during generation
          <b>playOrFileBtn.setEnabled(false);</b>
          //Generate synthetic data
          <b>new SynGen().getSyntheticData(
                                      audioData);</b>
          //Now it is OK for the user to listen
          // to or file the synthetic audio data.
          <b>playOrFileBtn.setEnabled(true);</b>
        }//end actionPerformed
      }//end ActionListener
    );//end addActionListener()

<b><font face="Courier New,Courier">Listing 12</font></b></pre>
</td>
</tr>
</table>

<p>
I have discussed code similar to this in several previous lessons.<p>
For purposes of this lesson, the three most significant lines of code in Listing 12 are those highlighted in 
boldface.&nbsp; Two of those lines of code first disable, and later enable the
<b>Play/File</b> button.&nbsp; The purpose is to prevent the user from 
attempting to play the synthetic sound or to store it in a file while it is 
being generated.<p>
<font color="#FF0000"><b>Generate the synthetic sound</b></font><p>
The most important code in Listing 12 is the code that instantiates an object of 
the class <b>SynGen</b>, and invokes the <b>getSyntheticData</b> method on that 
object.&nbsp; This is the statement that actually causes the synthetic sound to 
be generated.<p>
Note that the method invocation passes the byte array named <b>audioData</b> to 
the method.&nbsp; This is a 64000-byte array, which will be filled with 
synthetic sound data when the <b>getSyntheticData</b> method returns.<p>
At this point, I am going to depart from my discussion of the constructor for 
the controlling class and discuss the synthetic sound generator class named <b>
SynGen</b>.&nbsp; I will return to a discussion of the constructor later.<p>
<font color="#FF0000"><b>The SynGen class</b></font><p>
Listing 13 shows the beginning of the <b>SynGen</b> class.&nbsp; Note that this 
is an inner class, defined within the controlling class named <b>AudioSynth01</b>.&nbsp; 
As a result, methods of objects instantiated from this class have direct access 
to the instance variables of the controlling class.&nbsp; This results in  less parameter passing than would be the case if this were a top-level 
class.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>class SynGen{
  ByteBuffer byteBuffer;
  ShortBuffer shortBuffer;
  int byteLength;

<b><font face="Courier New,Courier">Listing 13</font></b></pre>
</td>
</tr>
</table>

<p>
An object of the<b> SynGen </b>class can be used to generate a variety of different 
synthetic sound signals.&nbsp; Each time the
<b>getSyntheticData</b> method is called on an object of this class, the method will fill the 
<b>audioData</b> array <i>(see Listing 3)</i> with the samples for a synthetic signal.<p>
<font color="#FF0000"><b>Type ByteBuffer</b></font><p>
Listing 13 also shows the declaration of three instance variables.&nbsp; The 
types of the first two, <b>ByteBuffer</b> and <b>ShortBuffer</b>, are new to the
<b>java.nio</b> package, which was released in Java SDK, version 1.4.<blockquote>

<p>
<i>(Among other things this means that you must be using Java version 1.4 or 
later to successfully compile and execute this program.</i><p>
<i>To learn more about the capabilities of the <b>java.nio</b> package, see my 
tutorial lessons beginning with number 1780,
<a href="http://www.developer.com/java/other/article.php/1367031">Understanding 
the Buffer class in Java</a>.&nbsp; See my <a href="http://www.DickBaldwin.com">
web site</a> for an index to the other lessons in that series.)</i></blockquote>

<p>
The new capabilities of the <b>java.nio</b> package make the task of translating 
back and forth between signed 16-bit <b>short</b> data and bytes somewhat easier 
than would otherwise be the case.<p>
<font color="#FF0000"><b>The getSyntheticData method</b></font><p>
Listing 14 shows the beginning of the <b>getSyntheticData</b> method that was 
invoked earlier in Listing 12.&nbsp;
<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>  void <b>getSyntheticData</b>(byte[] synDataBuffer){

    byteBuffer = ByteBuffer.wrap(synDataBuffer);
    shortBuffer = byteBuffer.asShortBuffer();

    byteLength = synDataBuffer.length;

<b><font face="Courier New,Courier">Listing 14</font></b></pre>
</td>
</tr>
</table>

<p>
Note that this method receives an incoming parameter, which is a reference to 
the 64000-byte array named <b>audioData</b> discussed earlier in Listing 3.&nbsp; 
This is the array in which the synthetic data generators deposit the synthetic 
sound data for use by other parts of the program.<p>
<font color="#FF0000"><b>Preparing the arrays for use</b></font><p>
The code in Listing 14 begins by wrapping the incoming <b>audioData</b> array in 
a <b>ByteBuffer</b> object.&nbsp; Then a <b>ShortBuffer</b> object is created as 
a<b> short </b><i>view</i> of the <b>ByteBuffer</b> object.<p>
This makes it possible to store <b>short</b> data directly into the <b>audioData</b> 
array by invoking the <b>put</b> method on the <b>ShortData</b> view of the 
array.<p>
<font color="#FF0000"><b>Getting the length of the audio data in bytes</b></font><p>
The code in Listing 14 also gets and saves the required length of the synthetic 
sound data in bytes.&nbsp; This value will be used in the algorithms to be 
discussed later.<p>
<font color="#FF0000"><b>Choose a synthetic data algorithm</b></font> 

<p>
The code in Listing 15 decides which synthetic data generator method to invoke based on which radio button the user 
has selected in the center of the GUI in Figure 1.<blockquote>

<p>
<i>(If you add more methods for other synthetic sound types, you need to add corresponding radio buttons to the GUI and add statements here to test the new radio buttons.)</i></blockquote>
<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>    <b>if(tones.isSelected())</b> <b>tones</b>();
    if(stereoPanning.isSelected())
                                 <b>stereoPanning</b>();
    if(stereoPingpong.isSelected())
                                <b>stereoPingpong</b>();
    if(fmSweep.isSelected()) <b>fmSweep</b>();
    if(decayPulse.isSelected()) <b>decayPulse</b>();
    if(echoPulse.isSelected()) <b>echoPulse</b>();
    if(waWaPulse.isSelected()) <b>waWaPulse</b>();

  }//end getSyntheticData method

<b><font face="Courier New,Courier">Listing 15</font></b></pre>
</td>
</tr>
</table>

<p>
<font color="#FF0000"><b>Synthetic data generator method names</b></font><p>
The names of the synthetic data generator methods that correspond to each of the 
buttons are highlighted in boldface in Listing 15.&nbsp; I will discuss each of 
those methods in the paragraphs that follow.<p>
Listing 15 also signals the end of the <b>getSyntheticData</b> method.<p>
<font color="#FF0000"><b>The tones method</b></font><p>
Listing 16 shows the beginning of the method named <b>tones</b>, which 
corresponds to the radio button labeled <b>Tones</b> in Figure 1.&nbsp; This 
method generates a monaural tone,  two seconds in length, 
consisting of the sum of three sinusoids at different frequencies.<p>
This is a relatively simple synthetic sound.&nbsp; One of my main reasons for 
including it in this lesson is to introduce you to the concept of using 
sinusoids as sources for synthetic sound.<p>
I have also discussed sinusoids in detail in my tutorial lesson entitled
<a href="http://www.dickbaldwin.com/dsp/Dsp00100.htm">Periodic Motion and 
Sinusoids</a>.&nbsp; Rather than to repeat that 
discussion, I will simply refer you to that earlier lesson.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>  void <b>tones</b>(){
    channels = 1;//Java allows 1 or 2
    int bytesPerSamp = 2;
    sampleRate = 16000.0F;
    // Allowable 8000,11025,16000,22050,44100
    int sampLength = byteLength/bytesPerSamp;

<b><font face="Courier New,Courier">Listing 16</font></b></pre>
</td>
</tr>
</table>

<p>
<font color="#FF0000"><b>Monaural versus stereo data</b></font><p>
Before getting into the use of sinusoids, however, there is some general 
housekeeping that I need to take care of.<p>
To begin with, the code in Listing 16 sets the audio format instance variable 
named <b>channels</b> <i>(see Listing 2)</i> to a value of 1.&nbsp; This causes 
the audio data produced by this method to be later interpreted as monaural data 
instead of stereo data.<p>
<font color="#FF0000"><b>The number of bytes per sample</b></font><p>
Each channel requires two 8-bit bytes per 16-bit sample.&nbsp; Since this method 
produces one-channel <i>(monaural)</i> data, Listing 16 sets the value of <b>
bytesPerSamp</b> to 2.&nbsp; <i>(for stereo data, the number of bytes per sample 
would be 4).</i><p>
<font color="#FF0000"><b>The sampling rate</b></font><p>
As mentioned earlier, Listing 16 sets the sampling rate to 16000 samples per 
second as a reasonable compromise between the lowest and highest allowable 
sampling rates.<p>
<font color="#FF0000"><b>The length of the audio data in samples</b></font><p>
Finally, the code in Listing 16 computes and saves the required length of the 
synthetic sound data in samples by dividing the length of the <b>audioData</b> array <i>
<b>(byteLength</b>,</i> <i>see Listing 14)</i> by the number of bytes per sample
<i>(<b>bytesPerSamp</b>).</i><p>
The required number of samples is saved in the variable named <b>sampLength</b>.<p>
<font color="#FF0000"><b>Generate the synthetic data</b></font><p>
Listing 17 contains a <b>for</b> loop.&nbsp; Each iteration of the loop:<ul>
  <li>Generates a data sample as type <b>double</b>.</li>
  <li>Casts that data to type <b>short</b>.</li>
  <li>Invokes the <b>put</b> method on the <b>ShortBuffer</b> object to store 
  the sample in the <b>byte</b> array named <b>audioData</b> <i>(see Listing 3 
  and Listing 12).</i></li>
  </ul>
  <table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>    <b>for</b>(int cnt = 0; cnt < sampLength; cnt++){
      double time = cnt/sampleRate;
      double freq = 950.0;//arbitrary frequency
      double sinValue =
        (Math.sin(<b>2*Math.PI*freq*time</b>) +
        Math.sin(2*Math.PI*(freq/1.8)*time) +
        Math.sin(2*Math.PI*(freq/1.5)*time))/3.0;
      shortBuffer.put((short)(16000*sinValue));
    }//end for loop
  }//end method tones

<b><font face="Courier New,Courier">Listing 17</font></b></pre>
</td>
</tr>
</table>

  <p>
The loop iterates once for each required data sample, producing the required 
number of synthetic data samples before terminating.<blockquote>
    <p>
<i>(A similar loop structure is used for all of the synthetic data generator 
methods.&nbsp; Generally, it is the code within the body of the loop that 
determines the nature of the synthetic sound that is produced.)</i></blockquote>

<p>
<font color="#FF0000"><b>Arguments to the Math.sin method</b></font><p>
During each iteration of the <b>for</b> loop, the code in Listing 17 calculates 
the <b>time</b> in seconds, by dividing the sample number by the number of 
samples per second.<blockquote>

<p>
<i>(As discussed earlier, for this monaural case, the time will range from zero 
to two seconds before the <b>for</b> loop terminates.)</i></blockquote>

<p>
This <b>time</b> value is multiplied by three different frequency values, a 
factor of 2, and the constant <b>PI</b> to produce three different values in 
radians to be used as arguments to the <b>Math.sin</b> method.<blockquote>

<p>
<i>(If this terminology isn't familiar to you, please review
<a href="http://www.dickbaldwin.com/dsp/Dsp00100.htm">Periodic Motion and 
Sinusoids</a> before going further.)</i></blockquote>

<p>
The three values in radians are passed to three separate invocations of the <b>
Math.sin</b> method to produce the sum of three separate sine values as type <b>
double</b>.&nbsp; This sum is divided by 3 to produce the numeric average of the 
three sine values.<p>
The numeric average of the three sine values is multiplied by the constant 
16000, cast to type <b>short</b>, and <b>put</b> into the output array.<p>
<font color="#FF0000"><b>Why was type short used?</b></font><p>
The type <b>short</b> is inherently a signed 16-bit type with big-endian byte 
order in Java, which is exactly what we need for the audio data format that I 
elected to use.<p>
<font color="#FF0000"><b>Why was the constant value of 16000 used?</b></font><p>
I wanted the sound to be loud enough to hear easily.&nbsp; I also wanted to make 
certain that I didn't overflow the maximum value that can be contained in a 
value of type <b>short</b>.<p>
The maximum value produced by the <b>Math.sin</b> method is 1.0. Thus, the 
maximum possible value in the average of the three sine values is also 1.0.&nbsp; 
The constant value of 16000 was chosen because it is approximately half the 
maximum value that can be contained in a value of type <b>short</b>.&nbsp; Thus, 
the maximum value that this algorithm can produce is approximately half the 
maximum value that can be contained in type <b>short</b>.<blockquote>

<p>
<i>(These are very important considerations, because integer arithmetic overflow 
can destroy what might otherwise be a good synthetic sound algorithm.)</i></blockquote>

<p>
<font color="#FF0000"><b>Why was a frequency 950 Hz used?</b></font><p>
The frequency of 950 Hz was chosen because it is well within the spectral 
hearing range of most people, and it is within the spectral reproduction range 
of most computer speakers.&nbsp; However, the choice was arbitrary.&nbsp; 
Any other frequency that meets the above requirements should work just as well.<p>
<font color="#FF0000"><b>Play and/or modify the sound</b></font><p>
If you generate and play the sound, you should hear a monaural tone, 
 
two seconds in length.<p>
You can change the sound by modifying the frequency <i>(950)</i> in Listing 17, 
and by changing the factors used to specify different frequencies <i>(1.8 and 
1.5)</i> in Listing 17.<p>
You can change the length of the sound by changing the size of the array 
referred to by <b>audioData</b> in Listing 3.<blockquote>

<p>
<i>(Increase the length of the array to make the sound longer than two seconds, 
and decrease the length of the array to make the sound shorter than two seconds.&nbsp; 
For reasons having to do with audio frame size, you should make certain that the 
size of the array is evenly divisible by four.)</i></blockquote>

<p>
<font color="#FF0000"><b>The quality of the playback</b></font><p>
Despite everything that I have done in my attempts to improve the quality of the playback, I hear 
extraneous clicking noises when the sound is played back by this program, and by 
other Java programs written by other people.&nbsp; This may indicate that my 
computer is too slow to provide the audio data to the speakers in real time, 
although I'm not certain that is the cause of the problem.<p>
In any event, I get much better playback quality by saving the synthetic sound 
in an audio file and using a media player such as the Windows Media Player, or 
the RealOne media player to play back the synthetic sound.<p>
<font color="#FF0000"><b>A visual analysis</b></font><p>
When creating synthetic sounds, it is often useful to perform a visual analysis 
of the sound's waveform, and to measure the spectral content of the sound to confirm that your algorithm 
is performing as expected.<blockquote>
  <p>
<i>(For example, your algorithm may have experienced integer overflow without 
you having realized it.)</i></blockquote>
<p>
Numerous audio tools are available for downloading that you can use for this 
purpose.&nbsp; <i>(If you are ambitious, you can even write your own.)</i>&nbsp; Some are free, some are not free, some are free for an 
evaluation period only, some are free for certain features and are not free for 
other features, and some are free for some other combination of the above.<p>
<font color="#FF0000"><b>AudioSuite 4.20.3</b></font><p>
I am going to show you some pictures that were produced with the unregistered evaluation 
version of <a href="http://www.glowingcoast.co.uk/audio/index.htm">AudioSuite 
4.20.3</a>, which can be downloaded free of charge.&nbsp; This is an extremely 
powerful set of audio tools.<blockquote>
  <p>
<i>(Some of the features have a timeout period in the unregistered version.&nbsp; 
Fortunately, many of the features, such as waveform plotting, do not expire in 
the unregistered version.)</i></blockquote>
<p>
<font color="#FF0000"><b>The raw waveform for the tones method</b></font><p>
The raw waveform of the complete two-second audio signal produced by the <b>
tones</b> method is shown in Figure 2.&nbsp; This is a plot of signal amplitude 
on the vertical versus time on the horizontal.<p align="center">
<img border="0" src="java2022b.gif" width="387" height="362"><p align="center">
Figure 2&nbsp; Raw waveform for <b>tones</b> method<p>
Because of the horizontal compression that was required to include the entire 
waveform in this narrow format, the waveform shown in Figure 2 isn't very 
enlightening.<p>
<font color="#FF0000"><b>A more enlightening waveform</b></font><p>
Figure 3 shows a very small portion of the beginning of the waveform greatly 
expanded along the horizontal <i>(time)</i> axis.<p align="center">
<img border="0" src="java2022c.gif" width="390" height="362"><p align="center">
Figure 3&nbsp; Time-expanded waveform for <b>tones</b> method<p>
This representation of the waveform is much more enlightening.&nbsp; If you plot 
the sum of the three sinusoids that were added together in Listing 17 to produce 
the synthetic sound, this is what you should see.<blockquote>
  <p>
<i>(Note that the waveform shown in Figure 3 is periodic, with almost five 
periods of the waveform showing.&nbsp; It also exhibits an odd (as opposed to 
even) symmetry within each period.)</i></blockquote>
<p>
<font color="#FF0000"><b>Spectrum analysis</b></font><p>
The synthetic sound produced by the code in Listing 17 consists of the sum of 
three sinusoids at frequencies of 950 Hz, 527 Hz, and 633 Hz.&nbsp; 
<p align="center">
<img border="0" src="java2022d.gif" width="389" height="375"><p align="center">
Figure 4&nbsp; Spectrum analysis<p>
Figure 4 shows the result of performing a spectrum analysis on a portion of the two-second 
synthetic sound signal.&nbsp; <i>(Figure 4 plots energy on the vertical axis 
versus frequency on the horizontal axis.)</i>&nbsp; Note the peaks in the spectrum at 950 Hz, 527 Hz, 
and 633 Hz.<blockquote>
  <p>
<i>(This is just what I would expect, which confirms that my algorithm behaves 
as I intended for it to behave.)</i></blockquote>
<p>
<font color="#FF0000"><b>The stereoPanning method</b></font><p>
The<b> stereoPanning </b>method generates a one-second stereo speaker sweep, starting with a relatively high frequency tone on the left speaker and moving across to a lower frequency tone on the right speaker.&nbsp; 
Among other things, this method will teach you how to generate synthetic sound 
data that will later be interpreted as two-channel or stereo data.<p>
The beginning of the <b>stereoPanning</b> method is shown in Listing 18.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>  void <b>stereoPanning</b>(){
    <b>channels = 2;</b>
    int bytesPerSamp = 4;
    sampleRate = 16000.0F;
    // Allowable 8000,11025,16000,22050,44100
    int sampLength = byteLength/bytesPerSamp;

<b><font face="Courier New,Courier">Listing 18</font></b></pre>
</td>
</tr>
</table>

<p>
<font color="#FF0000"><b>Similar to the tones method so far</b></font><p>
This method begins just like the <b>tones</b> method discussed earlier, except:<ul>
    <li>The code in Listing 18 sets the value of <b>channels</b> to 2 instead of 
    1.&nbsp; As a result, the synthetic data produced by this method will be 
    interpreted as stereo data by the playback code later.</li>
    <li>The code in Listing 18 sets the value of <b>bytesPerSamp</b> to 4 
    instead of 2.&nbsp; One sample is considered to contain the data for both 
    channels <i>(this may more properly be referred to as a frame).</i>&nbsp; 
    One sample for each channel requires two bytes.&nbsp; Thus, the sample <i>
    (frame)</i> for both channels requires four bytes.</li>
    </ul>
    <blockquote>

<p>
<font color="#FF0000"><i><b>An important note</b></i></font><p>
<i>(There is nothing in the synthetic data produced by these generator methods 
that indicates the number of channels.&nbsp; These methods simply produce byte 
data and store that data in an array object of type <b>byte</b>.&nbsp; The 
synthetic data must be constructed by these generator methods in such a way that 
it will be correct for the number of channels specified in the audio format when 
the data is either played back or written to an audio file later.&nbsp; The 
purpose of setting <b>channels</b> in these methods is to properly set the audio 
format for the playback loop to be executed later in the program.)</i></blockquote>

<p>
<font color="#FF0000"><b>Creating a stereo sweep</b></font><p>
The for loop that is typical of these generator methods begins in Listing 19.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>    for(int cnt = 0; cnt < sampLength; cnt++){

      double rightGain = 16000.0*cnt/sampLength;
      double leftGain = 16000.0 - rightGain;

<b><font face="Courier New,Courier">Listing 19</font></b></pre>
</td>
</tr>
</table>

<p>
This method generates two channels of data.&nbsp; One channel will ultimately be 
supplied to each speaker at playback.&nbsp; The apparent sweep from the left 
speaker to the right speaker is accomplished by:<ul>
      <li>Causing the strength of the signal applied to the left speaker to 
      decrease from a maximum value to zero over the <i>(one second)</i> time 
      span of the signal.</li>
      <li>Causing the strength of the signal applied to the right speaker to 
      increase from zero to the maximum value over the time span of the signal.</li>
      </ul>

<p>
<font color="#FF0000"><b>Time-varying gains</b></font><p>
The code in Listing 19 computes the time-varying gain to be applied to the data 
for each channel during each iteration of the <b>for</b> loop.&nbsp; This code 
is straightforward and shouldn't be difficult to understand.&nbsp; The gain for 
the left channel varies from 16000 to zero while the gain for the right channel 
varies from zero to 16000.<p>
<font color="#FF0000"><b>Time and frequency</b></font><p>
The code in Listing 20 calculates the time and sets the frequency to be used in 
the arguments for the <b>Math.sin</b> methods later.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>      double time = cnt/sampleRate;
      double freq = 600;//An arbitrary frequency

<b><font face="Courier New,Courier">Listing 20</font></b></pre>
</td>
</tr>
</table>

      <blockquote>

<p>
<i>(It occurred to me during the writing of this lesson that because the frequency 
doesn't vary with time, it would have been more logical to set the frequency 
value prior to entering the <b>for</b> loop.&nbsp; However, by the time I had 
that epiphany I was too far down the road to go back and change everything.)</i></blockquote>

<p>
<font color="#FF0000"><b>Generate data for the left speaker</b></font><p>
The required format of the byte data for stereo sound signals consists of alternating 
left speaker and right speaker samples, beginning with the data for the left 
speaker.&nbsp; <i>(Again, the set of combined samples for both 
channels is often referred to as a frame.)</i>&nbsp; The bytes in a single frame are interpreted to be 
one sample for each of the two channels that occur at the same point in time.<p>
Thus, the code in Listing 21:<ul>
        <li>Generates a <b>double</b> sine value for the left speaker at the 
        correct frequency for the left speaker.</li>
        <li>Multiplies that sine value by the time-varying <b>leftGain</b> value 
        for the left speaker.</li>
        <li>Casts the <b>double</b> value to type <b>short</b>.</li>
        <li>Puts the two bytes that constitute the sample for the left speaker 
        into the output array.</li>
        </ul>
        <table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>      double sinValue =
                 Math.sin(2*Math.PI*(freq)*time);
      shortBuffer.put(
                     (short)(<b>leftGain</b>*sinValue));

<b><font face="Courier New,Courier">Listing 21</font></b></pre>
</td>
</tr>
</table>

        <blockquote>

<p>
<i>(This will be followed by putting two bytes that constitute the corresponding 
sample for the right speaker into the next two bytes in the output array.)</i></blockquote>

<p>
<font color="#FF0000"><b>Generate data for the right speaker</b></font><p>
The code in Listing 22:<ul>
          <li>Generates a <b>double</b> sine value for the right speaker at the 
          correct frequency for the right speaker <i>(0.8 times the frequency of 
          the left speaker).</i></li>
          <li>Multiplies that sine value by the time-varying <b>rightGain</b> 
          value for the right speaker.</li>
          <li>Casts the <b>double</b> value to type <b>short</b>.</li>
          <li>Puts the two bytes that constitute the sample for the right speaker 
          in the output array, immediately following the two bytes that were put 
          there by the code in Listing 21.</li>
          </ul>
          <table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>      sinValue =
             Math.sin(2*Math.PI*(freq*0.8)*time);
      shortBuffer.put(
                    (short)(<b>rightGain</b>*sinValue));
    }//end for loop
  }//end method stereoPanning

<b><font face="Courier New,Courier">Listing 22</font></b></pre>
</td>
</tr>
</table>

<p>
The code in Listing 22 also signals the end of the method named <b>stereoPanning</b>.<p>
<font color="#FF0000"><b>The waveform</b></font><p>
Recall that this is a one-second, two-channel stereo sound.&nbsp; At the 
beginning, all of the sound comes from the left speaker, and at the end of one 
second, all the sound comes from the right speaker.<p>
Between the beginning and the end, the sound coming from the left speaker 
decreases from maximum to zero in a liner fashion.&nbsp; During that same period, the sound coming from the right speaker increases from zero to 
maximum in a linear fashion.<p>
Also, the pitch of the sound from the right speaker is lower than the pitch of 
the sound from the left speaker, because the signal for the right speaker has a 
lower frequency.&nbsp; This causes the sound to appear to sweep 
from the left to the right, changing pitch in the process.<p>
This is shown by the waveforms in Figure 5 and Figure 6.<p align="center">
<img border="0" src="java2022e.gif" width="390" height="378"><p align="center">
Figure 5&nbsp; Raw waveforms from the stereoPanning method<p>
Figure 5 shows the waveform of the left-channel signal in red and shows the 
waveform of the right-channel signal in blue.&nbsp; This representation of the 
waveforms clearly shows the change in sound level for each channel during the 
one-second period.&nbsp; However, because of the horizontal compression, Figure 
5 doesn't show anything about the frequency or pitch of the sound from the two 
channels.<p>
<font color="#FF0000"><b>Expanded waveform</b></font><p>
Figure 6 shows a small slice in time from both waveforms near the one-half second point, 
with a greatly expanded time scale.<p align="center">
<img border="0" src="java2022f.gif" width="389" height="379"><p align="center">
Figure 6&nbsp; Expanded waveforms from the stereoPanning method<p>
Figure 6 confirms that each of the two sounds is a simple sinusoid, as shown in 
Listing 21 and Listing 22.&nbsp; Also, Figure 6 confirms that the frequency of 
the sinusoid on the right channel is approximately eighty-percent of the frequency of the 
sinusoid on the left channel as indicated by Listing 22.<blockquote>

<p>
<i>(There are nine positive peaks in the waveform for the left channel in Figure 
6 and only 7 positive peaks in the waveform for the right channel in the same 
time period.)</i></blockquote>
<p>
<font color="#FF0000"><b>The stereoPingpong method</b></font><p>
The <b>stereoPingpong</b> method uses stereo to switch a sound back and forth between the left and right speakers at a rate of about eight switches per second.&nbsp; On my system, this is a much better demonstration of the sound separation between the two speakers than is the demonstration produced by the
<b>stereoPanning</b> method.<p>
The sounds produced are at different frequencies.&nbsp; As a result, the sounds produced 
are similar to that of U.S. emergency vehicles.<p>
<b><font color="#FF0000">Following discussions will be more abbreviated</font></b><p>
Now that you understand the fundamental structure of these generator 
methods, the discussion of the remaining methods should go more quickly than the 
discussion of the first two methods.<p>
The beginning of the <b>stereoPingpong</b> method is shown in Listing 23.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>  void <b>stereoPingpong</b>(){
    channels = 2;//Java allows 1 or 2
    int bytesPerSamp = 4;//Based on channels
    sampleRate = 16000.0F;
    // Allowable 8000,11025,16000,22050,44100
    int sampLength = byteLength/bytesPerSamp;

    <b>double leftGain = 0.0;
    double rightGain = 16000.0;</b>

<b><font face="Courier New,Courier">Listing 23</font></b></pre>
</td>
</tr>
</table>

<p>
<font color="#FF0000"><b>Time varying gains</b></font><p>
Much of the code in Listing 23 is similar or identical to the code that you have 
seen in the previous generator methods.<p>
As was the case with the method named <b>stereoPanning</b> this method generates 
two channels of data.&nbsp; Each channel will ultimately be supplied to each 
speaker at playback.&nbsp; The apparent switch from one speaker to the other 
speaker is accomplished by causing the strength of the signal applied to one 
speaker to go to zero at the same time that the strength of the signal applied 
to the other speaker goes to its maximum value.<p>
The code in Listing 23 declares and initializes two variables named <b>leftGain</b> 
and <b>rightGain</b>, which are used for this purpose.&nbsp; Note that the left 
gain value is initialized to 0.0, while the right gain value is initialized to 
16000.&nbsp; These values will be periodically swapped between the two channels 
in the <b>for</b> loop that follows.<p>
<font color="#FF0000"><b>The for loop</b></font><p>
The typical <b>for</b> loop begins in Listing 24.&nbsp; During each iteration of 
this loop, one data sample is produced for each channel, and the samples are <b>
put</b> into successive bytes in the output array.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>    for(int cnt = 0; cnt < sampLength; cnt++){

      if(cnt % (sampLength/8) == 0){
        //swap gain values
        double temp = leftGain;
        leftGain = rightGain;
        rightGain = temp;
      }//end if

<b><font face="Courier New,Courier">Listing 24</font></b></pre>
</td>
</tr>
</table>

<p>
<font color="#FF0000"><b>Computing the time-varying gains</b></font><p>
The code in Listing 24 computes the gain for each channel during each iteration 
of the <b>for</b> loop.<p>
This code uses the modulus operator to swap the gain values between the left and 
right channels each time the iteration counter value is an even multiple of 
one-eighth of the sample length.&nbsp; For the <b>audioData</b> array of 64000 
bytes, this amounts to one swap of the gain values every 2000 samples, or eight 
times during the one-second elapsed time of the sound.<p>
<font color="#FF0000"><b>Remainder of the for loop</b></font><p>
The remainder of the <b>for</b> loop is shown in Listing 25.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>      double time = cnt/sampleRate;
      double freq = 600;//An arbitrary frequency
      //Generate data for left speaker
      double sinValue =
                 Math.sin(2*Math.PI*(freq)*time);
      shortBuffer.put(
                     (short)(leftGain*sinValue));
      //Generate data for right speaker
      sinValue =
             Math.sin(2*Math.PI*(freq*0.8)*time);
      shortBuffer.put(
                    (short)(rightGain*sinValue));
    }//end for loop
  }//end stereoPingpong method

<b><font face="Courier New,Courier">Listing 25</font></b></pre>
</td>
</tr>
</table>

<p>
The code in Listing 25 is essentially the same as code that I discussed in 
conjunction with an earlier generator method.&nbsp; Therefore, I won't discuss 
it further.<p>
<font color="#FF0000"><b>Waveforms</b></font><p>
Figure 7 shows the waveforms for the left <i>(red)</i> and right <i>(blue)</i> 
channels of the synthetic sound produced by the method named <b>stereoPingpong</b>.&nbsp; 
In Figure 7, you can see the signals for each of the channels being switched on 
and off in an alternating manner.<blockquote>

<p>
<i>(When the left channel is on, the right channel is off, and vice versa.)</i></blockquote>

<p align="center">
<img border="0" src="java2022g.gif" width="390" height="381"><p align="center">
Figure 7&nbsp; Waveforms from <b>stereoPingpong</b> method<p>
Because of the horizontal compression, you can't tell anything about the 
frequencies involved in Figure 7.<p>
Figure 8 shows a time-expanded waveform display of a very small time slice taken 
at one of the transition points where the left channel is being turned off 
and the right channel is being turned on.<p align="center">
<img border="0" src="java2022h.gif" width="390" height="381"><p align="center">
Figure 8&nbsp; Time-expanded waveforms from <b>stereoPingpong</b> method<p>
If you measure the time between the peaks on the two signals, you can confirm 
that the frequency of the right channel is lower than the frequency of the left 
channel, as indicated in Listing 25.<p>
<font color="#FF0000"><b>Some background on the fmSweep method</b></font><p>
I have spent a good portion of my career doing digital signal processing <i>
(DSP).</i>&nbsp; During part of that time, I worked in the submarine 
sonar business.<p>
There are fundamentally two types of sonar systems, active and passive.&nbsp; 
Active sonar systems are the ones that you usually see in the movies, where a 
ship transmits a <i>ping</i> into the water and listens for an echo that comes back 
from other objects in the water, such as submarines.<p>
Passive sonar is not frequently shown in the movies because it doesn't appear 
to do anything.&nbsp; With a passive sonar, the system, <i>(including the human 
operator),</i> simply listens for sounds in the water, and tries to identify those 
sounds as friendly or unfriendly.<p>
Typically surface ships use active sonar and submarines use passive sonar.<p>
<font color="#FF0000"><b>Different types of pings</b></font><p>
The actual sound pulse that is put into the water by an active sonar can take on 
many different waveforms.&nbsp; One waveform that is fairly popular 
is a linear FM sweep.&nbsp; This is a waveform where a carrier frequency 
undergoes frequency modulation from a low frequency to a higher frequency, or 
vice versa.&nbsp; This particular waveform has a number of desirable 
characteristics having to do with underwater physics, digital signal processing, 
Doppler effects, etc.<blockquote>

<p>
<i>(By the way, the sound produced by an active sonar is a good example of 
synthetic sound.&nbsp; The sound is not produced by someone banging on a piece 
of steel with a hammer and recording the resulting sound through a microphone.&nbsp; 
Rather, the sound is produced by evaluating some sort of algorithm using some 
sort of electronic device, and then converting the results of that evaluation into 
sound pressure waves in the water.)</i></blockquote>

<p>
<font color="#FF0000"><b>The fmSweep method</b></font><p>
This method generates a monaural linear frequency sweep that begins at 100 Hz 
and changes linearly up to 1000 Hz during the two-second elapsed time period of 
the sound.<p>
The <b>fmSweep</b> method begins in Listing 26.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>  void <b>fmSweep</b>(){
    channels = 1;//Java allows 1 or 2
    int bytesPerSamp = 2;//Based on channels
    sampleRate = 16000.0F;
    // Allowable 8000,11025,16000,22050,44100
    int sampLength = byteLength/bytesPerSamp;

<b>    double lowFreq = 100.0;
    double highFreq = 1000.0;</b>

<b><font face="Courier New,Courier">Listing 26</font></b></pre>
</td>
</tr>
</table>

<p>
Listing 26 initializes the typical variables.&nbsp; In addition, Listing 26 
declares and initializes variables containing the low and high frequency values 
that will be used in the <b>for</b> loop that follows.<p>
<font color="#FF0000"><b>Generate the synthetic sound</b></font><p>
The synthetic sound data is generated by the <b>for</b> loop shown in Listing 
27.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>    for(int cnt = 0; cnt < sampLength; cnt++){
      double time = cnt/sampleRate;

      <b>double freq = lowFreq +
               cnt*(highFreq-lowFreq)/sampLength;</b>
      double sinValue =
                   Math.sin(2*Math.PI*freq*time);
      shortBuffer.put((short)(16000*sinValue));
    }//end for loop
  }//end method fmSweep

<b><font face="Courier New,Courier">Listing 27</font></b></pre>
</td>
</tr>
</table>

<p>
The thing that is new and different in Listing 27 is the statement that is 
highlighted in boldface.&nbsp; This statement computes a new frequency value to 
be used during each iteration.&nbsp; The frequency value changes linearly from 
low to high during the two-second elapsed time interval for the sound.<p>
<font color="#FF0000"><b>Waveform</b></font><p>
Figure 9 shows a time-expanded waveform for the beginning of the signal produced 
by the <b>fmSweep</b> method.<blockquote>

<p>
<i>(Note that in this format, instead of drawing lines, the graphics program 
fills in the entire area under the curve.)</i></blockquote>

<p align="center">
<img border="0" src="java2022i.gif" width="391" height="382"><p align="center">
Figure 9&nbsp; Time-expanded waveform from <b>fmSweep</b> method<p>
By observing the distance between the peaks in Figure 9,  this waveform 
confirms the implementation of the algorithm in Listing 27.&nbsp; The frequency 
of the sine wave increases with time.<p>
<font color="#FF0000"><b>The decayPulse method</b></font><p>
The sound produced by this method is significantly different from the sounds 
produced by the previous methods.&nbsp; The previous methods have produced 
sounds, which had essentially constant intensity during the entire elapsed time 
period of the sound <i>(although that intensity may have been allocated between 
two different channels).</i><p>
The <b>decayPulse</b> method generates a monaural pulse for which the intensity 
decays over time.&nbsp; The decay function is linear with respect to time.&nbsp; 
The pulse begins with a maximum amplitude.&nbsp; The amplitude of the pulse 
decreases linearly with time and goes to zero at the end of one second.<p>
The pulse is made up of the sum of three sinusoids at different frequencies.<p>
The <b>decayPulse</b> method begins in Listing 28, by initializing the typical 
values.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>  void <b>decayPulse</b>(){
    channels = 1;//Java allows 1 or 2
    int bytesPerSamp = 2;//Based on channels
    sampleRate = 16000.0F;
    // Allowable 8000,11025,16000,22050,44100
    int sampLength = byteLength/bytesPerSamp;

<b><font face="Courier New,Courier">Listing 28</font></b></pre>
</td>
</tr>
</table>

<p>
<font color="#FF0000"><b>Generate the synthetic sound</b></font><p>
The <b>for</b> loop, which is used to generate the sound, begins in Listing 29.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>    <b>for</b>(int cnt = 0; cnt < sampLength; cnt++){
      double scale = 2*cnt;
      if(scale > sampLength) scale = sampLength;

<b><font face="Courier New,Courier">Listing 29</font></b></pre>
</td>
</tr>
</table>

<p>
<font color="#FF0000"><b>The scale variable</b></font><p>
The code in Listing 29 declares and initializes a variable named <b>scale</b>.&nbsp; 
The value of <b>scale</b> determines the rate of decay of the resulting pulse.&nbsp; 
Large values of <b>scale</b> cause the pulse to decay rapidly, while small 
values of <b>scale</b> cause the pulse to decay less rapidly.<blockquote>
  <p>
<i>(For example, to increase the rate of decay, change the literal constant 2 to 
a larger value.&nbsp; To decrease the rate of decay, change the literal constant 
2 to a smaller value.)</i></blockquote>
<p>
By virtue of the manner in which <b>scale</b> is used later in the algorithm, it 
is necessary to clip the value of <b>scale</b> at a maximum value of <b>sampLength</b>.&nbsp; This is also accomplished by the code in Listing 29.<p>
<font color="#FF0000"><b>Time-varying gain</b></font><p>
As with some of the previous methods, this method also uses a time-varying gain 
value.&nbsp; In this case, the time-varying gain describes a decay function that 
decays in a linear fashion with respect to time. The 
statement that computes the time-varying gain value is shown in Listing 30.<blockquote>
  <p>
<i>(This value varies with time because it is based on the value of <b>scale</b>, 
which varies with time as shown in Listing 29.)</i></blockquote>
<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>      double gain = 
             16000*(sampLength-<b>scale</b>)/sampLength;

<b><font face="Courier New,Courier">Listing 30</font></b></pre>
</td>
</tr>
</table>

<p>
<font color="#FF0000"><b>The remaining code</b></font><p>
The remaining code in the <b>for</b> loop  is shown in Listing 31.&nbsp; 
This code is very similar to what you have seen previously, and should not 
require further explanation.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>      double time = cnt/sampleRate;
      double freq = 499.0;//an arbitrary freq
      double sinValue =
        (Math.sin(2*Math.PI*freq*time) +
        Math.sin(2*Math.PI*(freq/1.8)*time) +
        Math.sin(2*Math.PI*(freq/1.5)*time))/3.0;
      shortBuffer.put((short)(gain*sinValue));
    }//end for loop
  }//end method decayPulse

<b><font face="Courier New,Courier">Listing 31</font></b></pre>
</td>
</tr>
</table>

<p>
<font color="#FF0000"><b>Waveform</b></font><p>
Figure 10 shows the single-channel, two-second waveform produced by the <b>
decayPulse</b> method.<p align="center">
<img border="0" src="java2022j.gif" width="390" height="382"><p align="center">
Figure 10&nbsp; Waveform from <b>decayPulse</b> method<p>
As you can see in Figure 10, the amplitude of the signals goes from maximum to 
zero in a linear fashion during the first one-second of the two-second interval 
covered by the synthetic sound.&nbsp; This confirms the algorithm defined in 
Listings 29, 30, and 31.<blockquote>
  <p>
<i>(This synthetic sound makes use of sinusoidal functions that are similar to 
those used in the <b>tones</b> method, except that the base frequency is lower.&nbsp; 
If I were to show a time-expanded view of the waveform, it would look similar to 
that shown in Figure 3)</i></blockquote>
<p>
<font color="#FF0000"><b>The echoPulse method</b></font><p>
The<b> echoPulse </b>method generates a monaural triple-frequency pulse that decays in a linear fashion with time.&nbsp; 
The synthetic sound data generated by this method begins the same as the sound 
data produced by the previously discussed method named <b>decayPulse</b>.&nbsp; 
However, with this method, three echoes can be heard over time with the amplitude of the echoes decreasing with time.<p>
The beginning of the <b>echoPulse</b> method, including the initialization of 
the typical variables, is shown in Listing 32.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>  void <b>echoPulse</b>(){
    channels = 1;//Java allows 1 or 2
    int bytesPerSamp = 2;//Based on channels
    sampleRate = 16000.0F;
    // Allowable 8000,11025,16000,22050,44100
    int sampLength = byteLength/bytesPerSamp;

<b><font face="Courier New,Courier">Listing 32</font></b></pre>
</td>
</tr>
</table>

<p>
<font color="#FF0000"><b>The time-delay factors</b></font><p>
The sound data produced by this method consists of the sum of four pulses 
occurring at different times.&nbsp; The first pulse occurs at zero time.&nbsp; 
The remaining three pulses are delayed relative to 
the previous pulse, and have a lower amplitude than the previous pulse.<p>
The delays <i>(in samples)</i> that are applied to the three delayed pulses are controlled by the 
three variables that are declared and initialized in Listing 33.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>    int cnt2 = -8000;
    int cnt3 = -16000;
    int cnt4 = -24000;

<b><font face="Courier New,Courier">Listing 33</font></b></pre>
</td>
</tr>
</table>

<p>
The first pulse begins at the beginning of the sound data.&nbsp; The second 
pulse begins at sample number 8000.&nbsp; The third pulse begins at sample 
number 16000, and the fourth pulse begins at sample number 24000.&nbsp; All 
three pulses have the same waveform with decreased amplitude.<p>
<font color="#FF0000"><b>The echoPulseHelper Method</b></font><p>
Because this method is required to generate four separate pulses instead of just 
one, I elected to break a portion of the code out and put it into a helper 
method named <b>echoPulseHelper</b>.&nbsp; 

<p>
The entire <b>echoPulseHelper Method</b> is shown in Listing 34.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>  double <b>echoPulseHelper</b>(int cnt,int sampLength){
    //The value of scale controls the rate of
    // decay - large scale, fast decay.
    double scale = 2*cnt;
    if(scale > sampLength) scale = sampLength;
    double gain = 
             16000*(sampLength-scale)/sampLength;
    double time = cnt/sampleRate;
    double freq = 499.0;//an arbitrary freq
    double sinValue =
      (Math.sin(2*Math.PI*freq*time) +
      Math.sin(2*Math.PI*(freq/1.8)*time) +
      Math.sin(2*Math.PI*(freq/1.5)*time))/3.0;
    return(short)(gain*sinValue);
  }//end echoPulseHelper

<b><font face="Courier New,Courier">Listing 34</font></b></pre>
</td>
</tr>
</table>

<p>
This code in this method is identical to code in the <b>decayPulse</b> method 
and should not require an explanation.<p>
<font color="#FF0000"><b>Now back to the echoPulse method</b></font><p>
Returning to the discussion of the <b>echoPulse</b> method, the code in Listing 
35 shows the beginning of the <b>for</b> loop that is used to generate the 
synthetic sound data.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>    <b>for</b>(int cnt1 = 0; cnt1 < sampLength;
                    <b>cnt1++,cnt2++,cnt3++,cnt4++</b>){
      double val = echoPulseHelper(
                                cnt1,sampLength);
<b><font face="Courier New,Courier">Listing 35</font></b></pre>
</td>
</tr>
</table>

<p>
<font color="#FF0000"><b>Update all counter values</b></font><p>
Two things are worth noting in Listing 35.&nbsp; The first is that all four 
counter values are incremented in the update clause of the <b>for</b> loop.&nbsp; 
This not only includes the counter named <b>cnt1</b> that is used in the conditional 
clause of the <b>for</b> loop, it also includes the other three counters that 
were declared and initialized in Listing 33.<p>
<font color="#FF0000"><b>Call the echoPulseHelper method</b></font><p>
The second thing that is worthy of note is that the code in Listing 35 calls the
<b>echoPulseHelper</b> method, passing <b>cnt1</b> as a parameter, to get a value for each iteration of the <b>for</b> 
loop.&nbsp; Each call to the <b>echoPulseHelper</b> method passes a value of the 
counter.&nbsp; The value returned by the method is the correct value for that 
particular iteration of the <b>for</b> loop.<p>
<font color="#FF0000"><b>Get and add value for first delayed pulse</b></font><p>
For positive values of <b>cnt2</b>, the code in Listing 36 calls the <b>echoPulseHelper</b> method to get a value 
for the first delayed pulse, and adds that value to the value produced earlier 
by the code in Listing 35.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>      if(<b>cnt2 > 0</b>){
        val += 0.7 * echoPulseHelper(
                                cnt2,sampLength);
      }//end if

<b><font face="Courier New,Courier">Listing 36</font></b></pre>
</td>
</tr>
</table>

<p>
<font color="#FF0000"><b>A time delay is implemented</b></font><p>
Recall that the vale of <b>cnt2</b> was initialized to -8000 in Listing 33, and 
that the value of <b>cnt2</b> is incremented  at the end of each iteration of 
the <b>for</b> loop in Listing 35.<p>
Because of the conditional clause in the <b>if</b> statement in Listing 36, the 
code in Listing 36 contributes nothing to the synthetic sound data until the 
<b>for</b> loop has gone through the required number of iterations to cause the 
value of <b>cnt2</b> to go positive.&nbsp; At that point in time, the 
code in Listing 36 begins calling the <b>echoPulseHelper</b> method to get the values for 
another pulse.&nbsp; These values are scaled down by 0.7 and added to the values 
produced by the code in Listing 35.&nbsp; The result is that a second, 
attenuated pulse is generated and added to the first pulse at that point in 
time.<p>
<font color="#FF0000"><b>Add two more time-delayed pulses</b></font><p>
The code in Listing 37 causes two more time-delayed pulses to be generated and 
added to the synthetic sound data beginning around sample number 16000 and sample 
number 24000.&nbsp; These pulses are scaled by attenuation factors of 0.49 and 
0.34 respectively.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>      if(cnt3 > 0){
        val += 0.49 * echoPulseHelper(
                                cnt3,sampLength);
      }//end if
      if(cnt4 > 0){
        val += 0.34 * echoPulseHelper(
                                cnt4,sampLength);
      }//end if

      shortBuffer.<b>put</b>((short)val);
    }//end for loop
  }//end method echoPulse

<b><font face="Courier New,Courier">Listing 37</font></b></pre>
</td>
</tr>
</table>

<p>
Listing 37 also contains the requisite call to the <b>put</b> method to cause 
the synthetic sound data to be deposited in the <b>audioData</b> array during 
each iteration of the <b>for</b> loop.<p>
<font color="#FF0000"><b>Waveform</b></font><p>
Figure 11 shows the waveform produced by the <b>echoPulse</b> method.<p align="center">
<img border="0" src="java2022k.gif" width="389" height="383"><p align="center">
Figure 11&nbsp; Waveform from <b>echoPulse</b> method<p>
<font color="#FF0000"><b>Is this what you expected?</b></font><p>
This may not be what you expected to see for this method.&nbsp; You may have 
expected the three pulses that were added in after a time delay to be more 
obvious.&nbsp; However, this is one of the reasons that a visual analysis of the 
synthetic signal produced by your algorithm is very valuable.<p>
<font color="#FF0000"><b>Why aren't the pulses more obvious?</b></font><p>
Remember that the  output produced by the <b>echoPulseHelper</b> method <i>
(Listing 34)</i> is simply a sequence of positive and negative values.&nbsp; 
Four versions of the output from the <b>echoPulseHelper</b> method, three with 
time delays, were added together.<p>
Remember also that the underlying waveform for each of the sequences produced by 
the <b>echoPulseHelper</b> method is a pseudo-periodic function with an odd 
symmetry <i>(a periodic 
function with an amplitude that decreases linearly with time).</i><p>
<font color="#FF0000"><b>Is cancellation possibility?</b></font><p>
Were it not for the decreasing amplitude, there are certain time delays where 
the registration between two of the sequences would be such that the positive 
and negative values belonging to one sequence would exactly cancel the positive 
and negative values belonging to the other sequence.&nbsp; 

<p>
Therefore, in the absence of a decreasing amplitude, when two of the sequences 
are added together, one with a time delay and the other without a time delay, 
the sum could be:<ul>
  <li>All zero values</li>
  <li>Values that are exactly double the original values</li>
  <li>Values in between the two extremes, depending on the exact amount of time 
  delay involved</li>
  </ul>

<p>
<font color="#FF0000"><b>Low side of the range</b></font><p>
For the time delays used in this method, the values resulting from adding the 
sequences seem to be on the low side of that allowable range.<blockquote>

<p>
<i>(The result will be different for the waveform for the <b>waWaPulse</b> 
method to be discussed later.)</i></blockquote>

<p>
Again, this is a reason that the ability to examine the waveform is very 
valuable when creating synthetic sound signals.&nbsp; Although it would be 
possible to determine the result analytically by hand, that would require a very tedious 
effort.<p>
<font color="#FF0000"><b>The waWaPulse method</b></font><p>
The <b>waWaPulse</b> method is identical to the&nbsp;method named <b>echoPulse</b>, except that the algebraic sign was switched on the amplitude of two of the echoes before adding them to the composite synthetic signal.&nbsp; This resulted in 
some differences in the synthetic sound data.<p>
The entire <b>waWaPulse</b> method can be viewed in Listing 49 near the end of 
the lesson.&nbsp; Listing 38 shows only the <b>for</b> loop portion of the 
method, with the code that is different from the <b>echoPulse</b> method 
highlighted in boldface.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>    for(int cnt1 = 0; cnt1 < sampLength;
                    cnt1++,cnt2++,cnt3++,cnt4++){
      double val = waWaPulseHelper(
                                cnt1,sampLength);
      if(cnt2 > 0){
        <b>val += -0.7 </b>* waWaPulseHelper(
                                cnt2,sampLength);
      }//end if
      if(cnt3 > 0){
        val += 0.49 * waWaPulseHelper(
                                cnt3,sampLength);
      }//end if
      if(cnt4 > 0){
        <b>val += -0.34</b> * waWaPulseHelper(
                                cnt4,sampLength);
      }//end if

      shortBuffer.put((short)val);
    }//end for loop

<b><font face="Courier New,Courier">Listing 38</font></b></pre>
</td>
</tr>
</table>

<p>
<font color="#FF0000"><b>Waveform</b></font><p>
The waveform produced by the <b>waWaPulse</b> method is shown in Figure 12.&nbsp; 
Compare this to the waveform produced by the <b>echoPulse</b> method in Figure 
11, and you should notice a striking difference between the two.<p align="center">
<img border="0" src="java2022l.gif" width="390" height="384"><p align="center">
Figure 12&nbsp; Waveform from <b>waWaPulse</b> method<p>
It appears that in this case, the time delays used, in combination with the 
algebraic signs on the scale factors caused the waveforms to add constructively, 
whereas the waveforms in Figure 11 seem to have added destructively.<p>
You should also be able to notice that difference when listing to the synthetic 
sounds produced by the <b>echoPulse</b> and <b>waWaPulse</b> methods.<blockquote>
  <p>
<i>(Because of constructive and destructive addition when adding delayed 
waveforms together, sometimes seemingly small changes can make big differences 
is a synthetic sound.)</i></blockquote>
<p>
<font color="#FF0000"><b>Creating your own synthetic sounds</b></font><p>
Once again, I encourage you to use this program as a framework to create and 
experiment with synthetic sounds of your own design.&nbsp; <p>
You may find some ideas for synthetic sound algorithms on the
<a href="http://users.iafrica.com/k/ku/kurient/dsp/effects.html">Audio Effects</a> 
web page.<blockquote>
  <p>
<i>(Note that the Wah-Wah effect described there has no relationship to my 
method named <b>waWaPulse</b>.&nbsp; I used that simply as a unique method name.&nbsp; 
The author of the
<a href="http://users.iafrica.com/k/ku/kurient/dsp/effects.html">Audio Effects</a> 
page used it as the actual name of an audio effect.)</i></blockquote>
<p>
<font color="#FF0000"><b>Now back to the constructor for the controlling class</b></font><p>
That concludes the explanation of the methods that are used to generate the 
different kinds of synthetic sound data.&nbsp; Now it is time to return to the 
discussion of the constructor where I left off with Listing 12.<p>
At this point, you understand how the following statement in Listing 12 causes 
the array named <b>audioData</b> to be filled with synthetic sound data 
according to the radio button that is selected in the center of Figure 1:<p>
<b><font face="Courier New" size="2">new SynGen().getSyntheticData(audioData);</font></b><p>
<font color="#FF0000"><b>Play or file the synthetic sound data</b></font><p>
The code in Listing 39 instantiates an <b>ActionListener</b> object and 
registers it on the <b>Play/File</b> button shown in Figure 1.&nbsp; If you have 
been studying the previous lessons in this series, you will understand this 
style of programming using anonymous objects instantiated from anonymous 
classes.<p>
In any event, in the context of this lesson, the most important code in Listing 
39 is the statement that is highlighted in boldface.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>    playOrFileBtn.addActionListener(
      new ActionListener(){
        public void actionPerformed(
                                  ActionEvent e){
          //Play or file the data synthetic data
          <b>playOrFileData();</b>
        }//end actionPerformed
      }//end ActionListener
    );//end addActionListener()

<b><font face="Courier New,Courier">Listing 39</font></b></pre>
</td>
</tr>
</table>

<p>
The boldface statement in Listing 39 invokes the <b>playOrFileData</b> method 
each time the user clicks the <b>Play/File</b> button in Figure 1.<p>
<font color="#FF0000"><b>The playOrFileData method</b></font><p>
Once again, I'm going to depart from a purely sequential explanation of the 
program code and discuss the method named <b>playOrFileData</b>.&nbsp; I 
will return to a discussion of the constructor later.<p>
The <b>playOrFileData</b>&nbsp;method plays or files the synthetic sound data that has been generated and saved in an array in memory.&nbsp; 
If a decision is made to file the data, it is written to an audio file of type
<b>AU</b>.<blockquote>
  <p>
<i>(Much of the material that follows has been discussed in 
previous lessons, so I will discuss it only briefly here.)</i></blockquote>
<p>
The beginning of the <b>playOrFileData</b> method is shown in Listing 40.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>  private void <b>playOrFileData</b>() {
    try{
      InputStream byteArrayInputStream =
                        new ByteArrayInputStream(
                                      <b>audioData</b>);

<b><font face="Courier New,Courier">Listing 40</font></b></pre>
</td>
</tr>
</table>

<p>
The code in Listing 40 gets a <b>ByteArrayInputStream</b> object based on the 
synthetic sound data previously generated and stored in the array referred to by
<b>audioData</b>.<p>
<font color="#FF0000"><b>Establish the audio format</b></font><p>
The code in Listing 41 instantiates an <b>AudioFormat</b> object, based on the 
values stored in the audio format variables of Listing 2.&nbsp; This is the 
audio format that will be used when playing back the synthetic sound data, or 
when writing that data into an audio file.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>      audioFormat = new AudioFormat(
                                sampleRate,
                                sampleSizeInBits,
                                channels,
                                signed,
                                bigEndian);

<b><font face="Courier New,Courier">Listing 41</font></b></pre>
</td>
</tr>
</table>

<p>
Recall that the values stored in some of these variables may have been modified 
by the code in the synthetic sound data generator methods.&nbsp; For example, 
those methods that generate monaural sound data will have set the value of <b>
channels</b> to 1, while the methods that generate stereo data will have set the 
value of <b>channels</b> to 2.<p>
Thus, the format values set by the generator methods will be used to either play 
the audio data back, or to write that data into an audio file.<p>
<font color="#FF0000"><b>Instantiate an audio input stream</b></font><p>
The code in Listing 42 instantiates a required <b>AudioInputStream</b> object 
based on the data in the <b>ByteArrayInputStream</b>, and the audio format 
established from the default values in Listing 2 and the modified values that 
were set by the synthetic sound data generator program that produced the data.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>      audioInputStream = new AudioInputStream(
                    byteArrayInputStream,
                    audioFormat,
                    audioData.length/audioFormat.
                                 getFrameSize());

<b><font face="Courier New,Courier">Listing 42</font></b></pre>
</td>
</tr>
</table>

<p>
<font color="#FF0000"><b>Get a SourceDataLine object</b></font><p>
A <b>SourceDataLine</b> object handles the actual real-time delivery of the data 
to the speakers.&nbsp; The code in Listing 43 gets a <b>SourceDataLine</b> 
object.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>      DataLine.Info dataLineInfo =
                          new DataLine.Info(
                            SourceDataLine.class,
                                    audioFormat);

      //Geta SourceDataLine object
      sourceDataLine = (SourceDataLine)
                             AudioSystem.getLine(
                                   dataLineInfo);

<b><font face="Courier New,Courier">Listing 43</font></b></pre>
</td>
</tr>
</table>

<p>
I have discussed code similar to that in Listing 43 in several previous lessons, 
so I won't discuss it further here.<p>
<font color="#FF0000"><b>Play the data, or write it into an audio file</b></font><p>
The code in Listing 44 examines the radio buttons at the bottom of the GUI in 
Figure 1 to decide whether to play the synthetic sound data back immediately, or 
to write that data into an audio file of type <b>AU</b>.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>      <b>if(listen.isSelected()</b>){
        new ListenThread().start();
      }else{
        //Write the synthetic data to an audio
        // file of type AU.

<b><font face="Courier New,Courier">Listing 44</font></b></pre>
</td>
</tr>
</table>

<p>
If the user has selected the <b>Listen</b> button on the bottom of the GUI, the 
code in Listing 44 instantiates a <b>ListenThread</b> object and starts it 
running to play back the synthetic sound data immediately.<p>
Otherwise, the code in Listing 44 writes the synthetic sound data to an audio 
file of type <b>AU</b>.<p>
<font color="#FF0000"><b>The ListenThread class</b></font><p>
The code in the <b>ListenThread</b> method is so similar to code used to play 
back audio data in previous lessons that there is no point in discussing it  here.&nbsp; You can view a complete listing of the <b>ListenThread</b> 
class in Listing 49 near the end of the lesson.&nbsp; If you don't understand 
that code, please go back and review the previous lessons in this series.<p>
<font color="#FF0000"><b>Playback quality</b></font><p>
Some comments regarding playback quality are  in order.&nbsp; 
One of the aspects of playing back synthetic sound data <i>(as opposed to 
microphone data)</i> is that you can know exactly what it should sound like, and 
you can play the same data back repeatedly and listen to it more than once.&nbsp; This makes it possible to 
identify playback quality problems that might not be as obvious when playing 
back microphone data.<p>
My computer is several years old, and is not very fast.&nbsp; Whenever I use 
this program to play back the synthetic data, I hear clicks in the playback that 
are not in the data.<blockquote>
  <p>
<i>(I can confirm that the clicks are not in the data by saving the data into a 
file and playing it back using a media player such as the Windows Media Player, 
or the RealOne Player.)</i></blockquote>
<p>
Although I'm not certain, this may indicate that my computer is incapable of 
delivering the audio data to the speakers in real time using the playback loop 
in the <b>ListenThread</b> class.<p>
Furthermore, I have experimented with similar playback loops written by others, 
including code snippets that are available on the Sun site, and am unable to 
eliminate this problem.<p>
I mention this here so that you can be on the lookout for similar problems when 
you compile and execute this program on your system.<p>
<font color="#FF0000"><b>An audio output file of type AU</b></font><p>
Now, going back and picking up with the <b>else</b> clause in Listing 44, I will 
explain the code that writes the synthetic sound data into an audio file of type
<b>AU</b>.<p>
The code in Listing 45 disables both of the buttons at the top of the GUI in 
Figure 1 to prevent them from firing action events while the data is being 
written to the disk file.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>        generateBtn.setEnabled(false);
        playOrFileBtn.setEnabled(false);

<b><font face="Courier New,Courier">Listing 45</font></b></pre>
</td>
</tr>
</table>

<p>
<font color="#FF0000"><b>Write the file</b></font><p>
The code that writes the data into the audio file is shown in Listing 46.&nbsp; 
This code is very simple.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>        try{
          AudioSystem.<b>write</b>(
                    audioInputStream,
                    AudioFileFormat.Type.AU,
                    new File(fileName.getText() +
                                         ".au"));
        }catch (Exception e) {
          e.printStackTrace();
          System.exit(0);
        }//end catch

<b><font face="Courier New,Courier">Listing 46</font></b></pre>
</td>
</tr>
</table>

<p>
This code makes use of the static <b>write</b> method of the <b>AudioSystem</b> 
class to transfer the data from the <b>AudioInputStream</b> object <i>(provided 
as the first parameter)</i> to the audio file.<blockquote>

<p>
<i>(The <b>AudioInputStream</b> object was instantiated in Listing 42.)</i></blockquote>

<p>
The type of the audio file is specified as the second parameter to the <b>write</b> method.<blockquote>

<p>
<i>(This code writes an audio file of type AU by default.&nbsp; If your system 
doesn't support that file type, you can easily write a different file type by 
modifying the second parameter.)</i></blockquote>

<p>
The name of the audio file is extracted from the text field at the bottom of the 
GUI in Figure 1, and provided as the third parameter to the <b>write</b> method.<p>
<font color="#FF0000"><b>Enable the Generate and Play/File buttons</b></font><p>
After the file has been written, the code in Listing 47 enables both of the buttons at the top of the GUI in 
Figure 1 to get the system ready for another operation.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>        generateBtn.setEnabled(true);
        playOrFileBtn.setEnabled(true);
      }//end else

<b><font face="Courier New,Courier">Listing 47</font></b></pre>
</td>
</tr>
</table>

<p>
Except for a <b>catch</b> block that you can view in Listing 49 near the end of 
the lesson, the code in Listing 47 signals the end of the <b>playOrFile</b> 
method.<p>
<font color="#FF0000"><b>Return to the constructor again</b></font><p>
Returning once again to the place in the constructor where I left off in Listing 
39, the code in Listing 48:<ul>
  <li>Adds two buttons and a text field to a panel, which will appear at the top 
  of the GUI.</li>
  <li>Adds seven radio buttons to a mutually exclusive group, which will appear 
  in the center of the GUI.&nbsp; If you add a new generator method to the 
  program, you will need to create a new radio button and add it to this group.</li>
  <li>Adds the seven radio buttons to a panel, which will appear centered 
  horizontally in the center of the GUI.&nbsp; You will also need to make an 
  addition here if you add a new generator method to the program.</li>
  <li>Adds two radio buttons to a mutually exclusive group, which will appear at 
  the bottom of the GUI.</li>
  <li>Adds the two radio buttons and a text field to a panel, which will appear 
  at the bottom of the GUI.</li>
  <li>Adds the three panels to the content pane at the North, Center, and South 
  locations in the JFrame object that constitutes the GUI.</li>
  <li>Takes care of a few more odds and ends necessary to make the GUI appear on 
  the screen with the correct title, correct size, etc.</li>
  </ul>
  <p>
The code to accomplish these tasks is straightforward, so I won't discuss it in 
detail here.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>//Continue discussion of the constructor here

    //Add two buttons and a text field to a
    // panel in the North of the GUI.
    controlButtonPanel.add(generateBtn);
    controlButtonPanel.add(playOrFileBtn);
    controlButtonPanel.add(elapsedTimeMeter);

    //Add radio buttons to a mutually exclusive
    // group in the Center of the GUI.  Make
    // additions here if you add new synthetic
    // generator methods.
    synButtonGroup.add(tones);
    synButtonGroup.add(stereoPanning);
    synButtonGroup.add(stereoPingpong);
    synButtonGroup.add(fmSweep);
    synButtonGroup.add(decayPulse);
    synButtonGroup.add(echoPulse);
    synButtonGroup.add(waWaPulse);

    //Add radio buttons to a panel and
    // center it in the Center of the GUI. Make
    // additions here if you add new synthetic
    // generator methods.
    synButtonPanel.setLayout(
                            new GridLayout(0,1));
    synButtonPanel.add(tones);
    synButtonPanel.add(stereoPanning);
    synButtonPanel.add(stereoPingpong);
    synButtonPanel.add(fmSweep);
    synButtonPanel.add(decayPulse);
    synButtonPanel.add(echoPulse);
    synButtonPanel.add(waWaPulse);

    //Note that the centerPanel has center
    // alignment by default.
    centerPanel.add(synButtonPanel);

    //Add radio buttons to a mutually exclusive
    // group in the South of the GUI.
    outputButtonGroup.add(listen);
    outputButtonGroup.add(file);

    //Add radio buttons to a panel in
    // the South of the GUI.
    outputButtonPanel.add(listen);
    outputButtonPanel.add(file);
    outputButtonPanel.add(fileName);

    //Add the panels containing components to the
    // content pane of the GUI in the appropriate
    // positions.
    getContentPane().add(
          controlButtonPanel,BorderLayout.NORTH);
    getContentPane().add(centerPanel,
                            BorderLayout.CENTER);
    getContentPane().add(outputButtonPanel,
                             BorderLayout.SOUTH);

    //Finish the GUI.  If you add more radio
    // buttons in the center, you may need to
    // modify the call to setSize to increase
    // the vertical component of the GUI size.
    setTitle("Copyright 2003, R.G.Baldwin");
    setDefaultCloseOperation(EXIT_ON_CLOSE);
    setSize(250,275);
    setVisible(true);
  }//end constructor
  //-------------------------------------------//
}//end outer class AudioSynth01.java

<b><font face="Courier New,Courier">Listing 48</font></b></pre>
</td>
</tr>
</table>

<p>
The code in Listing 48 also signals the end of the constructor and the end of 
the program.<center>
<h2>
<a NAME="Run the program"></a>Run the Program</h2></center>
        <p>
      At this point, you may find it useful to compile and run the program shown 
      in Listing 49 near the end of the lesson.&nbsp; Operating instructions 
      were provided earlier in the section entitled <b>Operating instructions</b>.<p>
If you use a media player, such as the Windows Media Player, to play back your 
file, be sure to release the old file from the media player before attempting to create a new file with the same 
name and extension.&nbsp; Otherwise, the program will not be able to create the 
new file, and a runtime error will occur.<p>
Also be aware that this program makes use of Java features in the <b>java.nio</b> 
package, which was first released in Java version 1.4.&nbsp; Therefore, you must 
be running version 1.4 or later to successfully compile and run this program.<h2 align="center"><a name="Summary">Summary</a></h2>
  <p>In this lesson, I showed you how to create synthetic sound data and how to 
  play it back immediately, or to save it in an audio file of type <b>AU</b>.&nbsp; </p>
  <p>Because this lesson is somewhat long and complex, I will recap the essence 
  of creating, playing, and filing synthetic sound in this summary section.</p>
  <p><font color="#FF0000"><b>First you need an algorithm to create the data</b></font></p>
  <p>To create synthetic sound, you must write an algorithm that will place 
  bytes of synthetic sound data into an array of type <b>byte</b>.&nbsp; The 
  values of the bytes must represent the synthetic sound samples.</p>
  <p><font color="#FF0000"><b>Keep the audio format in mind</b></font></p>
  <p>When you create the bytes that represent the synthetic sound samples, you 
  must keep in mind the audio format that will be used to play back the data, or 
  to save the data into an audio file.&nbsp; You must arrange the bytes in the 
  byte array in a manner that is consistent with that format.</p>
  <p><font color="#FF0000"><b>Audio format attributes</b></font></p>
  <p>An audio format consists of the following attributes.&nbsp; <i>(The choices 
  supported by Java version 1.4 are listed.)</i></p>
  <ul>
    <li>Encoding scheme, ALAW, PCM_SIGNED, PCM_UNSIGNED, OR ULAW</li>
    <li>Sample rate, 8000, 11025, 16000, 22050, or 44100 samples per second.</li>
    <li>Sample size, 8 bits or 16 bits</li>
    <li>Number of channels, 1 or 2</li>
    <li>Signed or unsigned for PCM encoding.</li>
    <li>Big-endian or little-endian byte order</li>
  </ul>
  <p><font color="#FF0000"><b>Some formats are easy</b></font></p>
  <p>Some formats are much easier to handle in Java than others.&nbsp; This is 
  particularly true if your algorithm requires the use of arithmetic operations.</p>
  <p>For example, Java data of type <b>short</b> is naturally compatible with 
  PCM_SIGNED, 16-bit, big-endian format.</p>
  <blockquote>
  <p><i>(Due to its ease of use, this is the format that was used for all the 
  samples in this lesson.)</i></p>
  </blockquote>
  <p>Java data of type <b>byte</b> is naturally compatible with PCM_SIGNED, 
  8-bit, big-endian format.</p>
  <blockquote>
  <p><i>(This format is also relatively easy to use, but it has very limited 
  dynamic range.&nbsp; Integer overflow is a constant potential problem when 
  doing 8-bit arithmetic.&nbsp; For that reason, this format was not used for 
  any of the samples in this lesson.)</i></p>
  </blockquote>
  <p><font color="#FF0000"><b>Some formats are more difficult</b></font></p>
  <p>If you want to use ALAW or ULAW encoding, PCM_UNSIGNED, or little-endian 
  byte order, you are going to have to expend some extra programming effort to convert 
  the data that is naturally produced by Java arithmetic operations to the other 
  format parameters.</p>
  <p><font color="#FF0000"><b>Generate the synthetic sound data</b></font></p>
  <p>Having defined an algorithm, and having chosen an audio format, you must 
  generate the synthetic sound data samples and store them in the <b>byte</b> 
  array with an arrangement that matches the chosen format parameters.</p>
  <p><font color="#FF0000"><b>The java.nio package can be very useful</b></font></p>
  <p>If you are creating 16-bit audio data samples as type <b>short</b>, you can 
  use the capabilities of the <b>java.nio</b> package to help you with the 
  translation from 16-bit data to bytes in the array.&nbsp; Without the <b>
  java.nio</b> capabilities, you would probably need to perform bitwise 
  operations to handle that translation.</p>
  <p><font color="#FF0000"><b>Arrangement for monaural and stereo data samples</b></font></p>
  <p>For single-channel <i>(monaural)</i> data, the audio data samples follow 
  one another in the <b>byte</b> array.</p>
  <p>For two-channel <i>(stereo)</i> data, the data in the byte array must 
  consist of alternating data samples from each of the two channels, beginning 
  with a sample from the left channel.</p>
  <p>Make certain that the size of the <b>byte</b> array is correct for an 
  integer number of samples for the number of channels specified in the format.</p>
  <blockquote>
  <p><i>(A byte array size that is a multiple of four bytes should handle both 
  monaural and stereo data for either 8-bit or 16-bit samples.)</i></p>
  </blockquote>
  <p><font color="#FF0000"><b>Playback or file writing</b></font></p>
  <p>To playback the synthetic sound data, or to write it into an audio file, 
  you will need to:</p>
  <ul>
    <li>Instantiate an <b>AudioFormat</b> object using the format parameters 
    that you used to arrange your data in the <b>byte</b> array.</li>
    <li>Instantiate a <b>ByteArrayInputStream</b> object based on the <b>byte</b> 
    array that contains your data samples.</li>
    <li>Instantiate an <b>AudioInputStream</b> object based on your <b>
    ByteArrayInputStream</b> object and your <b>AudioFormat</b> object.</li>
  </ul>
  <p><font color="#FF0000"><b>File writing only</b></font></p>
  <p>To write the data to an audio file, invoke the <b>write</b> method of the
  <b>AudioSystem</b> class, passing the following as parameters:</p>
  <ul>
    <li>Your <b>AudioInputStream</b> object.</li>
    <li>The audio file type as a constant defined in the <b>AudioFileFormat.Type</b> 
    class.</li>
    <li>A <b>File</b> object that supplies the name and extension for your file.</li>
  </ul>
  <p><font color="#FF0000"><b>Playback of synthetic sound data</b></font></p>
  <p>Having instantiated your <b>AudioFormat</b> object and your <b>
  AudioInputStream</b> object from above, to play back the data from within the 
  same program:</p>
  <ul>
    <li>Instantiate a<b> DataLine.Info</b> object that describes a <b>
    SourceDataLine</b> according to the <b>AudioFormat</b> object.</li>
    <li>Get and save a <b>SourceDataLine</b> object by invoking the <b>getLine</b> 
    method of the <b>AudioSystem</b> class, passing your <b>DataLine.Info</b> 
    object as a parameter.</li>
    <li>Spawn a thread that uses a playback loop to transfer the data from the
    <b>AudioInputStream</b> object to the <b>SourceDataLine</b> object in real 
    time.&nbsp; An example of such a thread has been discussed in several 
    previous lessons, and is also provided in the class definition for the <b>
    ListenThread</b> class in Listing 49 near the end of the lesson.</li>
  </ul>
<center>
<h2>
<a NAME="Complete Program Listings"></a>Complete Program Listing</h2></center>
        A complete listing of the program is shown in Listing 49.<br>
&nbsp;<table BORDER COLS=1 WIDTH="400" BGCOLOR="#FFFF00" >
<tr>
<td>
<pre>/*File AudioSynth01.java
Copyright 2003, R.G.Baldwin

This program demonstrates the ability to create
synthetic audio data, and to play it back
immediately, or to store it in an AU file for
later playback.

A GUI appears on the screen containing the
following components in the North position:

Generate button
Play/File button
Elapsed time meter (JTextField)

Several radio buttons appear in the Center
position of the GUI.  Each radio button selects
a different format for synthetic audio data.

The South position of the GUI contains the
following components:

Listen radio button
File radio button
File Name text field

Select a radio button from the Center and click
the Generate button.  A short segment of
synthetic audio data will be generated and saved
in memory.  The segment length is two seconds
for monaural data and one second for stereo data,
at 16000 samp/sec and 16 bits per sample.

To listen to the audio data, select the Listen
radio button in the South position and click the
Play/File button.  You can listen to the data
repeatedly if you so choose.  In addition to
listening to the data, you can also save it in
an audio file.

To save the audio data in an audio file of type
AU, enter a file name (without extension) in the
text field in the South position, select the
File radio button in the South position, and
click the Play/File button.

You should be able to play the audio file back
with any standard media player that can handle
the AU file type, or with a program written in
Java, such as the program named AudioPlayer02
that was discussed in an earlier lesson.

Tested using SDK 1.4.0 under Win2000
************************************************/

import javax.swing.*;
import java.awt.*;
import java.awt.event.*;
import javax.sound.sampled.*;
import java.io.*;
import java.nio.channels.*;
import java.nio.*;
import java.util.*;

public class AudioSynth01 extends JFrame{

  //The following are general instance variables
  // used to create a SourceDataLine object.
  AudioFormat audioFormat;
  AudioInputStream audioInputStream;
  SourceDataLine sourceDataLine;

  //The following are audio format parameters.
  // They may be modified by the signal generator
  // at runtime.  Values allowed by Java
  // SDK 1.4.1 are shown in comments.
  float sampleRate = 16000.0F;
  //Allowable 8000,11025,16000,22050,44100
  int sampleSizeInBits = 16;
  //Allowable 8,16
  int channels = 1;
  //Allowable 1,2
  boolean signed = true;
  //Allowable true,false
  boolean bigEndian = true;
  //Allowable true,false

  //A buffer to hold two seconds monaural and one
  // second stereo data at 16000 samp/sec for
  // 16-bit samples
  byte audioData[] = new byte[16000*4];

  //Following components appear in the North
  // position of the GUI.
  final JButton generateBtn =
                         new JButton("Generate");
  final JButton playOrFileBtn =
                        new JButton("Play/File");
  final JLabel elapsedTimeMeter =
                              new JLabel("0000");

  //Following radio buttons select a synthetic
  // data type.  Add more buttons if you add
  // more synthetic data types.  They appear in
  // the center position of the GUI.
  final JRadioButton tones =
                  new JRadioButton("Tones",true);
  final JRadioButton stereoPanning =
              new JRadioButton("Stereo Panning");
  final JRadioButton stereoPingpong =
             new JRadioButton("Stereo Pingpong");
  final JRadioButton fmSweep =
                    new JRadioButton("FM Sweep");
  final JRadioButton decayPulse =
                 new JRadioButton("Decay Pulse");
  final JRadioButton echoPulse =
                 new JRadioButton("Echo Pulse");
  final JRadioButton waWaPulse =
                 new JRadioButton("WaWa Pulse");

  //Following components appear in the South
  // position of the GUI.
  final JRadioButton listen =
                 new JRadioButton("Listen",true);
  final JRadioButton file =
                        new JRadioButton("File");
  final JTextField fileName =
                       new JTextField("junk",10);

  //-------------------------------------------//
  public static void main(
                        String args[]){
    new AudioSynth01();
  }//end main
  //-------------------------------------------//

  public AudioSynth01(){//constructor
    //A panel for the North position.  Note the
    // etched border.
    final JPanel controlButtonPanel =
                                    new JPanel();
    controlButtonPanel.setBorder(
             BorderFactory.createEtchedBorder());

    //A panel and button group for the radio
    // buttons in the Center position.
    final JPanel synButtonPanel = new JPanel();
    final ButtonGroup synButtonGroup =
                               new ButtonGroup();
    //This panel is used for cosmetic purposes
    // only, to cause the radio buttons to be
    // centered horizontally in the Center
    // position.
    final JPanel centerPanel = new JPanel();

    //A panel for the South position.  Note the
    // etched border.
    final JPanel outputButtonPanel =
                                    new JPanel();
    outputButtonPanel.setBorder(
             BorderFactory.createEtchedBorder());
    final ButtonGroup outputButtonGroup =
                               new ButtonGroup();

    //Disable the Play button initially to force
    // the user to generate some data before
    // trying to listen to it or write it to a
    // file.
    playOrFileBtn.setEnabled(false);

    //Register anonymous listeners on the
    // Generate button and the Play/File button.
    generateBtn.addActionListener(
      new ActionListener(){
        public void actionPerformed(
                                  ActionEvent e){
          //Don't allow Play during generation
          playOrFileBtn.setEnabled(false);
          //Generate synthetic data
          new SynGen().getSyntheticData(
                                      audioData);
          //Now it is OK for the user to listen
          // to or file the synthetic audio data.
          playOrFileBtn.setEnabled(true);
        }//end actionPerformed
      }//end ActionListener
    );//end addActionListener()

    playOrFileBtn.addActionListener(
      new ActionListener(){
        public void actionPerformed(
                                  ActionEvent e){
          //Play or file the data synthetic data
          playOrFileData();
        }//end actionPerformed
      }//end ActionListener
    );//end addActionListener()

    //Add two buttons and a text field to a
    // physical group in the North of the GUI.
    controlButtonPanel.add(generateBtn);
    controlButtonPanel.add(playOrFileBtn);
    controlButtonPanel.add(elapsedTimeMeter);

    //Add radio buttons to a mutually exclusive
    // group in the Center of the GUI.  Make
    // additions here if you add new synthetic
    // generator methods.
    synButtonGroup.add(tones);
    synButtonGroup.add(stereoPanning);
    synButtonGroup.add(stereoPingpong);
    synButtonGroup.add(fmSweep);
    synButtonGroup.add(decayPulse);
    synButtonGroup.add(echoPulse);
    synButtonGroup.add(waWaPulse);

    //Add radio buttons to a physical group and
    // center it in the Center of the GUI. Make
    // additions here if you add new synthetic
    // generator methods.
    synButtonPanel.setLayout(
                            new GridLayout(0,1));
    synButtonPanel.add(tones);
    synButtonPanel.add(stereoPanning);
    synButtonPanel.add(stereoPingpong);
    synButtonPanel.add(fmSweep);
    synButtonPanel.add(decayPulse);
    synButtonPanel.add(echoPulse);
    synButtonPanel.add(waWaPulse);

    //Note that the centerPanel has center
    // alignment by default.
    centerPanel.add(synButtonPanel);

    //Add radio buttons to a mutually exclusive
    // group in the South of the GUI.
    outputButtonGroup.add(listen);
    outputButtonGroup.add(file);

    //Add radio buttons to a physical group in
    // the South of the GUI.
    outputButtonPanel.add(listen);
    outputButtonPanel.add(file);
    outputButtonPanel.add(fileName);

    //Add the panels containing components to the
    // content pane of the GUI in the appropriate
    // positions.
    getContentPane().add(
          controlButtonPanel,BorderLayout.NORTH);
    getContentPane().add(centerPanel,
                            BorderLayout.CENTER);
    getContentPane().add(outputButtonPanel,
                             BorderLayout.SOUTH);

    //Finish the GUI.  If you add more radio
    // buttons in the center, you may need to
    // modify the call to setSize to increase
    // the vertical component of the GUI size.
    setTitle("Copyright 2003, R.G.Baldwin");
    setDefaultCloseOperation(EXIT_ON_CLOSE);
    setSize(250,275);
    setVisible(true);
  }//end constructor
  //-------------------------------------------//

  //This method plays or files the synthetic
  // audio data that has been generated and saved
  // in an array in memory.
  private void playOrFileData() {
    try{
      //Get an input stream on the byte array
      // containing the data
      InputStream byteArrayInputStream =
                        new ByteArrayInputStream(
                                      audioData);

      //Get the required audio format
      audioFormat = new AudioFormat(
                                sampleRate,
                                sampleSizeInBits,
                                channels,
                                signed,
                                bigEndian);

      //Get an audio input stream from the
      // ByteArrayInputStream
      audioInputStream = new AudioInputStream(
                    byteArrayInputStream,
                    audioFormat,
                    audioData.length/audioFormat.
                                 getFrameSize());

      //Get info on the required data line
      DataLine.Info dataLineInfo =
                          new DataLine.Info(
                            SourceDataLine.class,
                                    audioFormat);

      //Get a SourceDataLine object
      sourceDataLine = (SourceDataLine)
                             AudioSystem.getLine(
                                   dataLineInfo);
      //Decide whether to play the synthetic
      // data immediately, or to write it into
      // an audio file, based on the user
      // selection of the radio buttons in the
      // South of the GUI..
      if(listen.isSelected()){
      //Create a thread to play back the data and
      // start it running.  It will run until all
      // the data has been played back
        new ListenThread().start();
      }else{
        //Disable buttons until existing data
        // is written to the file.
        generateBtn.setEnabled(false);
        playOrFileBtn.setEnabled(false);

        //Write the data to an output file with
        // the name provided by the text field
        // in the South of the GUI.
        try{
          AudioSystem.write(
                    audioInputStream,
                    AudioFileFormat.Type.AU,
                    new File(fileName.getText() +
                                         ".au"));
        }catch (Exception e) {
          e.printStackTrace();
          System.exit(0);
        }//end catch
        //Enable buttons for another operation
        generateBtn.setEnabled(true);
        playOrFileBtn.setEnabled(true);
      }//end else
    }catch (Exception e) {
      e.printStackTrace();
      System.exit(0);
    }//end catch
  }//end playOrFileData
//=============================================//

//Inner class to play back the data that was
// saved.
class ListenThread extends Thread{
  //This is a working buffer used to transfer
  // the data between the AudioInputStream and
  // the SourceDataLine.  The size is rather
  // arbitrary.
  byte playBuffer[] = new byte[16384];

  public void run(){
    try{
      //Disable buttons while data is being
      // played.
      generateBtn.setEnabled(false);
      playOrFileBtn.setEnabled(false);

      //Open and start the SourceDataLine
      sourceDataLine.open(audioFormat);
      sourceDataLine.start();

      int cnt;
      //Get beginning of elapsed time for
      // playback
      long startTime = new Date().getTime();

      //Transfer the audio data to the speakers
      while((cnt = audioInputStream.read(
                              playBuffer, 0,
                              playBuffer.length))
                                          != -1){
        //Keep looping until the input read
        // method returns -1 for empty stream.
        if(cnt > 0){
          //Write data to the internal buffer of
          // the data line where it will be
          // delivered to the speakers in real
          // time
          sourceDataLine.write(
                             playBuffer, 0, cnt);
        }//end if
      }//end while

      //Block and wait for internal buffer of the
      // SourceDataLine to become empty.
      sourceDataLine.drain();


      //Get and display the elapsed time for
      // the previous playback.
      int elapsedTime =
         (int)(new Date().getTime() - startTime);
      elapsedTimeMeter.setText("" + elapsedTime);

      //Finish with the SourceDataLine
      sourceDataLine.stop();
      sourceDataLine.close();

      //Re-enable buttons for another operation
      generateBtn.setEnabled(true);
      playOrFileBtn.setEnabled(true);
    }catch (Exception e) {
      e.printStackTrace();
      System.exit(0);
    }//end catch

  }//end run
}//end inner class ListenThread
//=============================================//

//Inner signal generator class.

//An object of this class can be used to
// generate a variety of different synthetic
// audio signals.  Each time the getSyntheticData
// method is called on an object of this class,
// the method will fill the incoming array with
// the samples for a synthetic signal.
class SynGen{
  //Note:  Because this class uses a ByteBuffer
  // asShortBuffer to handle the data, it can
  // only be used to generate signed 16-bit
  // data.
  ByteBuffer byteBuffer;
  ShortBuffer shortBuffer;
  int byteLength;

  void getSyntheticData(byte[] synDataBuffer){
    //Prepare the ByteBuffer and the shortBuffer
    // for use
    byteBuffer = ByteBuffer.wrap(synDataBuffer);
    shortBuffer = byteBuffer.asShortBuffer();

    byteLength = synDataBuffer.length;

    //Decide which synthetic data generator
    // method to invoke based on which radio
    // button the user selected in the Center of
    // the GUI.  If you add more methods for
    // other synthetic data types, you need to
    // add corresponding radio buttons to the
    // GUI and add statements here to test the
    // new radio buttons.  Make additions here
    // if you add new synthetic generator
    // methods.

    if(tones.isSelected()) tones();
    if(stereoPanning.isSelected())
                                 stereoPanning();
    if(stereoPingpong.isSelected())
                                stereoPingpong();
    if(fmSweep.isSelected()) fmSweep();
    if(decayPulse.isSelected()) decayPulse();
    if(echoPulse.isSelected()) echoPulse();
    if(waWaPulse.isSelected()) waWaPulse();

  }//end getSyntheticData method
  //-------------------------------------------//

  //This method generates a monaural tone
  // consisting of the sum of three sinusoids.
  void tones(){
    channels = 1;//Java allows 1 or 2
    //Each channel requires two 8-bit bytes per
    // 16-bit sample.
    int bytesPerSamp = 2;
    sampleRate = 16000.0F;
    // Allowable 8000,11025,16000,22050,44100
    int sampLength = byteLength/bytesPerSamp;
    for(int cnt = 0; cnt < sampLength; cnt++){
      double time = cnt/sampleRate;
      double freq = 950.0;//arbitrary frequency
      double sinValue =
        (Math.sin(2*Math.PI*freq*time) +
        Math.sin(2*Math.PI*(freq/1.8)*time) +
        Math.sin(2*Math.PI*(freq/1.5)*time))/3.0;
      shortBuffer.put((short)(16000*sinValue));
    }//end for loop
  }//end method tones
  //-------------------------------------------//

  //This method generates a stereo speaker sweep,
  // starting with a relatively high frequency
  // tone on the left speaker and moving across
  // to a lower frequency tone on the right
  // speaker.
  void stereoPanning(){
    channels = 2;//Java allows 1 or 2
    int bytesPerSamp = 4;//Based on channels
    sampleRate = 16000.0F;
    // Allowable 8000,11025,16000,22050,44100
    int sampLength = byteLength/bytesPerSamp;
    for(int cnt = 0; cnt < sampLength; cnt++){
      //Calculate time-varying gain for each
      // speaker
      double rightGain = 16000.0*cnt/sampLength;
      double leftGain = 16000.0 - rightGain;

      double time = cnt/sampleRate;
      double freq = 600;//An arbitrary frequency
      //Generate data for left speaker
      double sinValue =
                 Math.sin(2*Math.PI*(freq)*time);
      shortBuffer.put(
                     (short)(leftGain*sinValue));
      //Generate data for right speaker
      sinValue =
             Math.sin(2*Math.PI*(freq*0.8)*time);
      shortBuffer.put(
                    (short)(rightGain*sinValue));
    }//end for loop
  }//end method stereoPanning
  //-------------------------------------------//

  //This method uses stereo to switch a sound
  // back and forth between the left and right
  // speakers at a rate of about eight switches
  // per second.  On my system, this is a much
  // better demonstration of the sound separation
  // between the two speakers than is the
  // demonstration produced by the stereoPanning
  // method.  Note also that because the sounds
  // are at different frequencies, the sound
  // produced is similar to that of U.S.
  // emergency vehicles.

  void stereoPingpong(){
    channels = 2;//Java allows 1 or 2
    int bytesPerSamp = 4;//Based on channels
    sampleRate = 16000.0F;
    // Allowable 8000,11025,16000,22050,44100
    int sampLength = byteLength/bytesPerSamp;
    double leftGain = 0.0;
    double rightGain = 16000.0;
    for(int cnt = 0; cnt < sampLength; cnt++){
      //Calculate time-varying gain for each
      // speaker
      if(cnt % (sampLength/8) == 0){
        //swap gain values
        double temp = leftGain;
        leftGain = rightGain;
        rightGain = temp;
      }//end if

      double time = cnt/sampleRate;
      double freq = 600;//An arbitrary frequency
      //Generate data for left speaker
      double sinValue =
                 Math.sin(2*Math.PI*(freq)*time);
      shortBuffer.put(
                     (short)(leftGain*sinValue));
      //Generate data for right speaker
      sinValue =
             Math.sin(2*Math.PI*(freq*0.8)*time);
      shortBuffer.put(
                    (short)(rightGain*sinValue));
    }//end for loop
  }//end stereoPingpong method
  //-------------------------------------------//

  //This method generates a monaural linear
  // frequency sweep from 100 Hz to 1000Hz.
  void fmSweep(){
    channels = 1;//Java allows 1 or 2
    int bytesPerSamp = 2;//Based on channels
    sampleRate = 16000.0F;
    // Allowable 8000,11025,16000,22050,44100
    int sampLength = byteLength/bytesPerSamp;
    double lowFreq = 100.0;
    double highFreq = 1000.0;

    for(int cnt = 0; cnt < sampLength; cnt++){
      double time = cnt/sampleRate;

      double freq = lowFreq +
               cnt*(highFreq-lowFreq)/sampLength;
      double sinValue =
                   Math.sin(2*Math.PI*freq*time);
      shortBuffer.put((short)(16000*sinValue));
    }//end for loop
  }//end method fmSweep
  //-------------------------------------------//

  //This method generates a monaural triple-
  // frequency pulse that decays in a linear
  // fashion with time.
  void decayPulse(){
    channels = 1;//Java allows 1 or 2
    int bytesPerSamp = 2;//Based on channels
    sampleRate = 16000.0F;
    // Allowable 8000,11025,16000,22050,44100
    int sampLength = byteLength/bytesPerSamp;
    for(int cnt = 0; cnt < sampLength; cnt++){
      //The value of scale controls the rate of
      // decay - large scale, fast decay.
      double scale = 2*cnt;
      if(scale > sampLength) scale = sampLength;
      double gain = 
             16000*(sampLength-scale)/sampLength;
      double time = cnt/sampleRate;
      double freq = 499.0;//an arbitrary freq
      double sinValue =
        (Math.sin(2*Math.PI*freq*time) +
        Math.sin(2*Math.PI*(freq/1.8)*time) +
        Math.sin(2*Math.PI*(freq/1.5)*time))/3.0;
      shortBuffer.put((short)(gain*sinValue));
    }//end for loop
  }//end method decayPulse
  //-------------------------------------------//

  //This method generates a monaural triple-
  // frequency pulse that decays in a linear
  // fashion with time.  However, three echoes
  // can be heard over time with the amplitude
  // of the echoes also decreasing with time.
  void echoPulse(){
    channels = 1;//Java allows 1 or 2
    int bytesPerSamp = 2;//Based on channels
    sampleRate = 16000.0F;
    // Allowable 8000,11025,16000,22050,44100
    int sampLength = byteLength/bytesPerSamp;
    int cnt2 = -8000;
    int cnt3 = -16000;
    int cnt4 = -24000;
    for(int cnt1 = 0; cnt1 < sampLength;
                    cnt1++,cnt2++,cnt3++,cnt4++){
      double val = echoPulseHelper(
                                cnt1,sampLength);
      if(cnt2 > 0){
        val += 0.7 * echoPulseHelper(
                                cnt2,sampLength);
      }//end if
      if(cnt3 > 0){
        val += 0.49 * echoPulseHelper(
                                cnt3,sampLength);
      }//end if
      if(cnt4 > 0){
        val += 0.34 * echoPulseHelper(
                                cnt4,sampLength);
      }//end if

      shortBuffer.put((short)val);
    }//end for loop
  }//end method echoPulse
  //-------------------------------------------//

  double echoPulseHelper(int cnt,int sampLength){
    //The value of scale controls the rate of
    // decay - large scale, fast decay.
    double scale = 2*cnt;
    if(scale > sampLength) scale = sampLength;
    double gain = 
             16000*(sampLength-scale)/sampLength;
    double time = cnt/sampleRate;
    double freq = 499.0;//an arbitrary freq
    double sinValue =
      (Math.sin(2*Math.PI*freq*time) +
      Math.sin(2*Math.PI*(freq/1.8)*time) +
      Math.sin(2*Math.PI*(freq/1.5)*time))/3.0;
    return(short)(gain*sinValue);
  }//end echoPulseHelper

  //-------------------------------------------//

  //This method generates a monaural triple-
  // frequency pulse that decays in a linear
  // fashion with time.  However, three echoes
  // can be heard over time with the amplitude
  // of the echoes also decreasing with time.
  //Note that this method is identical to the
  // method named echoPulse, except that the
  // algebraic sign was switched on the amplitude
  // of two of the echoes before adding them to
  // the composite synthetic signal.  This
  // resulted in a difference in the
  // sound.
  void waWaPulse(){
    channels = 1;//Java allows 1 or 2
    int bytesPerSamp = 2;//Based on channels
    sampleRate = 16000.0F;
    // Allowable 8000,11025,16000,22050,44100
    int sampLength = byteLength/bytesPerSamp;
    int cnt2 = -8000;
    int cnt3 = -16000;
    int cnt4 = -24000;
    for(int cnt1 = 0; cnt1 < sampLength;
                    cnt1++,cnt2++,cnt3++,cnt4++){
      double val = waWaPulseHelper(
                                cnt1,sampLength);
      if(cnt2 > 0){
        val += -0.7 * waWaPulseHelper(
                                cnt2,sampLength);
      }//end if
      if(cnt3 > 0){
        val += 0.49 * waWaPulseHelper(
                                cnt3,sampLength);
      }//end if
      if(cnt4 > 0){
        val += -0.34 * waWaPulseHelper(
                                cnt4,sampLength);
      }//end if

      shortBuffer.put((short)val);
    }//end for loop
  }//end method waWaPulse
  //-------------------------------------------//

  double waWaPulseHelper(int cnt,int sampLength){
    //The value of scale controls the rate of
    // decay - large scale, fast decay.
      double scale = 2*cnt;
      if(scale > sampLength) scale = sampLength;
      double gain = 
             16000*(sampLength-scale)/sampLength;
    double time = cnt/sampleRate;
    double freq = 499.0;//an arbitrary freq
    double sinValue =
      (Math.sin(2*Math.PI*freq*time) +
      Math.sin(2*Math.PI*(freq/1.8)*time) +
      Math.sin(2*Math.PI*(freq/1.5)*time))/3.0;
    return(short)(gain*sinValue);
  }//end waWaPulseHelper

  //-------------------------------------------//
}//end SynGen class
//=============================================//

}//end outer class AudioSynth01.java

<b><font face="Courier New,Courier">Listing 49</font></b></pre>
</td>
</tr>
</table>

   <hr size=3 width="100%" align=center>
<p>Copyright 2003, Richard G. Baldwin.&nbsp; Reproduction in whole or in
part in any form or medium without express written permission from Richard
Baldwin is prohibited. <h4>
<a NAME="About the author"></a>About the author</h4>
<i><a href="mailto:Baldwin@DickBaldwin.com">Richard Baldwin</a> is a college professor (at Austin Community College in Austin, TX) and private consultant whose primary focus is a combination of Java, C#, and XML. In addition to the many platform and/or language independent benefits of Java and C# applications, he believes that a combination of Java, C#, and XML will become the primary driving force in the delivery of structured information on the Web.</i><br><p><i>Richard has participated in numerous consulting projects and he
frequently provides onsite training at the high-tech companies located
in and around Austin, Texas.&nbsp; He is the author of Baldwin's Programming <a href="http://www.DickBaldwin.com">Tutorials</a>,
which has gained a worldwide following among experienced and aspiring programmers.
He has also published articles in JavaPro magazine.</i> <p><i>Richard holds an MSEE degree from Southern Methodist University and
has many years of experience in the application of computer technology
to real-world problems.</i> <p><i><a href="mailto:Baldwin@DickBaldwin.com">Baldwin@DickBaldwin.com</a></i> <p>-end- </body></html>